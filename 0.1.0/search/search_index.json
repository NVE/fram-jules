{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>FRAM JulES package is a part of FRAM open-source modelling framework developed by NVE. The package is responsible for running open-source power market model JuLES with FRAM. It contains the implementation of JuLES solver based on the solver interface defined in FRAM core package. </p> <p></p>"},{"location":"#installation","title":"Installation","text":"<p>To install FRAM JulES package, run <code>pip install fram-jules</code>. But we recommend that you rather start by installing our simple demo to better understand how FRAM works.</p>"},{"location":"reference/","title":"Code Reference","text":""},{"location":"reference/#framjules","title":"<code>framjules</code>","text":""},{"location":"reference/#framjules.JulES","title":"<code>JulES</code>","text":""},{"location":"reference/#framjules.JulES.JulES","title":"<code>JulES</code>","text":"<p>               Bases: <code>Solver</code></p> <p>Solver class for JulES - a fundamental energy market simulation model for operational planning.</p> <p>The JulES solver takes a populated Model, and uses the configuration set by the user in JulESConfig to run JulES and read results back into the Model. The main steps of the JulES solver class are described below: 1. Transform Model into JulES compatible Components (SolveHandler) 2. Build JulES input files (BuildHandler) 3. Configure JulES according to the JulESConfig (ConfigHandler) 4. Run JulES (and setup Julia environment if needed) (RunHandler) 5. Read results from JulES back into the Model (ResultsHandler)</p> <p>SolveHandler - Initialize - Transform the Model Components into JulES compatible Components. JulES uses the main Components Node and Flow to represent the energy system. - If Aggregators are set in JulEConfig.short_term_aggregations, make an aggregated version of Model. The JulES, algorithm has different problems that will use different Models. The clearing, stochastic subsystem and end value problems will use the full detailed Model, while the price prognosis problem will use the aggregated Model. SolveHandler also makes the mappings between the detailed and aggregated Models to couple the problems. - JulES only support the commodities Power, Hydro and Battery at the moment. All commodities in Model will be mapped to these. The main property of the commodity in JulES is the horizon (with type, duration and resolution). Power is the default commodity, and all commodities with no storage will be mapped to Power. Battery represents short-term storage commodities with a detailed time resolution, while Hydro represents long-term storage commodities with a coarser time resolution. - Identify storagesystems (e.g. watersheds or batteries), and identify if they are long-term or short-term storage systems. Storage systems are short-term if all storages in the subsystem have lower storage duration than JulESConfig.get_short_term_storage_cutoff_hours(). All storage subsystems in the same category (short-term or long-term) will get the same storage commodities and horizons, problem structure and end-condition type.     - Short-term: StochSubsystem, startequalstop, no skipmed, Battery commodity, short horizon duration.     - Long-term: EVP and/or StochSubsystem, endvalues from ppp, skipmed, Hydro commodity, long horizon duration. - TODO: This implementation is built around the first JulES version and will be improved in the future. We would like to add more tailored configurations for each storage system. Also make models for each problem and subsystem in JulES, not just a detailed and aggregated version of Model that JulES has to derive all problems from.</p> <p>BuildHandler - Build JulES input files. - Write JulES input files for the detailed and aggregated elements, together with their timevectors. - Write JulES input files for detailed and aggregated start storages. - Write JulES input file for the mapping between detailed and aggregated storages.</p> <p>ConfigHandler - Configure JulES according to the JulESConfig set by the user and the Model. - Simulation mode, simulation periods, weather years and scenario generation. - Number of CPU cores to use, parallelization settings and optimization solvers. - Problem structure and horizons for each problem and commodity. Horizon type, duration and resolution.     - The problem structure will in most cases consist of the following, which are run for each simulation step:         - Deterministic price prognosis problems for each weather scenario         - Deterministic end value problems for each storage subsystem and weather scenario         - Stochastic (two-stage) subsystems problem for each storage subsystem         - Market clearing problem     - Exception 1: If there are no storages in the system, only the market clearing problem will be run.         TODO: Should also check if there are other constraints coupling time periods.         Then we need the price prognosis problems.     - Exception 2: If there is only exogenous market nodes only stochastic subsystem problems will not be run.     - TODO: Improve configuration possibilities for the different problem structure cases. - Result settings. - Turn on or off various JulES features.</p> <p>See JulES documentation at https://nve.github.io/JulES/ for more.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initializes the solver with default configuration.</p> <code>get_config</code> <p>Returns the internal configuration object for customization.</p> <code>solve</code> <p>Model): Solves the given model using JulES. Parent class method (Solver).</p> Source code in <code>framjules/JulES.py</code> <pre><code>class JulES(Solver):\n    \"\"\"Solver class for JulES - a fundamental energy market simulation model for operational planning.\n\n    The JulES solver takes a populated Model, and uses the configuration set by the user in JulESConfig to run\n    JulES and read results back into the Model. The main steps of the JulES solver class are described below:\n    1. Transform Model into JulES compatible Components (SolveHandler)\n    2. Build JulES input files (BuildHandler)\n    3. Configure JulES according to the JulESConfig (ConfigHandler)\n    4. Run JulES (and setup Julia environment if needed) (RunHandler)\n    5. Read results from JulES back into the Model (ResultsHandler)\n\n    SolveHandler - Initialize\n    - Transform the Model Components into JulES compatible Components. JulES uses the main Components\n    Node and Flow to represent the energy system.\n    - If Aggregators are set in JulEConfig.short_term_aggregations, make an aggregated version of Model. The JulES,\n    algorithm has different problems that will use different Models. The clearing, stochastic subsystem and end\n    value problems will use the full detailed Model, while the price prognosis problem will use the aggregated Model.\n    SolveHandler also makes the mappings between the detailed and aggregated Models to couple the problems.\n    - JulES only support the commodities Power, Hydro and Battery at the moment. All commodities in Model will be mapped\n    to these. The main property of the commodity in JulES is the horizon (with type, duration and resolution). Power is\n    the default commodity, and all commodities with no storage will be mapped to Power. Battery represents short-term\n    storage commodities with a detailed time resolution, while Hydro represents long-term storage commodities with a\n    coarser time resolution.\n    - Identify storagesystems (e.g. watersheds or batteries), and identify if they are long-term or short-term\n    storage systems. Storage systems are short-term if all storages in the subsystem have lower storage duration than\n    JulESConfig.get_short_term_storage_cutoff_hours(). All storage subsystems in the same category\n    (short-term or long-term) will get the same storage commodities and horizons, problem structure and end-condition\n    type.\n        - Short-term: StochSubsystem, startequalstop, no skipmed, Battery commodity, short horizon duration.\n        - Long-term: EVP and/or StochSubsystem, endvalues from ppp, skipmed, Hydro commodity, long horizon duration.\n    - TODO: This implementation is built around the first JulES version and will be improved in the future.\n    We would like to add more tailored configurations for each storage system. Also make models for each problem and\n    subsystem in JulES, not just a detailed and aggregated version of Model that JulES has to derive all problems from.\n\n    BuildHandler - Build JulES input files.\n    - Write JulES input files for the detailed and aggregated elements, together with their timevectors.\n    - Write JulES input files for detailed and aggregated start storages.\n    - Write JulES input file for the mapping between detailed and aggregated storages.\n\n    ConfigHandler - Configure JulES according to the JulESConfig set by the user and the Model.\n    - Simulation mode, simulation periods, weather years and scenario generation.\n    - Number of CPU cores to use, parallelization settings and optimization solvers.\n    - Problem structure and horizons for each problem and commodity. Horizon type, duration and resolution.\n        - The problem structure will in most cases consist of the following, which are run for each simulation step:\n            - Deterministic price prognosis problems for each weather scenario\n            - Deterministic end value problems for each storage subsystem and weather scenario\n            - Stochastic (two-stage) subsystems problem for each storage subsystem\n            - Market clearing problem\n        - Exception 1: If there are no storages in the system, only the market clearing problem will be run.\n            TODO: Should also check if there are other constraints coupling time periods.\n            Then we need the price prognosis problems.\n        - Exception 2: If there is only exogenous market nodes only stochastic subsystem problems will not be run.\n        - TODO: Improve configuration possibilities for the different problem structure cases.\n    - Result settings.\n    - Turn on or off various JulES features.\n\n    See JulES documentation at https://nve.github.io/JulES/ for more.\n\n    Methods:\n        __init__(): Initializes the solver with default configuration.\n        get_config(): Returns the internal configuration object for customization.\n        solve(model: Model): Solves the given model using JulES. Parent class method (Solver).\n\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Create new JulES solver with default config set.\"\"\"\n        super().__init__()\n        self._config = JulESConfig()\n\n    def get_config(self) -&gt; JulESConfig:\n        \"\"\"Get internal config object. Modify this to configure JulES.\"\"\"\n        return self._config\n\n    def _solve(\n        self,\n        folder: Path,\n        model: Model,\n    ) -&gt; None:\n        t0 = time()\n        if _PROFILE_PERFORMANCE:\n            profiler = cProfile.Profile()\n            profiler.enable()\n        handler = SolveHandler(folder, model, self.get_config())\n        self.send_debug_event(f\"SolveHandler time: {round(time() - t0, 2)} seconds\")\n        if _PROFILE_PERFORMANCE:\n            profiler.disable()  # Stop profiling\n            profiler.dump_stats(\"profile_solvehandler_init.prof\")\n\n        t = time()\n        if _PROFILE_PERFORMANCE:\n            profiler = cProfile.Profile()\n            profiler.enable()\n        handler.build()\n        if _PROFILE_PERFORMANCE:\n            profiler.disable()  # Stop profiling\n            profiler.dump_stats(\"profile_solvehandler_build.prof\")\n        self.send_debug_event(f\"build time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        handler.configure()\n        self.send_debug_event(f\"configure time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        loaders: set[Loader] = set()\n        add_loaders(loaders, model)\n        for loader in loaders:\n            loader.clear_cache()\n        gc.collect()\n        self.send_debug_event(f\"clear_cache time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        handler.run()\n        self.send_debug_event(f\"run time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        if _PROFILE_PERFORMANCE:\n            profiler = cProfile.Profile()\n            profiler.enable()\n        handler.set_results()\n        if _PROFILE_PERFORMANCE:\n            profiler.disable()  # Stop profiling\n            profiler.dump_stats(\"profile_solvehandler_results.prof\")\n        self.send_debug_event(f\"set_results time: {round(time() - t, 2)} seconds\")\n\n        self.send_debug_event(f\"JulES._solve time: {round(time() - t0, 2)} seconds\")\n</code></pre>"},{"location":"reference/#framjules.JulES.JulES.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Create new JulES solver with default config set.</p> Source code in <code>framjules/JulES.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create new JulES solver with default config set.\"\"\"\n    super().__init__()\n    self._config = JulESConfig()\n</code></pre>"},{"location":"reference/#framjules.JulES.JulES.get_config","title":"<code>get_config() -&gt; JulESConfig</code>","text":"<p>Get internal config object. Modify this to configure JulES.</p> Source code in <code>framjules/JulES.py</code> <pre><code>def get_config(self) -&gt; JulESConfig:\n    \"\"\"Get internal config object. Modify this to configure JulES.\"\"\"\n    return self._config\n</code></pre>"},{"location":"reference/#framjules.JulESConfig","title":"<code>JulESConfig</code>","text":""},{"location":"reference/#framjules.JulESConfig.JulESConfig","title":"<code>JulESConfig</code>","text":"<p>               Bases: <code>SolverConfig</code></p> <p>Class containing all config for JulES. Subclass of SolverConfig.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>class JulESConfig(SolverConfig):\n    \"\"\"Class containing all config for JulES. Subclass of SolverConfig.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Create new JulESConfig object.\"\"\"\n        super().__init__()\n\n        self._julia_exe_path: Path | str | None = None\n        self._julia_env_path: Path | str | None = None\n        self._julia_depot_path: Path | str | None = None\n        self._force_julia_install: bool = True\n\n        self._branch_jules: str | None = None\n        self._branch_tulipa: str | None = None\n\n        self._short_term_aggregations: list[Aggregator] = []\n\n        self._time_resolution = JulESTimeResolution()\n\n        self._duration_clearing = timedelta(days=1)\n        self._duration_short_term = timedelta(days=6)\n        self._duration_medium_term = timedelta(days=364)\n        self._duration_long_term = timedelta(days=364 * 5)\n\n        self._market_resolution_clearing = timedelta(hours=1)\n        self._market_resolution_short_term = timedelta(hours=2)\n\n        self._market_num_blocks_medium_term = 5\n        self._market_num_blocks_long_term = 4\n\n        self._storage_resolution_clearing = timedelta(days=1)\n        self._storage_resolution_short_term = timedelta(days=2)\n        self._storage_resolution_medium_term = timedelta(days=7)\n        self._storage_resolution_long_term = timedelta(days=28)\n\n        self._short_term_storage_cutoff_hours = 24 * 7\n\n        self._debug_short_opt_solver = False\n        self._debug_med_opt_solver = False\n        self._debug_long_opt_solver = False\n        self._debug_end_value_opt_solver = False\n        self._debug_subsystem_master_opt_solver = False\n        self._debug_subsystem_sub_opt_solver = False\n        self._debug_clearing_opt_solver = False\n        self._is_cache_db = True\n        self._skip_install_dependencies = False\n\n        self._clearing_days = 2\n        self._market_duration_minutes = 6 * 60\n        self._storage_duration_minutes = 2 * 24 * 60\n        self._lookahead_days = 5 * 365\n        self._detail_level = \"fast\"\n\n        self._skipmax_days = 6\n        self._warn_skipmax_days = 32\n\n    def set_skipmax_days(self, days: int) -&gt; None:\n        \"\"\"Set number of days between calculation of medium and long term storage values.\n\n        This can speed up a simulation as medium and long term price prognosis problems, and long term\n        storage value problems are solved less often. The cost is less good storage values. The longer between\n        re-calculation of storage values, the bigger negative impact on simulation result quality.\n\n        If skipmax_days = 6 and clearing_days = 2, JulES will calculate medium and long\n        term storage values every 3rd simulation step.\n\n        Short term price prognosis problems and storage values problems (i.e. for batteries) are not affected by this\n        setting, and are calculated every simulation step.\n        \"\"\"\n        self._check_type(days, int)\n        self._check_int(days, lower_bound=0, upper_bound=None)\n        if days &gt; self._warn_skipmax_days:\n            message = (\n                \"Unusually high value for skipmax_days: \"\n                f\"Medium and long term storage values updated only {days}th day. \"\n                \"This can give poor simulation results due to poor storage utilization.\"\n            )\n            self.send_warning_event(message)\n        self._skipmax_days = days\n\n    def get_skipmax_days(self) -&gt; int:\n        \"\"\"Get number of days between calculation of medium and long term storage values.\"\"\"\n        return self._skipmax_days\n\n    def is_skip_install_dependencies(self) -&gt; bool:\n        \"\"\"Return True if install julia dependencies will be skipped during JulES.solve.\"\"\"\n        return self._skip_install_dependencies\n\n    def activate_skip_install_dependencies(self) -&gt; None:\n        \"\"\"Tell JulES to not install julia dependencies, assuming they are already installed.\n\n        Default is to install.\n        \"\"\"\n        self._skip_install_dependencies = True\n\n    def deactivate_skip_install_dependencies(self) -&gt; None:\n        \"\"\"Tell JulES to install julia dependencies. (This is the default).\"\"\"\n        self._skip_install_dependencies = False\n\n    def is_cache_db(self) -&gt; bool:\n        \"\"\"Return True if JulES is allowed to use a cache to store precomputed values while building.\"\"\"\n        return self._is_cache_db\n\n    def activate_cache_db(self) -&gt; None:\n        \"\"\"Activates use of cache db.\"\"\"\n        self._is_cache_db = True\n\n    def deactivate_cache_db(self) -&gt; None:\n        \"\"\"Activates use of db without cache.\"\"\"\n        self._is_cache_db = False\n\n    def get_time_resolution(self) -&gt; JulESTimeResolution:\n        \"\"\"Get time resolution object. Modify this to modify time resolution of JulES.\"\"\"\n        return self._time_resolution\n\n    def get_short_term_storage_cutoff_hours(self) -&gt; int:\n        \"\"\"Return number of hours.\n\n        JulES will classify all storage subsystems with max storage duration less than cutoff as short term subsystems.\n        \"\"\"\n        return self._short_term_storage_cutoff_hours\n\n    def set_jules_version(self, jules_branch: str | None = None, tulipa_branch: str | None = None) -&gt; None:\n        \"\"\"Set which version of JulES and/or TuLiPa to use.\n\n        Can be a git branch name, or a local path to a git repo which will activate development mode.\n        \"\"\"\n        self._check_type(jules_branch, (str, type(None)))\n        self._check_type(tulipa_branch, (str, type(None)))\n        if jules_branch is not None:\n            self._branch_jules = jules_branch\n        if tulipa_branch is not None:\n            self._branch_tulipa = tulipa_branch\n        if self._branch_tulipa is None and self._branch_jules is not None:\n            self._branch_tulipa = self._branch_jules\n\n    def get_jules_version(self) -&gt; str | None:\n        \"\"\"Get JulES version.\n\n        Can be a git branch name, or a local path to a git repo for use in development mode.\n        \"\"\"\n        return self._branch_jules\n\n    def get_tulipa_version(self) -&gt; str | None:\n        \"\"\"Get TuLiPa git branch.\n\n        Can be a git branch name, or a local path to a git repo for use in development mode.\n        \"\"\"\n        return self._branch_tulipa\n\n    def set_julia_depot_path(self, path: Path) -&gt; None:\n        \"\"\"Set folder where Julia installs new packages.\"\"\"\n        self._check_type(path, Path)\n        self._julia_depot_path = path\n\n    def get_julia_depot_path(self) -&gt; Path | None:\n        \"\"\"Get folder where Julia installs new packages.\"\"\"\n        return self._julia_depot_path\n\n    def set_julia_env_path(self, path: Path) -&gt; None:\n        \"\"\"Set which Julia environment to use.\"\"\"\n        self._check_type(path, Path)\n        self._julia_env_path = path\n\n    def get_julia_env_path(self) -&gt; Path | None:\n        \"\"\"Get Julia environment being used.\"\"\"\n        return self._julia_env_path\n\n    def set_julia_exe_path(self, path: Path) -&gt; None:\n        \"\"\"Set which Julia installation to use.\"\"\"\n        self._check_type(path, Path)\n        self._julia_exe_path = path\n\n    def get_julia_exe_path(self) -&gt; Path | None:\n        \"\"\"Get Julia installation being used.\"\"\"\n        return self._julia_exe_path\n\n    def set_force_julia_install(self, flag: bool) -&gt; bool:\n        \"\"\"Set bool for force new julia install.\"\"\"\n        self._force_julia_install = flag\n\n    def get_force_julia_install(self) -&gt; bool:\n        \"\"\"Get bool for force new julia install.\"\"\"\n        return self._force_julia_install\n\n    def _check_supported_aggregators(self, aggregators: list[Aggregator]) -&gt; None:\n        for aggr in aggregators:\n            if not isinstance(aggr, tuple(_SUPPORTED_AGGREGATORS)):\n                message = (\n                    f\"Aggregator of type {type(aggr)} is not supported in JulES.\",\n                    f\"Supported types are: {_SUPPORTED_AGGREGATORS}\",\n                )\n                raise TypeError(message)\n\n    def set_short_term_aggregations(self, aggregators: list[Aggregator]) -&gt; None:\n        \"\"\"Set aggregations to create the short term model used in the price prognosis problems.\"\"\"\n        self._check_supported_aggregators(aggregators)\n        self._short_term_aggregations = aggregators\n\n    def get_short_term_aggregations(self) -&gt; list[Aggregator]:\n        \"\"\"Get aggregations to create the short term model used in the price prognosis problems.\"\"\"\n        return self._short_term_aggregations\n\n    \"\"\"\n    Debug optimization solvers of the different JulES problems.\n    Helpful if problems are encountered during solving, most commonly infeasibility issues.\n    Replaces TuLiPa.HiGHS_Prob with TuLiPa.JuMP_Prob which has better debugging features:\n    - More checks while building the optimization problem\n    - If infeasible, solve the problem again with relaxed constraints (with penalties) and return the broken constraints\n    - Outputs the optimization problem with variable and constraint names from FRAM\n    At the cost of performance, as JuMP_Prob is slower than HiGHS_Prob.\n\n    JulES will now automatically switch to JuMP_Prob if HiGHS_Prob fails, but these can still be used for testing\n    and debugging.\n    \"\"\"\n\n    def set_debug_all_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug all optimization solvers.\"\"\"\n        self._debug_short_opt_solver = debug\n        self._debug_med_opt_solver = debug\n        self._debug_long_opt_solver = debug\n        self._debug_end_value_opt_solver = debug\n        self._debug_subsystem_master_opt_solver = debug\n        self._debug_subsystem_sub_opt_solver = debug\n        self._debug_clearing_opt_solver = debug\n\n    def set_debug_short_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the short-term optimization solver.\"\"\"\n        self._debug_short_opt_solver = debug\n\n    def get_debug_short_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the short-term optimization solver.\"\"\"\n        return self._debug_short_opt_solver\n\n    def set_debug_med_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the medium-term optimization solver.\"\"\"\n        self._debug_med_opt_solver = debug\n\n    def get_debug_med_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the medium-term optimization solver.\"\"\"\n        return self._debug_med_opt_solver\n\n    def set_debug_long_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the long-term optimization solver.\"\"\"\n        self._debug_long_opt_solver = debug\n\n    def get_debug_long_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the long-term optimization solver.\"\"\"\n        return self._debug_long_opt_solver\n\n    def set_debug_end_value_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the end value optimization solver.\"\"\"\n        self._debug_end_value_opt_solver = debug\n\n    def get_debug_end_value_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the end value optimization solver.\"\"\"\n        return self._debug_end_value_opt_solver\n\n    def set_debug_subsystem_master_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the subsystem master optimization solver.\"\"\"\n        self._debug_subsystem_master_opt_solver = debug\n\n    def get_debug_subsystem_master_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the subsystem master optimization solver.\"\"\"\n        return self._debug_subsystem_master_opt_solver\n\n    def set_debug_subsystem_sub_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the subsystem sub optimization solver.\"\"\"\n        self._debug_subsystem_sub_opt_solver = debug\n\n    def get_debug_subsystem_sub_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the subsystem sub optimization solver.\"\"\"\n        return self._debug_subsystem_sub_opt_solver\n\n    def set_debug_clearing_opt_solver(self, debug: bool) -&gt; None:\n        \"\"\"Set whether to debug the clearing optimization solver.\"\"\"\n        self._debug_clearing_opt_solver = debug\n\n    def get_debug_clearing_opt_solver(self) -&gt; bool:\n        \"\"\"Get whether to debug the clearing optimization solver.\"\"\"\n        return self._debug_clearing_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Create new JulESConfig object.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create new JulESConfig object.\"\"\"\n    super().__init__()\n\n    self._julia_exe_path: Path | str | None = None\n    self._julia_env_path: Path | str | None = None\n    self._julia_depot_path: Path | str | None = None\n    self._force_julia_install: bool = True\n\n    self._branch_jules: str | None = None\n    self._branch_tulipa: str | None = None\n\n    self._short_term_aggregations: list[Aggregator] = []\n\n    self._time_resolution = JulESTimeResolution()\n\n    self._duration_clearing = timedelta(days=1)\n    self._duration_short_term = timedelta(days=6)\n    self._duration_medium_term = timedelta(days=364)\n    self._duration_long_term = timedelta(days=364 * 5)\n\n    self._market_resolution_clearing = timedelta(hours=1)\n    self._market_resolution_short_term = timedelta(hours=2)\n\n    self._market_num_blocks_medium_term = 5\n    self._market_num_blocks_long_term = 4\n\n    self._storage_resolution_clearing = timedelta(days=1)\n    self._storage_resolution_short_term = timedelta(days=2)\n    self._storage_resolution_medium_term = timedelta(days=7)\n    self._storage_resolution_long_term = timedelta(days=28)\n\n    self._short_term_storage_cutoff_hours = 24 * 7\n\n    self._debug_short_opt_solver = False\n    self._debug_med_opt_solver = False\n    self._debug_long_opt_solver = False\n    self._debug_end_value_opt_solver = False\n    self._debug_subsystem_master_opt_solver = False\n    self._debug_subsystem_sub_opt_solver = False\n    self._debug_clearing_opt_solver = False\n    self._is_cache_db = True\n    self._skip_install_dependencies = False\n\n    self._clearing_days = 2\n    self._market_duration_minutes = 6 * 60\n    self._storage_duration_minutes = 2 * 24 * 60\n    self._lookahead_days = 5 * 365\n    self._detail_level = \"fast\"\n\n    self._skipmax_days = 6\n    self._warn_skipmax_days = 32\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.activate_cache_db","title":"<code>activate_cache_db() -&gt; None</code>","text":"<p>Activates use of cache db.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def activate_cache_db(self) -&gt; None:\n    \"\"\"Activates use of cache db.\"\"\"\n    self._is_cache_db = True\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.activate_skip_install_dependencies","title":"<code>activate_skip_install_dependencies() -&gt; None</code>","text":"<p>Tell JulES to not install julia dependencies, assuming they are already installed.</p> <p>Default is to install.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def activate_skip_install_dependencies(self) -&gt; None:\n    \"\"\"Tell JulES to not install julia dependencies, assuming they are already installed.\n\n    Default is to install.\n    \"\"\"\n    self._skip_install_dependencies = True\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.deactivate_cache_db","title":"<code>deactivate_cache_db() -&gt; None</code>","text":"<p>Activates use of db without cache.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def deactivate_cache_db(self) -&gt; None:\n    \"\"\"Activates use of db without cache.\"\"\"\n    self._is_cache_db = False\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.deactivate_skip_install_dependencies","title":"<code>deactivate_skip_install_dependencies() -&gt; None</code>","text":"<p>Tell JulES to install julia dependencies. (This is the default).</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def deactivate_skip_install_dependencies(self) -&gt; None:\n    \"\"\"Tell JulES to install julia dependencies. (This is the default).\"\"\"\n    self._skip_install_dependencies = False\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_clearing_opt_solver","title":"<code>get_debug_clearing_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the clearing optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_clearing_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the clearing optimization solver.\"\"\"\n    return self._debug_clearing_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_end_value_opt_solver","title":"<code>get_debug_end_value_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the end value optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_end_value_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the end value optimization solver.\"\"\"\n    return self._debug_end_value_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_long_opt_solver","title":"<code>get_debug_long_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the long-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_long_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the long-term optimization solver.\"\"\"\n    return self._debug_long_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_med_opt_solver","title":"<code>get_debug_med_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the medium-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_med_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the medium-term optimization solver.\"\"\"\n    return self._debug_med_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_short_opt_solver","title":"<code>get_debug_short_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the short-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_short_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the short-term optimization solver.\"\"\"\n    return self._debug_short_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_subsystem_master_opt_solver","title":"<code>get_debug_subsystem_master_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the subsystem master optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_subsystem_master_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the subsystem master optimization solver.\"\"\"\n    return self._debug_subsystem_master_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_debug_subsystem_sub_opt_solver","title":"<code>get_debug_subsystem_sub_opt_solver() -&gt; bool</code>","text":"<p>Get whether to debug the subsystem sub optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_debug_subsystem_sub_opt_solver(self) -&gt; bool:\n    \"\"\"Get whether to debug the subsystem sub optimization solver.\"\"\"\n    return self._debug_subsystem_sub_opt_solver\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_force_julia_install","title":"<code>get_force_julia_install() -&gt; bool</code>","text":"<p>Get bool for force new julia install.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_force_julia_install(self) -&gt; bool:\n    \"\"\"Get bool for force new julia install.\"\"\"\n    return self._force_julia_install\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_jules_version","title":"<code>get_jules_version() -&gt; str | None</code>","text":"<p>Get JulES version.</p> <p>Can be a git branch name, or a local path to a git repo for use in development mode.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_jules_version(self) -&gt; str | None:\n    \"\"\"Get JulES version.\n\n    Can be a git branch name, or a local path to a git repo for use in development mode.\n    \"\"\"\n    return self._branch_jules\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_julia_depot_path","title":"<code>get_julia_depot_path() -&gt; Path | None</code>","text":"<p>Get folder where Julia installs new packages.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_julia_depot_path(self) -&gt; Path | None:\n    \"\"\"Get folder where Julia installs new packages.\"\"\"\n    return self._julia_depot_path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_julia_env_path","title":"<code>get_julia_env_path() -&gt; Path | None</code>","text":"<p>Get Julia environment being used.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_julia_env_path(self) -&gt; Path | None:\n    \"\"\"Get Julia environment being used.\"\"\"\n    return self._julia_env_path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_julia_exe_path","title":"<code>get_julia_exe_path() -&gt; Path | None</code>","text":"<p>Get Julia installation being used.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_julia_exe_path(self) -&gt; Path | None:\n    \"\"\"Get Julia installation being used.\"\"\"\n    return self._julia_exe_path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_short_term_aggregations","title":"<code>get_short_term_aggregations() -&gt; list[Aggregator]</code>","text":"<p>Get aggregations to create the short term model used in the price prognosis problems.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_short_term_aggregations(self) -&gt; list[Aggregator]:\n    \"\"\"Get aggregations to create the short term model used in the price prognosis problems.\"\"\"\n    return self._short_term_aggregations\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_short_term_storage_cutoff_hours","title":"<code>get_short_term_storage_cutoff_hours() -&gt; int</code>","text":"<p>Return number of hours.</p> <p>JulES will classify all storage subsystems with max storage duration less than cutoff as short term subsystems.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_short_term_storage_cutoff_hours(self) -&gt; int:\n    \"\"\"Return number of hours.\n\n    JulES will classify all storage subsystems with max storage duration less than cutoff as short term subsystems.\n    \"\"\"\n    return self._short_term_storage_cutoff_hours\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_skipmax_days","title":"<code>get_skipmax_days() -&gt; int</code>","text":"<p>Get number of days between calculation of medium and long term storage values.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_skipmax_days(self) -&gt; int:\n    \"\"\"Get number of days between calculation of medium and long term storage values.\"\"\"\n    return self._skipmax_days\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_time_resolution","title":"<code>get_time_resolution() -&gt; JulESTimeResolution</code>","text":"<p>Get time resolution object. Modify this to modify time resolution of JulES.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_time_resolution(self) -&gt; JulESTimeResolution:\n    \"\"\"Get time resolution object. Modify this to modify time resolution of JulES.\"\"\"\n    return self._time_resolution\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.get_tulipa_version","title":"<code>get_tulipa_version() -&gt; str | None</code>","text":"<p>Get TuLiPa git branch.</p> <p>Can be a git branch name, or a local path to a git repo for use in development mode.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def get_tulipa_version(self) -&gt; str | None:\n    \"\"\"Get TuLiPa git branch.\n\n    Can be a git branch name, or a local path to a git repo for use in development mode.\n    \"\"\"\n    return self._branch_tulipa\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.is_cache_db","title":"<code>is_cache_db() -&gt; bool</code>","text":"<p>Return True if JulES is allowed to use a cache to store precomputed values while building.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def is_cache_db(self) -&gt; bool:\n    \"\"\"Return True if JulES is allowed to use a cache to store precomputed values while building.\"\"\"\n    return self._is_cache_db\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.is_skip_install_dependencies","title":"<code>is_skip_install_dependencies() -&gt; bool</code>","text":"<p>Return True if install julia dependencies will be skipped during JulES.solve.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def is_skip_install_dependencies(self) -&gt; bool:\n    \"\"\"Return True if install julia dependencies will be skipped during JulES.solve.\"\"\"\n    return self._skip_install_dependencies\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_all_opt_solver","title":"<code>set_debug_all_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug all optimization solvers.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_all_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug all optimization solvers.\"\"\"\n    self._debug_short_opt_solver = debug\n    self._debug_med_opt_solver = debug\n    self._debug_long_opt_solver = debug\n    self._debug_end_value_opt_solver = debug\n    self._debug_subsystem_master_opt_solver = debug\n    self._debug_subsystem_sub_opt_solver = debug\n    self._debug_clearing_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_clearing_opt_solver","title":"<code>set_debug_clearing_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the clearing optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_clearing_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the clearing optimization solver.\"\"\"\n    self._debug_clearing_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_end_value_opt_solver","title":"<code>set_debug_end_value_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the end value optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_end_value_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the end value optimization solver.\"\"\"\n    self._debug_end_value_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_long_opt_solver","title":"<code>set_debug_long_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the long-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_long_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the long-term optimization solver.\"\"\"\n    self._debug_long_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_med_opt_solver","title":"<code>set_debug_med_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the medium-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_med_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the medium-term optimization solver.\"\"\"\n    self._debug_med_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_short_opt_solver","title":"<code>set_debug_short_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the short-term optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_short_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the short-term optimization solver.\"\"\"\n    self._debug_short_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_subsystem_master_opt_solver","title":"<code>set_debug_subsystem_master_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the subsystem master optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_subsystem_master_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the subsystem master optimization solver.\"\"\"\n    self._debug_subsystem_master_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_debug_subsystem_sub_opt_solver","title":"<code>set_debug_subsystem_sub_opt_solver(debug: bool) -&gt; None</code>","text":"<p>Set whether to debug the subsystem sub optimization solver.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_debug_subsystem_sub_opt_solver(self, debug: bool) -&gt; None:\n    \"\"\"Set whether to debug the subsystem sub optimization solver.\"\"\"\n    self._debug_subsystem_sub_opt_solver = debug\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_force_julia_install","title":"<code>set_force_julia_install(flag: bool) -&gt; bool</code>","text":"<p>Set bool for force new julia install.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_force_julia_install(self, flag: bool) -&gt; bool:\n    \"\"\"Set bool for force new julia install.\"\"\"\n    self._force_julia_install = flag\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_jules_version","title":"<code>set_jules_version(jules_branch: str | None = None, tulipa_branch: str | None = None) -&gt; None</code>","text":"<p>Set which version of JulES and/or TuLiPa to use.</p> <p>Can be a git branch name, or a local path to a git repo which will activate development mode.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_jules_version(self, jules_branch: str | None = None, tulipa_branch: str | None = None) -&gt; None:\n    \"\"\"Set which version of JulES and/or TuLiPa to use.\n\n    Can be a git branch name, or a local path to a git repo which will activate development mode.\n    \"\"\"\n    self._check_type(jules_branch, (str, type(None)))\n    self._check_type(tulipa_branch, (str, type(None)))\n    if jules_branch is not None:\n        self._branch_jules = jules_branch\n    if tulipa_branch is not None:\n        self._branch_tulipa = tulipa_branch\n    if self._branch_tulipa is None and self._branch_jules is not None:\n        self._branch_tulipa = self._branch_jules\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_julia_depot_path","title":"<code>set_julia_depot_path(path: Path) -&gt; None</code>","text":"<p>Set folder where Julia installs new packages.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_julia_depot_path(self, path: Path) -&gt; None:\n    \"\"\"Set folder where Julia installs new packages.\"\"\"\n    self._check_type(path, Path)\n    self._julia_depot_path = path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_julia_env_path","title":"<code>set_julia_env_path(path: Path) -&gt; None</code>","text":"<p>Set which Julia environment to use.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_julia_env_path(self, path: Path) -&gt; None:\n    \"\"\"Set which Julia environment to use.\"\"\"\n    self._check_type(path, Path)\n    self._julia_env_path = path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_julia_exe_path","title":"<code>set_julia_exe_path(path: Path) -&gt; None</code>","text":"<p>Set which Julia installation to use.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_julia_exe_path(self, path: Path) -&gt; None:\n    \"\"\"Set which Julia installation to use.\"\"\"\n    self._check_type(path, Path)\n    self._julia_exe_path = path\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_short_term_aggregations","title":"<code>set_short_term_aggregations(aggregators: list[Aggregator]) -&gt; None</code>","text":"<p>Set aggregations to create the short term model used in the price prognosis problems.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_short_term_aggregations(self, aggregators: list[Aggregator]) -&gt; None:\n    \"\"\"Set aggregations to create the short term model used in the price prognosis problems.\"\"\"\n    self._check_supported_aggregators(aggregators)\n    self._short_term_aggregations = aggregators\n</code></pre>"},{"location":"reference/#framjules.JulESConfig.JulESConfig.set_skipmax_days","title":"<code>set_skipmax_days(days: int) -&gt; None</code>","text":"<p>Set number of days between calculation of medium and long term storage values.</p> <p>This can speed up a simulation as medium and long term price prognosis problems, and long term storage value problems are solved less often. The cost is less good storage values. The longer between re-calculation of storage values, the bigger negative impact on simulation result quality.</p> <p>If skipmax_days = 6 and clearing_days = 2, JulES will calculate medium and long term storage values every 3rd simulation step.</p> <p>Short term price prognosis problems and storage values problems (i.e. for batteries) are not affected by this setting, and are calculated every simulation step.</p> Source code in <code>framjules/JulESConfig.py</code> <pre><code>def set_skipmax_days(self, days: int) -&gt; None:\n    \"\"\"Set number of days between calculation of medium and long term storage values.\n\n    This can speed up a simulation as medium and long term price prognosis problems, and long term\n    storage value problems are solved less often. The cost is less good storage values. The longer between\n    re-calculation of storage values, the bigger negative impact on simulation result quality.\n\n    If skipmax_days = 6 and clearing_days = 2, JulES will calculate medium and long\n    term storage values every 3rd simulation step.\n\n    Short term price prognosis problems and storage values problems (i.e. for batteries) are not affected by this\n    setting, and are calculated every simulation step.\n    \"\"\"\n    self._check_type(days, int)\n    self._check_int(days, lower_bound=0, upper_bound=None)\n    if days &gt; self._warn_skipmax_days:\n        message = (\n            \"Unusually high value for skipmax_days: \"\n            f\"Medium and long term storage values updated only {days}th day. \"\n            \"This can give poor simulation results due to poor storage utilization.\"\n        )\n        self.send_warning_event(message)\n    self._skipmax_days = days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution","title":"<code>JulESTimeResolution</code>","text":""},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution","title":"<code>JulESTimeResolution</code>","text":"<p>               Bases: <code>Base</code></p> <p>Time resolution settings for JulES (only some are modifiable).</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>class JulESTimeResolution(Base):\n    \"\"\"Time resolution settings for JulES (only some are modifiable).\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Create instance with default values.\"\"\"\n        self._target_med_days = 12 * 7\n        self._target_long_storage_days = 6 * 7\n        self._target_lookahead_days = 365 * 5\n        self._target_ev_days = 365 * 3\n\n        self._clearing_days = 2\n        self._short_days = 5\n\n        self._clearing_market_minutes = 60 * 3\n        self._clearing_storage_minutes = 60 * 24\n\n        self._short_market_minutes = self._get_incremented_divisor(\n            n=self._clearing_days * 24 * 60,\n            divisor=self._clearing_market_minutes,\n            num_increments=1,\n        )\n        self._short_storage_minutes = 60 * 24 * self._short_days\n\n        self._long_adaptive_blocks = 4\n        self._long_adaptive_hours = 6\n\n        self._med_adaptive_blocks = 4\n        self._med_adaptive_hours = 6\n\n        med_days, long_days, med_storage_days, long_storage_days = self._get_med_long_days_and_storage_days(\n            self._target_lookahead_days,\n            self._clearing_days,\n            self._short_days,\n        )\n\n        self._med_days = med_days\n        self._long_days = long_days\n        self._med_storage_days = med_storage_days\n        self._long_storage_days = long_storage_days\n\n    def set_target_ev_days(self, x: int) -&gt; None:\n        \"\"\"Set prefered value for length in days of end value problems.\n\n        Will choose a close valid value.\n        \"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n        self._target_ev_days = x\n\n    def set_target_long_storage_days(self, x: int) -&gt; None:\n        \"\"\"Set prefered value for long_storage_days.\n\n        Will choose a close valid value.\n        \"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n        self._target_long_storage_days = x\n\n    def set_target_med_days(self, x: int) -&gt; None:\n        \"\"\"Set prefered value for horizon length in days in medium prognosis problem.\n\n        Will choose a close valid value.\n        \"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n        self._target_med_num_period = x\n\n    def set_clearing_days(self, x: int) -&gt; None:\n        \"\"\"Set length of clearing problem in days.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n        self._clearing_days = x\n\n        clearing_minutes = self._clearing_days * 24 * 60\n\n        self._clearing_market_minutes = min(self._clearing_market_minutes, clearing_minutes)\n        self._clearing_storage_minutes = min(self._clearing_storage_minutes, clearing_minutes)\n\n        if clearing_minutes % self._clearing_market_minutes != 0:\n            message = (\n                f\"clearing_market_minutes ({self._clearing_market_minutes}) does not go up\"\n                f\" in clearing_days in minutes ({clearing_minutes}).\"\n            )\n            raise ValueError(message)\n\n        if clearing_minutes % self._clearing_storage_minutes != 0:\n            message = (\n                f\"clearing_storage_minutes ({self._clearing_storage_minutes}) does not go up\"\n                f\" in clearing_days in minutes ({clearing_minutes}).\"\n            )\n            raise ValueError(message)\n\n        self.set_target_lookahead_days(self._target_lookahead_days)\n\n    def set_short_days(self, x: int) -&gt; None:\n        \"\"\"Set length of short term prognosis problem in days.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n        self._short_days = x\n\n        short_minutes = self._short_days * 24 * 60\n\n        self._short_market_minutes = min(self._short_market_minutes, short_minutes)\n        self._short_storage_minutes = min(self._short_storage_minutes, short_minutes)\n\n        if short_minutes % self._short_market_minutes != 0:\n            message = (\n                f\"short_market_minutes ({self._short_market_minutes}) does not go up\"\n                f\" in short_days in minutes ({short_minutes}).\"\n            )\n            raise ValueError(message)\n\n        if short_minutes % self._short_storage_minutes != 0:\n            message = (\n                f\"short_storage_minutes ({self._short_storage_minutes}) does not go up\"\n                f\" in short_days in minutes ({short_minutes}).\"\n            )\n            raise ValueError(message)\n\n        self.set_target_lookahead_days(self._target_lookahead_days)\n\n    def set_target_lookahead_days(self, x: int) -&gt; None:\n        \"\"\"Set target length of prognosis problems in days.\n\n        Will set med_days and long_days and make sure their sum is minimum this length.\n\n        Will set short_days if target_lookahead_days &lt; short_days.\n        \"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n        self._target_lookahead_days = x\n\n        if x &lt; self._short_days:\n            self.set_short_days(x)\n\n        med_days, long_days, med_storage_days, long_storage_days = self._get_med_long_days_and_storage_days(\n            self._target_lookahead_days,\n            self._clearing_days,\n            self._short_days,\n        )\n\n        self._med_days = med_days\n        self._long_days = long_days\n        self._med_storage_days = med_storage_days\n        self._long_storage_days = long_storage_days\n\n    def set_clearing_market_minutes(self, x: int) -&gt; None:\n        \"\"\"Set market period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n        self._check_hourly(x)\n        self._clearing_market_minutes = x\n\n    def set_clearing_storage_minutes(self, x: int) -&gt; None:\n        \"\"\"Set storage period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n        self._clearing_storage_minutes = x\n\n    def set_short_market_minutes(self, x: int) -&gt; None:\n        \"\"\"Set market period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n        self._short_market_minutes = x\n\n    def set_short_storage_minutes(self, x: int) -&gt; None:\n        \"\"\"Set storage period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n        self._check_type(x, int)\n        self._check_int(value=x, lower_bound=1, upper_bound=None)\n        self._short_storage_minutes = x\n\n    def get_clearing_days(self) -&gt; int:\n        \"\"\"Get length of clearing problem in days.\"\"\"\n        return self._clearing_days\n\n    def get_short_days(self) -&gt; int:\n        \"\"\"Get length of short prognosis problem in days.\"\"\"\n        return self._short_days\n\n    def get_target_lookahead_days(self) -&gt; int:\n        \"\"\"Get target (minimum) length of prognosis problems in days.\"\"\"\n        return self._target_lookahead_days\n\n    def get_med_days(self) -&gt; int:\n        \"\"\"Get length of medium prognosis problem in days.\"\"\"\n        return self._med_days\n\n    def get_long_days(self) -&gt; int:\n        \"\"\"Get length of long prognosis problem in days.\"\"\"\n        return self._long_days\n\n    def get_med_storage_days(self) -&gt; int:\n        \"\"\"Get storage period length in medium prognosis problem in days.\"\"\"\n        return self._med_storage_days\n\n    def get_long_storage_days(self) -&gt; int:\n        \"\"\"Get storage period length in long prognosis problem in days.\"\"\"\n        return self._long_storage_days\n\n    def get_clearing_market_minutes(self) -&gt; int:\n        \"\"\"Get market period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n        return self._clearing_market_minutes\n\n    def get_clearing_storage_minutes(self) -&gt; int:\n        \"\"\"Get storage period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n        return self._clearing_storage_minutes\n\n    def get_short_market_minutes(self) -&gt; int:\n        \"\"\"Get market period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n        return self._short_market_minutes\n\n    def get_short_storage_minutes(self) -&gt; int:\n        \"\"\"Get storage period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n        return self._short_storage_minutes\n\n    def get_long_adaptive_blocks(self) -&gt; int:\n        \"\"\"Get number of market periods long prognosis problem.\"\"\"\n        return self._long_adaptive_blocks\n\n    def get_long_adaptive_hours(self) -&gt; int:\n        \"\"\"Get resolution in hours used in clustering of market period blocks in medium prognosis problem.\"\"\"\n        return self._long_adaptive_hours\n\n    def get_med_adaptive_blocks(self) -&gt; int:\n        \"\"\"Get number of market periods long prognosis problem.\"\"\"\n        return self._med_adaptive_blocks\n\n    def get_med_adaptive_hours(self) -&gt; int:\n        \"\"\"Get resolution in hours used in clustering of market period blocks in medium prognosis problem.\"\"\"\n        return self._med_adaptive_hours\n\n    def get_target_long_storage_days(self) -&gt; int:\n        \"\"\"Get prefered value for long_storage_days.\"\"\"\n        return self._target_long_storage_days\n\n    def get_target_med_days(self) -&gt; int:\n        \"\"\"Get prefered value for horizon length of medium prognosis problem.\"\"\"\n        return self._target_med_days\n\n    def get_target_ev_days(self) -&gt; int:\n        \"\"\"Get prefered value for horizon length of end value problem.\"\"\"\n        return self._target_ev_days\n\n    def get_ev_days(self) -&gt; int:\n        \"\"\"Get number of days in horizon of end value problems.\"\"\"\n        target_horizon_days = self.get_target_ev_days()\n        long_period_days = self.get_long_storage_days()\n        return math.ceil(target_horizon_days / long_period_days) * long_period_days\n\n    def get_content_dict(self) -&gt; dict[str, int]:\n        \"\"\"Return dict of all settings. Useful to get an overview.\"\"\"\n        return {\n            \"clearing_days\": self.get_clearing_days(),\n            \"short_days\": self.get_short_days(),\n            \"med_days\": self.get_med_days(),\n            \"long_days\": self.get_long_days(),\n            \"long_storage_days\": self.get_long_storage_days(),\n            \"med_storage_days\": self.get_med_storage_days(),\n            \"clearing_market_minutes\": self.get_clearing_market_minutes(),\n            \"clearing_storage_minutes\": self.get_clearing_storage_minutes(),\n            \"short_market_minutes\": self.get_short_market_minutes(),\n            \"short_storage_minutes\": self.get_short_storage_minutes(),\n            \"long_adaptive_blocks\": self.get_long_adaptive_blocks(),\n            \"long_adaptive_hours\": self.get_long_adaptive_hours(),\n            \"med_adaptive_blocks\": self.get_med_adaptive_blocks(),\n            \"med_adaptive_hours\": self.get_med_adaptive_hours(),\n            \"target_lookahead_days\": self.get_target_lookahead_days(),\n            \"target_long_storage_days\": self.get_target_long_storage_days(),\n            \"target_med_days\": self.get_target_med_days(),\n            \"target_ev_days\": self.get_target_ev_days(),\n            \"ev_days\": self.get_ev_days(),\n        }\n\n    def _get_med_long_days_and_storage_days(\n        self,\n        target_lookahead_days: int,\n        clearing_days: int,\n        short_days: int,\n    ) -&gt; tuple[int, int, int, int]:\n        \"\"\"Find the valid configuration that is closest to the user supplied targets.\"\"\"\n        med_period = clearing_days + short_days\n\n        possible_med_pairs = self._get_possible_med_pairs(med_period, target_lookahead_days, short_days)\n\n        if not possible_med_pairs:\n            return tuple([clearing_days + short_days] * 4)\n\n        candidates = set()\n        for med_period, med_num_periods in possible_med_pairs:\n            possible_long_pairs = self._get_possible_long_pairs(\n                med_period,\n                med_num_periods,\n                target_lookahead_days,\n                short_days,\n            )\n            for long_period, long_num_periods in possible_long_pairs:\n                med_days = med_period * med_num_periods\n                long_days = long_period * long_num_periods\n                candidate = (med_days, long_days, med_period, long_period)\n                candidates.add(candidate)\n\n        target_med_days = self.get_target_med_days()\n        target_long_storage_days = self.get_target_long_storage_days()\n\n        def distance_from_targets(candidate: tuple[int, int, int, int]) -&gt; float | int:\n            med_days = candidate[0]\n            long_storage_days = candidate[3]\n            med_square_diff = (target_med_days - med_days) ** 2\n            long_square_diff = (target_long_storage_days - long_storage_days) ** 2\n            return med_square_diff + long_square_diff\n\n        return min(candidates, key=distance_from_targets)\n\n    def _get_possible_med_pairs(\n        self,\n        med_period: int,\n        target_lookahead_days: int,\n        short_days: int,\n    ) -&gt; list[tuple[int, int]]:\n        \"\"\"Fuzz number of med storage periods to get more candidates.\"\"\"\n        target_med_days = self.get_target_med_days()\n        out = []\n        n = math.ceil(target_med_days / med_period)\n        for m in [n - 1, n, n + 1]:\n            implied_target_lookahead_days = med_period * (m + 1) + short_days\n            if m &gt; 1 and implied_target_lookahead_days &lt;= target_lookahead_days:\n                out.append((med_period, m))\n        return out\n\n    def _get_possible_long_pairs(\n        self,\n        med_period: int,\n        med_num_periods: int,\n        target_lookahead_days: int,\n        short_days: int,\n    ) -&gt; list[tuple[int, int]]:\n        \"\"\"Find valid long pairs. Valid if long_period is divisor of med_days.\"\"\"\n        target_long_storage_days = self.get_target_long_storage_days()\n        med_days = med_period * med_num_periods\n        divisors = self._get_divisors(med_days)\n        divisors = sorted(divisors, key=lambda x: abs(target_long_storage_days - x))\n        divisors = divisors[:4]\n        out = []\n        for long_period in divisors:\n            long_num_periods = math.ceil(max(1, target_lookahead_days - med_days - short_days) / long_period)\n            out.append((long_period, long_num_periods))\n        return out\n\n    def _get_divisors(self, n: int) -&gt; list[int]:\n        \"\"\"Return sorted list of divisors of n.\n\n        Inspiration from: https://stackoverflow.com/questions/171765/what-is-the-best-way-to-get-all-the-divisors-of-a-number\n        \"\"\"\n        divs = [1]\n        for i in range(2, int(math.sqrt(n)) + 1):\n            if n % i == 0:\n                divs.extend([i, int(n / i)])\n        divs.extend([n])\n        return sorted(list(set(divs)))\n\n    def _get_incremented_divisor(self, n: int, divisor: int, num_increments: int) -&gt; int:\n        \"\"\"Get divisor of n num_increments greater than k if &lt;= n else n.\"\"\"\n        divs = self._get_divisors(n)\n        try:\n            i = divs.index(divisor)\n        except ValueError:\n            message = f\"{divisor} is not a divisor of {n}.\"\n            raise ValueError(message) from None\n        return divs[min(i + num_increments, len(divs) - 1)]\n\n    def _check_hourly(self, x: int) -&gt; None:\n        if not (x / 60).is_integer():\n            message = \"Currently, JulES only support hourly resolutions.\"\n            raise ValueError(message)\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Create instance with default values.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Create instance with default values.\"\"\"\n    self._target_med_days = 12 * 7\n    self._target_long_storage_days = 6 * 7\n    self._target_lookahead_days = 365 * 5\n    self._target_ev_days = 365 * 3\n\n    self._clearing_days = 2\n    self._short_days = 5\n\n    self._clearing_market_minutes = 60 * 3\n    self._clearing_storage_minutes = 60 * 24\n\n    self._short_market_minutes = self._get_incremented_divisor(\n        n=self._clearing_days * 24 * 60,\n        divisor=self._clearing_market_minutes,\n        num_increments=1,\n    )\n    self._short_storage_minutes = 60 * 24 * self._short_days\n\n    self._long_adaptive_blocks = 4\n    self._long_adaptive_hours = 6\n\n    self._med_adaptive_blocks = 4\n    self._med_adaptive_hours = 6\n\n    med_days, long_days, med_storage_days, long_storage_days = self._get_med_long_days_and_storage_days(\n        self._target_lookahead_days,\n        self._clearing_days,\n        self._short_days,\n    )\n\n    self._med_days = med_days\n    self._long_days = long_days\n    self._med_storage_days = med_storage_days\n    self._long_storage_days = long_storage_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_clearing_days","title":"<code>get_clearing_days() -&gt; int</code>","text":"<p>Get length of clearing problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_clearing_days(self) -&gt; int:\n    \"\"\"Get length of clearing problem in days.\"\"\"\n    return self._clearing_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_clearing_market_minutes","title":"<code>get_clearing_market_minutes() -&gt; int</code>","text":"<p>Get market period length in clearing problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_clearing_market_minutes(self) -&gt; int:\n    \"\"\"Get market period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n    return self._clearing_market_minutes\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_clearing_storage_minutes","title":"<code>get_clearing_storage_minutes() -&gt; int</code>","text":"<p>Get storage period length in clearing problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_clearing_storage_minutes(self) -&gt; int:\n    \"\"\"Get storage period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n    return self._clearing_storage_minutes\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_content_dict","title":"<code>get_content_dict() -&gt; dict[str, int]</code>","text":"<p>Return dict of all settings. Useful to get an overview.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_content_dict(self) -&gt; dict[str, int]:\n    \"\"\"Return dict of all settings. Useful to get an overview.\"\"\"\n    return {\n        \"clearing_days\": self.get_clearing_days(),\n        \"short_days\": self.get_short_days(),\n        \"med_days\": self.get_med_days(),\n        \"long_days\": self.get_long_days(),\n        \"long_storage_days\": self.get_long_storage_days(),\n        \"med_storage_days\": self.get_med_storage_days(),\n        \"clearing_market_minutes\": self.get_clearing_market_minutes(),\n        \"clearing_storage_minutes\": self.get_clearing_storage_minutes(),\n        \"short_market_minutes\": self.get_short_market_minutes(),\n        \"short_storage_minutes\": self.get_short_storage_minutes(),\n        \"long_adaptive_blocks\": self.get_long_adaptive_blocks(),\n        \"long_adaptive_hours\": self.get_long_adaptive_hours(),\n        \"med_adaptive_blocks\": self.get_med_adaptive_blocks(),\n        \"med_adaptive_hours\": self.get_med_adaptive_hours(),\n        \"target_lookahead_days\": self.get_target_lookahead_days(),\n        \"target_long_storage_days\": self.get_target_long_storage_days(),\n        \"target_med_days\": self.get_target_med_days(),\n        \"target_ev_days\": self.get_target_ev_days(),\n        \"ev_days\": self.get_ev_days(),\n    }\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_ev_days","title":"<code>get_ev_days() -&gt; int</code>","text":"<p>Get number of days in horizon of end value problems.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_ev_days(self) -&gt; int:\n    \"\"\"Get number of days in horizon of end value problems.\"\"\"\n    target_horizon_days = self.get_target_ev_days()\n    long_period_days = self.get_long_storage_days()\n    return math.ceil(target_horizon_days / long_period_days) * long_period_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_long_adaptive_blocks","title":"<code>get_long_adaptive_blocks() -&gt; int</code>","text":"<p>Get number of market periods long prognosis problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_long_adaptive_blocks(self) -&gt; int:\n    \"\"\"Get number of market periods long prognosis problem.\"\"\"\n    return self._long_adaptive_blocks\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_long_adaptive_hours","title":"<code>get_long_adaptive_hours() -&gt; int</code>","text":"<p>Get resolution in hours used in clustering of market period blocks in medium prognosis problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_long_adaptive_hours(self) -&gt; int:\n    \"\"\"Get resolution in hours used in clustering of market period blocks in medium prognosis problem.\"\"\"\n    return self._long_adaptive_hours\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_long_days","title":"<code>get_long_days() -&gt; int</code>","text":"<p>Get length of long prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_long_days(self) -&gt; int:\n    \"\"\"Get length of long prognosis problem in days.\"\"\"\n    return self._long_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_long_storage_days","title":"<code>get_long_storage_days() -&gt; int</code>","text":"<p>Get storage period length in long prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_long_storage_days(self) -&gt; int:\n    \"\"\"Get storage period length in long prognosis problem in days.\"\"\"\n    return self._long_storage_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_med_adaptive_blocks","title":"<code>get_med_adaptive_blocks() -&gt; int</code>","text":"<p>Get number of market periods long prognosis problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_med_adaptive_blocks(self) -&gt; int:\n    \"\"\"Get number of market periods long prognosis problem.\"\"\"\n    return self._med_adaptive_blocks\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_med_adaptive_hours","title":"<code>get_med_adaptive_hours() -&gt; int</code>","text":"<p>Get resolution in hours used in clustering of market period blocks in medium prognosis problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_med_adaptive_hours(self) -&gt; int:\n    \"\"\"Get resolution in hours used in clustering of market period blocks in medium prognosis problem.\"\"\"\n    return self._med_adaptive_hours\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_med_days","title":"<code>get_med_days() -&gt; int</code>","text":"<p>Get length of medium prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_med_days(self) -&gt; int:\n    \"\"\"Get length of medium prognosis problem in days.\"\"\"\n    return self._med_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_med_storage_days","title":"<code>get_med_storage_days() -&gt; int</code>","text":"<p>Get storage period length in medium prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_med_storage_days(self) -&gt; int:\n    \"\"\"Get storage period length in medium prognosis problem in days.\"\"\"\n    return self._med_storage_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_short_days","title":"<code>get_short_days() -&gt; int</code>","text":"<p>Get length of short prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_short_days(self) -&gt; int:\n    \"\"\"Get length of short prognosis problem in days.\"\"\"\n    return self._short_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_short_market_minutes","title":"<code>get_short_market_minutes() -&gt; int</code>","text":"<p>Get market period length in short prognosis problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_short_market_minutes(self) -&gt; int:\n    \"\"\"Get market period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n    return self._short_market_minutes\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_short_storage_minutes","title":"<code>get_short_storage_minutes() -&gt; int</code>","text":"<p>Get storage period length in short prognosis problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_short_storage_minutes(self) -&gt; int:\n    \"\"\"Get storage period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n    return self._short_storage_minutes\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_target_ev_days","title":"<code>get_target_ev_days() -&gt; int</code>","text":"<p>Get prefered value for horizon length of end value problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_target_ev_days(self) -&gt; int:\n    \"\"\"Get prefered value for horizon length of end value problem.\"\"\"\n    return self._target_ev_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_target_long_storage_days","title":"<code>get_target_long_storage_days() -&gt; int</code>","text":"<p>Get prefered value for long_storage_days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_target_long_storage_days(self) -&gt; int:\n    \"\"\"Get prefered value for long_storage_days.\"\"\"\n    return self._target_long_storage_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_target_lookahead_days","title":"<code>get_target_lookahead_days() -&gt; int</code>","text":"<p>Get target (minimum) length of prognosis problems in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_target_lookahead_days(self) -&gt; int:\n    \"\"\"Get target (minimum) length of prognosis problems in days.\"\"\"\n    return self._target_lookahead_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.get_target_med_days","title":"<code>get_target_med_days() -&gt; int</code>","text":"<p>Get prefered value for horizon length of medium prognosis problem.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def get_target_med_days(self) -&gt; int:\n    \"\"\"Get prefered value for horizon length of medium prognosis problem.\"\"\"\n    return self._target_med_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_clearing_days","title":"<code>set_clearing_days(x: int) -&gt; None</code>","text":"<p>Set length of clearing problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_clearing_days(self, x: int) -&gt; None:\n    \"\"\"Set length of clearing problem in days.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n    self._clearing_days = x\n\n    clearing_minutes = self._clearing_days * 24 * 60\n\n    self._clearing_market_minutes = min(self._clearing_market_minutes, clearing_minutes)\n    self._clearing_storage_minutes = min(self._clearing_storage_minutes, clearing_minutes)\n\n    if clearing_minutes % self._clearing_market_minutes != 0:\n        message = (\n            f\"clearing_market_minutes ({self._clearing_market_minutes}) does not go up\"\n            f\" in clearing_days in minutes ({clearing_minutes}).\"\n        )\n        raise ValueError(message)\n\n    if clearing_minutes % self._clearing_storage_minutes != 0:\n        message = (\n            f\"clearing_storage_minutes ({self._clearing_storage_minutes}) does not go up\"\n            f\" in clearing_days in minutes ({clearing_minutes}).\"\n        )\n        raise ValueError(message)\n\n    self.set_target_lookahead_days(self._target_lookahead_days)\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_clearing_market_minutes","title":"<code>set_clearing_market_minutes(x: int) -&gt; None</code>","text":"<p>Set market period length in clearing problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_clearing_market_minutes(self, x: int) -&gt; None:\n    \"\"\"Set market period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n    self._check_hourly(x)\n    self._clearing_market_minutes = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_clearing_storage_minutes","title":"<code>set_clearing_storage_minutes(x: int) -&gt; None</code>","text":"<p>Set storage period length in clearing problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_clearing_storage_minutes(self, x: int) -&gt; None:\n    \"\"\"Set storage period length in clearing problem in minutes. Currently only support whole hours.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n    self._clearing_storage_minutes = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_short_days","title":"<code>set_short_days(x: int) -&gt; None</code>","text":"<p>Set length of short term prognosis problem in days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_short_days(self, x: int) -&gt; None:\n    \"\"\"Set length of short term prognosis problem in days.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n    self._short_days = x\n\n    short_minutes = self._short_days * 24 * 60\n\n    self._short_market_minutes = min(self._short_market_minutes, short_minutes)\n    self._short_storage_minutes = min(self._short_storage_minutes, short_minutes)\n\n    if short_minutes % self._short_market_minutes != 0:\n        message = (\n            f\"short_market_minutes ({self._short_market_minutes}) does not go up\"\n            f\" in short_days in minutes ({short_minutes}).\"\n        )\n        raise ValueError(message)\n\n    if short_minutes % self._short_storage_minutes != 0:\n        message = (\n            f\"short_storage_minutes ({self._short_storage_minutes}) does not go up\"\n            f\" in short_days in minutes ({short_minutes}).\"\n        )\n        raise ValueError(message)\n\n    self.set_target_lookahead_days(self._target_lookahead_days)\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_short_market_minutes","title":"<code>set_short_market_minutes(x: int) -&gt; None</code>","text":"<p>Set market period length in short prognosis problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_short_market_minutes(self, x: int) -&gt; None:\n    \"\"\"Set market period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n    self._short_market_minutes = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_short_storage_minutes","title":"<code>set_short_storage_minutes(x: int) -&gt; None</code>","text":"<p>Set storage period length in short prognosis problem in minutes. Currently only support whole hours.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_short_storage_minutes(self, x: int) -&gt; None:\n    \"\"\"Set storage period length in short prognosis problem in minutes. Currently only support whole hours.\"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n    self._short_storage_minutes = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_target_ev_days","title":"<code>set_target_ev_days(x: int) -&gt; None</code>","text":"<p>Set prefered value for length in days of end value problems.</p> <p>Will choose a close valid value.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_target_ev_days(self, x: int) -&gt; None:\n    \"\"\"Set prefered value for length in days of end value problems.\n\n    Will choose a close valid value.\n    \"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n    self._target_ev_days = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_target_long_storage_days","title":"<code>set_target_long_storage_days(x: int) -&gt; None</code>","text":"<p>Set prefered value for long_storage_days.</p> <p>Will choose a close valid value.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_target_long_storage_days(self, x: int) -&gt; None:\n    \"\"\"Set prefered value for long_storage_days.\n\n    Will choose a close valid value.\n    \"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n    self._target_long_storage_days = x\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_target_lookahead_days","title":"<code>set_target_lookahead_days(x: int) -&gt; None</code>","text":"<p>Set target length of prognosis problems in days.</p> <p>Will set med_days and long_days and make sure their sum is minimum this length.</p> <p>Will set short_days if target_lookahead_days &lt; short_days.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_target_lookahead_days(self, x: int) -&gt; None:\n    \"\"\"Set target length of prognosis problems in days.\n\n    Will set med_days and long_days and make sure their sum is minimum this length.\n\n    Will set short_days if target_lookahead_days &lt; short_days.\n    \"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=1, upper_bound=None)\n\n    self._target_lookahead_days = x\n\n    if x &lt; self._short_days:\n        self.set_short_days(x)\n\n    med_days, long_days, med_storage_days, long_storage_days = self._get_med_long_days_and_storage_days(\n        self._target_lookahead_days,\n        self._clearing_days,\n        self._short_days,\n    )\n\n    self._med_days = med_days\n    self._long_days = long_days\n    self._med_storage_days = med_storage_days\n    self._long_storage_days = long_storage_days\n</code></pre>"},{"location":"reference/#framjules.JulESTimeResolution.JulESTimeResolution.set_target_med_days","title":"<code>set_target_med_days(x: int) -&gt; None</code>","text":"<p>Set prefered value for horizon length in days in medium prognosis problem.</p> <p>Will choose a close valid value.</p> Source code in <code>framjules/JulESTimeResolution.py</code> <pre><code>def set_target_med_days(self, x: int) -&gt; None:\n    \"\"\"Set prefered value for horizon length in days in medium prognosis problem.\n\n    Will choose a close valid value.\n    \"\"\"\n    self._check_type(x, int)\n    self._check_int(value=x, lower_bound=self._clearing_days + self._short_days, upper_bound=None)\n    self._target_med_num_period = x\n</code></pre>"},{"location":"reference/#framjules.loaders","title":"<code>loaders</code>","text":""},{"location":"reference/#framjules.loaders.time_vector_loaders","title":"<code>time_vector_loaders</code>","text":""},{"location":"reference/#framjules.loaders.time_vector_loaders.DemandJulESH5TimeVectorLoader","title":"<code>DemandJulESH5TimeVectorLoader</code>","text":"<p>               Bases: <code>JulESH5TimeVectorLoader</code></p> <p>Workaround to get demand results and at the same time avoid name conflicts.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>class DemandJulESH5TimeVectorLoader(JulESH5TimeVectorLoader):\n    \"\"\"Workaround to get demand results and at the same time avoid name conflicts.\"\"\"\n\n    _SUPPORTED_SUFFIXES: ClassVar[list] = [\".h5\"]\n    _SEARCH_FIELDS: ClassVar[list] = [\n        (\"demandnames\", \"priceindex\", \"demandvalues\", True),\n    ]\n    _DEFAULT_INDEX = \"priceindex\"\n    pass\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader","title":"<code>JulESH5TimeVectorLoader</code>","text":"<p>               Bases: <code>FileLoader</code>, <code>TimeVectorLoader</code></p> <p>Loader for JulES H5 files containing time vectors.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>class JulESH5TimeVectorLoader(FileLoader, TimeVectorLoader):\n    \"\"\"Loader for JulES H5 files containing time vectors.\"\"\"\n\n    _SUPPORTED_SUFFIXES: ClassVar[list] = [\".h5\"]\n    # find time vector id in one of the names, then use the corresponding names to get the data\n    _SEARCH_FIELDS: ClassVar[list] = [\n        (\"areanames\", \"priceindex\", \"pricematrix\", True),\n        (\"batnames\", \"batindex\", \"batmatrix\", True),\n        (\"resnames\", \"resindex\", \"resmatrix_water\", True),\n        (\"othernames_Vars_Power\", \"priceindex\", \"othervalues_Vars_Power\", True),\n        (\"othernames_Vars_Hydro\", \"resindex\", \"othervalues_Vars_Hydro\", True),\n        (\n            \"storagenames\",\n            \"stateindex\",\n            \"storagevalues_main\",\n            True,\n        ),\n    ]\n    _DEFAULT_INDEX = \"priceindex\"\n\n    def __init__(\n        self,\n        source: Path | str,\n        units: dict[str, str],\n        relative_loc: Path | str | None = None,\n        is_whole_years: bool = False,\n    ) -&gt; None:\n        \"\"\"Initialize the NVEH5TimeVectorLoader.\"\"\"\n        super().__init__(source, relative_loc)\n        self._data: dict[str, NDArray] = {}\n        self._index: dict[str, TimeIndex] = {}\n        self._units: dict[str, str] = units\n        self._is_whole_years = is_whole_years\n\n        self._id_fields_map: dict[str, list[set]] = {}\n\n    def clear_cache(self) -&gt; None:\n        \"\"\"Clear cached data.\"\"\"\n        self._data = {}\n        self._index = {}\n        self._id_fields_map = {}\n\n    def get_reference_period(self, vector_id: str) -&gt; None:\n        \"\"\"Return None.\"\"\"\n        return\n\n    def is_max_level(self, vector_id: str) -&gt; None:\n        \"\"\"Return None.\"\"\"\n        return\n\n    def is_zero_one_profile(self, vector_id: str) -&gt; None:\n        \"\"\"Return None.\"\"\"\n        return True\n\n    def get_values(self, vector_id: str) -&gt; NDArray:\n        \"\"\"Find the values for a given vector id.\n\n        Args:\n            vector_id: (str)\n\n        Returns:\n            NDArray: Values for the vector id.\n\n        \"\"\"\n        self._id_exsists(vector_id)\n        self._check_multiple_fields(vector_id)\n        if vector_id not in self._data:\n            id_field, values_field = self._get_id_values_field(vector_id)\n            with h5py.File(self.get_source(), \"r\") as f:\n                ids = np.array([item.decode() for item in f[id_field]])\n                values_matrix = np.array(f[values_field])\n                new_data = {id_: values_matrix[i, :] for i, id_ in enumerate(ids)}\n                self._data.update(new_data)\n        # index may not use all values\n        index = self.get_index(vector_id)\n        vector = self._data[vector_id]\n        n = index.get_num_periods()\n        return vector[:n]\n\n    def get_index(self, vector_id: str) -&gt; TimeIndex:\n        \"\"\"Find the time index for a given vector id.\n\n        Args:\n            vector_id: (str)\n\n        Returns:\n            TimeIndex\n\n        \"\"\"\n        self._id_exsists(vector_id)  # calls get_ids which calls _get_ids which sets _id_fields_map\n        self._check_multiple_fields(vector_id)  # therefore we can use this afterwards\n        with h5py.File(self.get_source(), \"r\") as f:\n            index_field = self._id_fields_map.get(vector_id)[0][1]\n            fmt = \"%Y-%m-%dT%H:%M:%S\"\n            if self._index is None or (index_field not in self._index):\n                t0 = datetime.strptime(f[index_field][0].decode(), fmt)\n                t1 = datetime.strptime(f[index_field][1].decode(), fmt)\n                index = FixedFrequencyTimeIndex(\n                    start_time=t0,\n                    period_duration=t1 - t0,\n                    num_periods=len(f[index_field]),\n                    is_52_week_years=False,\n                    extrapolate_first_point=False,\n                    extrapolate_last_point=False,\n                )\n                if not index.is_whole_years() and self._is_whole_years:\n                    # start time for each period\n                    datetime_list = [datetime.strptime(x.decode(), fmt) for x in f[index_field]]\n                    period_duration = datetime_list[1] - datetime_list[0]\n\n                    # add end index since JulES index represents periods\n                    datetime_list.append(datetime_list[-1] + period_duration)\n                    num_periods = len(datetime_list)\n\n                    # find last index before new iso year\n                    last_in_year_ix = num_periods - 1\n                    while last_in_year_ix &gt;= 0:\n                        last_in_year_ix -= 1\n                        this_period = datetime_list[last_in_year_ix]\n                        next_period = this_period + period_duration\n                        this_year = this_period.isocalendar().year\n                        next_year = next_period.isocalendar().year\n                        if next_year &gt; this_year:\n                            break\n\n                    last_in_year = datetime_list[last_in_year_ix]\n\n                    first_next_year = last_in_year.fromisocalendar(last_in_year.isocalendar().year + 1, 1, 1)\n\n                    if last_in_year + period_duration == first_next_year:\n                        index = FixedFrequencyTimeIndex(\n                            start_time=datetime_list[0],\n                            period_duration=period_duration,\n                            num_periods=last_in_year_ix + 1,\n                            is_52_week_years=False,\n                            extrapolate_first_point=False,\n                            extrapolate_last_point=False,\n                        )\n                    elif last_in_year + period_duration &gt; first_next_year:\n                        # TODO: test (only reachable without profiles as ProfileTimeIndex enforces whole years)\n                        datetime_list[last_in_year_ix + 1] = first_next_year\n                        del datetime_list[last_in_year_ix + 2 :]  # (slice delete does not error when out-of-bounds)\n                        index = ListTimeIndex(\n                            datetime_list=datetime_list,\n                            is_52_week_years=False,\n                            extrapolate_first_point=False,\n                            extrapolate_last_point=False,\n                        )\n                    else:\n                        n = last_in_year_ix\n                        message = (\n                            f\"Unexpected last_in_year + period_duration &lt; first_next_year.\\n\"\n                            f\"vector_id = {vector_id}\\n\"\n                            f\"last_in_year = {last_in_year}\\n\"\n                            f\"period_duration = {period_duration}\\n\"\n                            f\"first_next_year = {first_next_year}\\n\"\n                            f\"datetime_list around last_in_year_ix = {datetime_list[n - 10 : n + 10]}\"\n                        )\n                        raise RuntimeError(message)\n\n                self._index[index_field] = index\n        return self._index[index_field]\n\n    def get_unit(self, vector_id: str) -&gt; str:\n        \"\"\"Get the unit of the time vector.\"\"\"\n        return self._units[vector_id]\n\n    def get_metadata(self) -&gt; str:\n        \"\"\"Get metadata from the file.\"\"\"\n        return \"\"\n\n    def _get_id_values_field(self, vector_id: str) -&gt; str:\n        search_fields = self._id_fields_map.get(vector_id)\n        return search_fields[0][0], search_fields[0][2]\n\n    def _get_ids(self) -&gt; list[str]:\n        if not self._id_fields_map:\n            self._create_id_fields_map()\n        return list(self._id_fields_map.keys())\n\n    def _create_id_fields_map(self) -&gt; dict[str, list[str]]:\n        if not self._id_fields_map:\n            self._id_fields_map: dict[str, list[str]] = dict()\n            with h5py.File(self.get_source(), \"r\") as f:\n                for search_name in self._SEARCH_FIELDS:\n                    if search_name[0] in f:\n                        new_ids = [item.decode() for item in f[search_name[0]]]\n                        for vector_id in new_ids:\n                            if vector_id not in self._id_fields_map:\n                                self._id_fields_map[vector_id] = [search_name]\n                            else:\n                                self._id_fields_map[vector_id].append(search_name)\n\n    def _check_multiple_fields(self, vector_id: str) -&gt; None:\n        self._create_id_fields_map()\n        # check if the vector id is found in multiple fields.\n        if len(self._id_fields_map[vector_id]) &gt; 1:\n            msg = (\n                f\"Vector ID {vector_id} found in multiple fields: {self._id_fields_map[vector_id]}. \"\n                \"Could not determine which field to use.\"\n            )\n            raise NotImplementedError(msg)\n\n    def get_fingerprint(self) -&gt; Fingerprint:\n        \"\"\"Get the fingerprint of the NVEH5TimeVectorLoader.\"\"\"\n        return None\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Check if self and other are equal.\"\"\"\n        if not isinstance(other, type(self)):\n            return False\n        return self.get_source() == other.get_source() and self._SEARCH_FIELDS == other._SEARCH_FIELDS\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return hash of NVEH5TimeVectorLoader object.\"\"\"\n        return hash(\n            (\n                self.get_source(),\n                frozenset(self._SEARCH_FIELDS),\n            ),\n        )\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.__eq__","title":"<code>__eq__(other: object) -&gt; bool</code>","text":"<p>Check if self and other are equal.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Check if self and other are equal.\"\"\"\n    if not isinstance(other, type(self)):\n        return False\n    return self.get_source() == other.get_source() and self._SEARCH_FIELDS == other._SEARCH_FIELDS\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.__hash__","title":"<code>__hash__() -&gt; int</code>","text":"<p>Return hash of NVEH5TimeVectorLoader object.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return hash of NVEH5TimeVectorLoader object.\"\"\"\n    return hash(\n        (\n            self.get_source(),\n            frozenset(self._SEARCH_FIELDS),\n        ),\n    )\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.__init__","title":"<code>__init__(source: Path | str, units: dict[str, str], relative_loc: Path | str | None = None, is_whole_years: bool = False) -&gt; None</code>","text":"<p>Initialize the NVEH5TimeVectorLoader.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def __init__(\n    self,\n    source: Path | str,\n    units: dict[str, str],\n    relative_loc: Path | str | None = None,\n    is_whole_years: bool = False,\n) -&gt; None:\n    \"\"\"Initialize the NVEH5TimeVectorLoader.\"\"\"\n    super().__init__(source, relative_loc)\n    self._data: dict[str, NDArray] = {}\n    self._index: dict[str, TimeIndex] = {}\n    self._units: dict[str, str] = units\n    self._is_whole_years = is_whole_years\n\n    self._id_fields_map: dict[str, list[set]] = {}\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.clear_cache","title":"<code>clear_cache() -&gt; None</code>","text":"<p>Clear cached data.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def clear_cache(self) -&gt; None:\n    \"\"\"Clear cached data.\"\"\"\n    self._data = {}\n    self._index = {}\n    self._id_fields_map = {}\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_fingerprint","title":"<code>get_fingerprint() -&gt; Fingerprint</code>","text":"<p>Get the fingerprint of the NVEH5TimeVectorLoader.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_fingerprint(self) -&gt; Fingerprint:\n    \"\"\"Get the fingerprint of the NVEH5TimeVectorLoader.\"\"\"\n    return None\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_index","title":"<code>get_index(vector_id: str) -&gt; TimeIndex</code>","text":"<p>Find the time index for a given vector id.</p> <p>Parameters:</p> Name Type Description Default <code>vector_id</code> <code>str</code> <p>(str)</p> required <p>Returns:</p> Type Description <code>TimeIndex</code> <p>TimeIndex</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_index(self, vector_id: str) -&gt; TimeIndex:\n    \"\"\"Find the time index for a given vector id.\n\n    Args:\n        vector_id: (str)\n\n    Returns:\n        TimeIndex\n\n    \"\"\"\n    self._id_exsists(vector_id)  # calls get_ids which calls _get_ids which sets _id_fields_map\n    self._check_multiple_fields(vector_id)  # therefore we can use this afterwards\n    with h5py.File(self.get_source(), \"r\") as f:\n        index_field = self._id_fields_map.get(vector_id)[0][1]\n        fmt = \"%Y-%m-%dT%H:%M:%S\"\n        if self._index is None or (index_field not in self._index):\n            t0 = datetime.strptime(f[index_field][0].decode(), fmt)\n            t1 = datetime.strptime(f[index_field][1].decode(), fmt)\n            index = FixedFrequencyTimeIndex(\n                start_time=t0,\n                period_duration=t1 - t0,\n                num_periods=len(f[index_field]),\n                is_52_week_years=False,\n                extrapolate_first_point=False,\n                extrapolate_last_point=False,\n            )\n            if not index.is_whole_years() and self._is_whole_years:\n                # start time for each period\n                datetime_list = [datetime.strptime(x.decode(), fmt) for x in f[index_field]]\n                period_duration = datetime_list[1] - datetime_list[0]\n\n                # add end index since JulES index represents periods\n                datetime_list.append(datetime_list[-1] + period_duration)\n                num_periods = len(datetime_list)\n\n                # find last index before new iso year\n                last_in_year_ix = num_periods - 1\n                while last_in_year_ix &gt;= 0:\n                    last_in_year_ix -= 1\n                    this_period = datetime_list[last_in_year_ix]\n                    next_period = this_period + period_duration\n                    this_year = this_period.isocalendar().year\n                    next_year = next_period.isocalendar().year\n                    if next_year &gt; this_year:\n                        break\n\n                last_in_year = datetime_list[last_in_year_ix]\n\n                first_next_year = last_in_year.fromisocalendar(last_in_year.isocalendar().year + 1, 1, 1)\n\n                if last_in_year + period_duration == first_next_year:\n                    index = FixedFrequencyTimeIndex(\n                        start_time=datetime_list[0],\n                        period_duration=period_duration,\n                        num_periods=last_in_year_ix + 1,\n                        is_52_week_years=False,\n                        extrapolate_first_point=False,\n                        extrapolate_last_point=False,\n                    )\n                elif last_in_year + period_duration &gt; first_next_year:\n                    # TODO: test (only reachable without profiles as ProfileTimeIndex enforces whole years)\n                    datetime_list[last_in_year_ix + 1] = first_next_year\n                    del datetime_list[last_in_year_ix + 2 :]  # (slice delete does not error when out-of-bounds)\n                    index = ListTimeIndex(\n                        datetime_list=datetime_list,\n                        is_52_week_years=False,\n                        extrapolate_first_point=False,\n                        extrapolate_last_point=False,\n                    )\n                else:\n                    n = last_in_year_ix\n                    message = (\n                        f\"Unexpected last_in_year + period_duration &lt; first_next_year.\\n\"\n                        f\"vector_id = {vector_id}\\n\"\n                        f\"last_in_year = {last_in_year}\\n\"\n                        f\"period_duration = {period_duration}\\n\"\n                        f\"first_next_year = {first_next_year}\\n\"\n                        f\"datetime_list around last_in_year_ix = {datetime_list[n - 10 : n + 10]}\"\n                    )\n                    raise RuntimeError(message)\n\n            self._index[index_field] = index\n    return self._index[index_field]\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_metadata","title":"<code>get_metadata() -&gt; str</code>","text":"<p>Get metadata from the file.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_metadata(self) -&gt; str:\n    \"\"\"Get metadata from the file.\"\"\"\n    return \"\"\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_reference_period","title":"<code>get_reference_period(vector_id: str) -&gt; None</code>","text":"<p>Return None.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_reference_period(self, vector_id: str) -&gt; None:\n    \"\"\"Return None.\"\"\"\n    return\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_unit","title":"<code>get_unit(vector_id: str) -&gt; str</code>","text":"<p>Get the unit of the time vector.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_unit(self, vector_id: str) -&gt; str:\n    \"\"\"Get the unit of the time vector.\"\"\"\n    return self._units[vector_id]\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.get_values","title":"<code>get_values(vector_id: str) -&gt; NDArray</code>","text":"<p>Find the values for a given vector id.</p> <p>Parameters:</p> Name Type Description Default <code>vector_id</code> <code>str</code> <p>(str)</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Values for the vector id.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def get_values(self, vector_id: str) -&gt; NDArray:\n    \"\"\"Find the values for a given vector id.\n\n    Args:\n        vector_id: (str)\n\n    Returns:\n        NDArray: Values for the vector id.\n\n    \"\"\"\n    self._id_exsists(vector_id)\n    self._check_multiple_fields(vector_id)\n    if vector_id not in self._data:\n        id_field, values_field = self._get_id_values_field(vector_id)\n        with h5py.File(self.get_source(), \"r\") as f:\n            ids = np.array([item.decode() for item in f[id_field]])\n            values_matrix = np.array(f[values_field])\n            new_data = {id_: values_matrix[i, :] for i, id_ in enumerate(ids)}\n            self._data.update(new_data)\n    # index may not use all values\n    index = self.get_index(vector_id)\n    vector = self._data[vector_id]\n    n = index.get_num_periods()\n    return vector[:n]\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.is_max_level","title":"<code>is_max_level(vector_id: str) -&gt; None</code>","text":"<p>Return None.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def is_max_level(self, vector_id: str) -&gt; None:\n    \"\"\"Return None.\"\"\"\n    return\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.JulESH5TimeVectorLoader.is_zero_one_profile","title":"<code>is_zero_one_profile(vector_id: str) -&gt; None</code>","text":"<p>Return None.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>def is_zero_one_profile(self, vector_id: str) -&gt; None:\n    \"\"\"Return None.\"\"\"\n    return True\n</code></pre>"},{"location":"reference/#framjules.loaders.time_vector_loaders.SupplyJulESH5TimeVectorLoader","title":"<code>SupplyJulESH5TimeVectorLoader</code>","text":"<p>               Bases: <code>JulESH5TimeVectorLoader</code></p> <p>Workaround to get supply results and at the same time avoid name conflicts.</p> Source code in <code>framjules/loaders/time_vector_loaders.py</code> <pre><code>class SupplyJulESH5TimeVectorLoader(JulESH5TimeVectorLoader):\n    \"\"\"Workaround to get supply results and at the same time avoid name conflicts.\"\"\"\n\n    _SUPPORTED_SUFFIXES: ClassVar[list] = [\".h5\"]\n    _SEARCH_FIELDS: ClassVar[list] = [\n        (\"supplynames\", \"priceindex\", \"supplyvalues\", True),\n    ]\n    _DEFAULT_INDEX = \"priceindex\"\n    pass\n</code></pre>"},{"location":"reference/#framjules.solve_handler","title":"<code>solve_handler</code>","text":""},{"location":"reference/#framjules.solve_handler.JulESAggregator","title":"<code>JulESAggregator</code>","text":""},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator","title":"<code>JulESAggregator</code>","text":"<p>               Bases: <code>Base</code></p> <p>Class for defining and calculating aggregated Model instances based on a clearing Model.</p> <p>In JulES, the clearing Model is the main Model we simulate and collect results from. JulES also has short, medium and long term price prognosis problems, which needs aggregated Models to be solved efficiently. This class helps create and manage these aggregated Models.</p> Note <ul> <li>Short term price prognosis Model is aggregated from a Clearing Model and a list of Aggregators.</li> <li>Medium term price prognosis Model is aggregated from the Short term Model and a list of Aggregators.</li> <li>Long term price prognosis Model is aggregated from the medium term Model and a list of Aggregators.</li> <li>Storages must be the same in all aggregations</li> <li>At the moment the short, medium, and long term Models are the same, du to limitations in JulES (TODO)</li> </ul> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>class JulESAggregator(Base):\n    \"\"\"Class for defining and calculating aggregated Model instances based on a clearing Model.\n\n    In JulES, the clearing Model is the main Model we simulate and collect results from. JulES also has short,\n    medium and long term price prognosis problems, which needs aggregated Models to be solved efficiently.\n    This class helps create and manage these aggregated Models.\n\n    Note:\n        - Short term price prognosis Model is aggregated from a Clearing Model and a list of Aggregators.\n        - Medium term price prognosis Model is aggregated from the Short term Model and a list of Aggregators.\n        - Long term price prognosis Model is aggregated from the medium term Model and a list of Aggregators.\n        - Storages must be the same in all aggregations\n        - At the moment the short, medium, and long term Models are the same, du to limitations in JulES (TODO)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        clearing: Model,\n        short: list[Aggregator],\n        medium: list[Aggregator],\n        long: list[Aggregator],\n    ) -&gt; None:\n        \"\"\"Initialize a JulESAggregator instance.\n\n        Args:\n            clearing (Model): The clearing Model to aggregate from.\n            short (list[Aggregator]): List of aggregations to create the short term price prognosis Model from clearing.\n            medium (list[Aggregator]): List of aggregations to create the medium term price prognosis Model from short\n            long (list[Aggregator]): List of aggregations to create the long term price prognosis Model from medium.\n\n        \"\"\"\n        self._clearing = clearing\n        self._short = short\n        self._medium = medium\n        self._long = long\n\n        self._short_model: Model | None = None\n        self._medium_model: Model | None = None\n        self._long_model: Model | None = None\n\n    def get_short_term_model(self) -&gt; Model:\n        \"\"\"Apply defined aggregations for short term Model.\"\"\"\n        if self._short_model is None:\n            self._short_model = self._aggregate(self._clearing, self._short)\n        return self._short_model\n\n    def get_medium_term_model(self) -&gt; Model:\n        \"\"\"Apply defined aggregations for medium term Model.\"\"\"\n        if self._medium_model is None:\n            self._medium_model = self._aggregate(self.get_short_term_model(), self._medium)\n        return self._medium_model\n\n    def get_long_term_model(self) -&gt; Model:\n        \"\"\"Apply defined aggregations for long term Model.\"\"\"\n        if self._long_model is None:\n            self._long_model = self._aggregate(self.get_medium_term_model(), self._long)\n        return self._long_model\n\n    def get_short_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get the aggregation map of Components from clearing to short term Model.\"\"\"\n        return self._create_aggregation_map(self._clearing, self._short)\n\n    def get_medium_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get the aggregation map of Components from clearing to medium term Model.\"\"\"\n        return self._create_aggregation_map(self._clearing, self._short + self._medium)\n\n    def get_long_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get the aggregation map of Components from clearing to long term Model.\"\"\"\n        return self._create_aggregation_map(self._clearing, self._short + self._medium + self._long)\n\n    def get_short_term_graph_map(\n        self,\n        graph_clearing: dict[str, Component],\n        graph_short: dict[str, Component],\n    ) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get aggregation map for version of short term Model with graph of Flows and Nodes.\"\"\"\n        return self._get_graph_aggregation_map(\n            original_agg_map=self.get_short_term_aggregation_map(),\n            clearing=self._clearing,\n            graph_clearing=graph_clearing,\n            aggregated=self.get_short_term_model(),\n            graph_aggregated=graph_short,\n        )\n\n    def get_medium_term_graph_map(\n        self,\n        graph_clearing: dict[str, Component],\n        graph_medium: dict[str, Component],\n    ) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get aggregation map for version of medium term Model with graph of Flows and Nodes.\"\"\"\n        return self._get_graph_aggregation_map(\n            original_agg_map=self.get_medium_term_aggregation_map(),\n            clearing=self._clearing,\n            graph_clearing=graph_clearing,\n            aggregated=self.get_medium_term_model(),\n            graph_aggregated=graph_medium,\n        )\n\n    def get_long_term_graph_map(\n        self,\n        graph_clearing: dict[str, Component],\n        graph_long: dict[str, Component],\n    ) -&gt; dict[str, set[str] | None]:\n        \"\"\"Get aggregation map for version of long term Model with graph of Flows and Nodes.\"\"\"\n        return self._get_graph_aggregation_map(\n            original_agg_map=self.get_long_term_aggregation_map(),\n            clearing=self._clearing,\n            graph_clearing=graph_clearing,\n            aggregated=self.get_long_term_model(),\n            graph_aggregated=graph_long,\n        )\n\n    def assert_equal_storages(\n        self,\n        simpler_short: dict[str, Component],\n        simpler_medium: dict[str, Component],\n        simpler_long: dict[str, Component],\n    ) -&gt; None:\n        \"\"\"Check that all Nodes with Storages are preserved between short, medium and long term Models.\n\n        Args:\n            simpler_short (dict[str, Component]): Short term Model Components.\n            simpler_medium (dict[str, Component]): Medium term Model Components.\n            simpler_long (dict[str, Component]): Long term Model Components.\n\n        Raises:\n            ValueError: If the Models have differing Storages.\n\n        \"\"\"\n        short_storages = self._get_storages(simpler_short)\n        medium_storages = self._get_storages(simpler_medium)\n        long_storages = self._get_storages(simpler_long)\n\n        if short_storages != medium_storages != long_storages:\n            message = \"Storages are not equal between short, medium and long term Models.\"\n            unique_short = short_storages - (medium_storages | long_storages)\n            unique_medium = medium_storages - (short_storages | long_storages)\n            unique_long = long_storages - (short_storages | medium_storages)\n            if unique_short:\n                message += f\"\\n - Unique Nodes with Storages in Short Model: {unique_short}\"\n            if unique_medium:\n                message += f\"\\n - Unique Nodes with Storages in Medium Model: {unique_medium}\"\n            if unique_long:\n                message += f\"\\n - Unique Nodes with Storages in Long Model: {unique_long}\"\n            raise ValueError(message)\n\n    def _aggregate(self, model: Model, aggs: list[Aggregator]) -&gt; Model:\n        if aggs:\n            # works because aggregators should not modify the original components\n            # except if disaggregate is called, but we shall only use aggregate\n            agg_model = Model()\n            agg_model.get_data().update(model.get_data())\n        else:\n            agg_model = model\n        for agg in aggs:\n            agg.aggregate(agg_model)\n        return agg_model\n\n    def _create_aggregation_map(self, clearing: Model, aggs: list[Aggregator]) -&gt; dict[str, list[str]]:\n        \"\"\"Merge aggregation maps of a list of aggregators from clearing to final.\"\"\"\n        clearing_ids = [name for name, ob in clearing.get_data().items() if isinstance(ob, Component)]\n        full_agg_mapping = {k: {v} for k, v in zip(clearing_ids, clearing_ids, strict=True)}\n\n        for agg in aggs:\n            agg_map = agg.get_aggregation_map()\n            for detailed_id, aggregated_ids in full_agg_mapping.items():\n                if not aggregated_ids:  # Component has been deleted by an aggregation.\n                    continue\n\n                new_agg_ids = set()\n                for agg_id in aggregated_ids:\n                    if agg_id not in agg_map:\n                        new_agg_ids.add(agg_id)  # left as is\n                        continue\n                    if not agg_map[agg_id]:\n                        # deleted. if all agg_ids are marked deleted, so is the detailed one.\n                        continue\n                    new_agg_ids |= agg_map[agg_id]\n\n                full_agg_mapping[detailed_id] = new_agg_ids  # empty set signifies deleted component\n\n        return full_agg_mapping\n\n    def _get_graph_aggregation_map(\n        self,\n        original_agg_map: dict[str, set[str]],\n        clearing: Model | dict[str, Component],\n        graph_clearing: dict[str, Component],\n        aggregated: Model | dict[str, Component],\n        graph_aggregated: dict[str, Component],\n    ) -&gt; dict[str, set[str]]:\n        \"\"\"Create aggregation map with simpler Component IDs based on an original mapping from clearing to aggregated.\n\n        Use get_top_parent of components to find IDs in original_agg_map then change to the Flow/Node ID.\n\n        Args:\n            original_agg_map (dict[str, set[str]]): Mapping between Components of clearing and aggregated Models.\n            clearing (dict[str, Component]): Clearing Model with top parents.\n            graph_clearing (dict[str, Component]): Clearing Model version with Flows and Nodes. Derived from\n                                                     clearing.\n            aggregated (dict[str, Component]): Aggregated Model with top parents. Aggregated from clearing.\n            graph_aggregated (dict[str, Component]): Aggregated Model version with Flows and Nodes. Derived from\n                                                       aggregated.\n\n        Returns:\n            dict[str, set[str]]: Mapping between components of simpler clearing and simpler aggregated Models.\n\n        \"\"\"\n        if isinstance(clearing, Model):\n            clearing = {k: v for k, v in clearing.get_data().items() if isinstance(v, Component)}\n        if isinstance(aggregated, Model):\n            aggregated = {k: v for k, v in aggregated.get_data().items() if isinstance(v, Component)}\n\n        self._check_agg_map_compatibility(clearing, aggregated, original_agg_map)\n\n        graph_clearing_map = self._get_top_parent_to_simple(original=clearing, simpler=graph_clearing)\n        graph_aggregated_map = self._get_top_parent_to_simple(original=aggregated, simpler=graph_aggregated)\n        simple_agg_map = {}\n\n        for clearing_id, agg_ids in original_agg_map.items():\n            # the two if statements are there for if we want to map only a subset of the simpler Components.\n            if clearing_id in graph_clearing_map:\n                if not agg_ids:\n                    continue  # choose not to add deleted components. May change this later.\n                simple_agg_ids = set()\n                for agg_id in agg_ids:\n                    if agg_id in graph_aggregated_map:  # Again to allow subset to be mapped\n                        simple_agg_ids |= graph_aggregated_map[agg_id]  # add set if simple component ids\n                if simple_agg_ids:\n                    for graph_clearing_id in graph_clearing_map[clearing_id]:\n                        simple_agg_map[graph_clearing_id] = simple_agg_ids\n\n        self._check_agg_map_validity(graph_clearing, graph_aggregated, simple_agg_map)\n        return simple_agg_map\n\n    def _check_agg_map_compatibility(\n        self,\n        clearing: Model | dict[str, Component],\n        aggregated: Model | dict[str, Component],\n        original_agg_map: dict[str, set[str]],\n    ) -&gt; None:\n        if set(clearing.keys()) != set(original_agg_map.keys()):\n            missing_in_clearing = set(original_agg_map.keys()).difference(clearing.keys())\n            extra_in_clearing = set(clearing.keys()).difference(original_agg_map.keys())\n            message = (\n                \"clearing is incompatible with the aggregation mapping between clearing and aggregated Models.\\n\"\n                f\"Missing in clearing: {missing_in_clearing}\\n\"\n                f\"Extra in clearing: {extra_in_clearing}\"\n            )\n            raise KeyError(message)\n\n        original_agg_map_values = set().union(*(v for v in original_agg_map.values() if v))\n        if set(aggregated.keys()) != original_agg_map_values:\n            missing_in_aggregated = original_agg_map_values.difference(aggregated.keys())\n            extra_in_aggregated = set(aggregated.keys()).difference(original_agg_map_values)\n            message = (\n                \"aggregated is incompatible with the aggregation mapping between clearing and aggregated Models.\\n\"\n                f\"Missing in aggregated: {missing_in_aggregated}\\n\"\n                f\"Extra in aggregated: {extra_in_aggregated}\"\n            )\n            raise KeyError(message)\n\n    def _check_agg_map_validity(\n        self,\n        original_components: dict[str, Component],\n        aggregated_components: dict[str, Component],\n        agg_map: dict[str, set[str] | None],\n    ) -&gt; None:\n        \"\"\"Check Flow and Node rules for all mappings in an aggregation map.\"\"\"\n        errors = set()\n        for original_id, aggregated_ids in agg_map.items():\n            component = original_components[original_id]\n            if isinstance(component, Node):\n                self._check_node_rules(original_id, component, aggregated_ids, aggregated_components, errors)\n\n            if isinstance(component, Flow) and component.get_startupcost() is not None:\n                self._check_flow_rules(original_id, aggregated_ids, aggregated_components, errors)\n\n            if not isinstance(component, (Flow, Node)):\n                message = (\n                    f\"Invalig Model of simpler Components. Must consist of only Flows and Nodes. Found: {component}\"\n                )\n                raise ValueError(message)\n\n        self._report_errors(errors)\n\n    def _check_node_rules(\n        self,\n        original_id: str,\n        node: Node,\n        aggregated_ids: set[str] | None,\n        aggregated_components: dict[str, Component],\n        errors: set[str],\n    ) -&gt; None:\n        \"\"\"Check rules for Nodes for a Component ID in an aggregation map.\n\n        A Node on the disaggregated side (keys) must map to exactly one other Node. More keys are alowed to map to the\n        same aggregated Node.\n\n        \"\"\"\n        if node.get_storage() is None:\n            # Check rules here?\n            return\n\n        if aggregated_ids is None:\n            e = f\"Node with Storage {original_id} was deleted during aggregations. This is not supported in JulES.\"\n            errors.add(e)\n            return\n        aggregated_storages = set()\n        for agg_id in aggregated_ids:\n            agg_component = aggregated_components[agg_id]\n            if isinstance(agg_component, Node) and agg_component.get_storage() is not None:\n                aggregated_storages.add(agg_id)\n        if len(aggregated_storages) != 1:\n            errors.add(\n                f\"Node with Storage {original_id} must be connected to exactly one Node with Storage in the \"\n                f\"aggregation map in JulES. Currently connected to: {aggregated_storages}.\",\n            )\n\n    def _check_flow_rules(\n        self,\n        original_id: str,\n        aggregated_ids: set[str] | None,\n        aggregated_components: dict[str, Component],\n        errors: set[str],\n    ) -&gt; None:\n        \"\"\"Check rules for Flows for a Component ID in an aggregation map.\n\n        A Flow on the disaggregated side (keys) must map to exactly one other Flow. More keys are alowed to map to the\n        same aggregated Flow.\n\n        \"\"\"\n        if aggregated_ids is None:\n            e = f\"Flow with StartUpCost {original_id} was deleted during aggregations. This is not supported in JulES.\"\n            errors.add(e)\n            return\n        aggregated_flows = set()\n        for agg_id in aggregated_ids:\n            agg_component = aggregated_components[agg_id]\n            if isinstance(agg_component, Flow) and agg_component.get_startupcost() is not None:\n                aggregated_flows.add(agg_id)\n        if len(aggregated_flows) != 1:\n            errors.add(\n                f\"Flow with StartUpCost {original_id} must be connected to exactly one Flow with StartUpCost in the \"\n                f\"aggregation map in JulES. Currently connected to: {aggregated_flows}.\",\n            )\n\n    @staticmethod\n    def _get_storages(simpler: dict[str, Component]) -&gt; set[str]:\n        nodes_with_storages = set()\n        for n, c in simpler.items():\n            if isinstance(c, Node) and c.get_storage() is not None:\n                nodes_with_storages.add(n)\n        return nodes_with_storages\n\n    @staticmethod\n    def _get_top_parent_to_simple(original: dict[str, Component], simpler: dict[str, Component]) -&gt; dict[str, set[str]]:\n        \"\"\"Map simpler components to their top parent.\"\"\"\n        inv_original = {c: n for n, c in original.items()}\n        simpler_map: dict[str, set[str]] = {}\n\n        for simple_id, component in simpler.items():\n            top_parent = component.get_top_parent()\n            if top_parent is None:\n                message = (\n                    f\"Component {component} with ID {simple_id} has no parents. This means it has not been \"\n                    \"derived from original.\"\n                )\n                raise ValueError(message)\n            try:\n                top_parent_id = inv_original[top_parent]\n            except KeyError as e:\n                message = (\n                    f\"Component {top_parent} does not exist in original Model. This means simpler has not been \"\n                    \"derived from original.\"\n                )\n                raise KeyError(message) from e\n            if top_parent_id in simpler_map:\n                # list has been set, wo we add the simple component id to the\n                simpler_map[top_parent_id].add(simple_id)\n            else:\n                simpler_map[top_parent_id] = {simple_id}\n\n        return simpler_map\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.__init__","title":"<code>__init__(clearing: Model, short: list[Aggregator], medium: list[Aggregator], long: list[Aggregator]) -&gt; None</code>","text":"<p>Initialize a JulESAggregator instance.</p> <p>Parameters:</p> Name Type Description Default <code>clearing</code> <code>Model</code> <p>The clearing Model to aggregate from.</p> required <code>short</code> <code>list[Aggregator]</code> <p>List of aggregations to create the short term price prognosis Model from clearing.</p> required <code>medium</code> <code>list[Aggregator]</code> <p>List of aggregations to create the medium term price prognosis Model from short</p> required <code>long</code> <code>list[Aggregator]</code> <p>List of aggregations to create the long term price prognosis Model from medium.</p> required Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def __init__(\n    self,\n    clearing: Model,\n    short: list[Aggregator],\n    medium: list[Aggregator],\n    long: list[Aggregator],\n) -&gt; None:\n    \"\"\"Initialize a JulESAggregator instance.\n\n    Args:\n        clearing (Model): The clearing Model to aggregate from.\n        short (list[Aggregator]): List of aggregations to create the short term price prognosis Model from clearing.\n        medium (list[Aggregator]): List of aggregations to create the medium term price prognosis Model from short\n        long (list[Aggregator]): List of aggregations to create the long term price prognosis Model from medium.\n\n    \"\"\"\n    self._clearing = clearing\n    self._short = short\n    self._medium = medium\n    self._long = long\n\n    self._short_model: Model | None = None\n    self._medium_model: Model | None = None\n    self._long_model: Model | None = None\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.assert_equal_storages","title":"<code>assert_equal_storages(simpler_short: dict[str, Component], simpler_medium: dict[str, Component], simpler_long: dict[str, Component]) -&gt; None</code>","text":"<p>Check that all Nodes with Storages are preserved between short, medium and long term Models.</p> <p>Parameters:</p> Name Type Description Default <code>simpler_short</code> <code>dict[str, Component]</code> <p>Short term Model Components.</p> required <code>simpler_medium</code> <code>dict[str, Component]</code> <p>Medium term Model Components.</p> required <code>simpler_long</code> <code>dict[str, Component]</code> <p>Long term Model Components.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the Models have differing Storages.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def assert_equal_storages(\n    self,\n    simpler_short: dict[str, Component],\n    simpler_medium: dict[str, Component],\n    simpler_long: dict[str, Component],\n) -&gt; None:\n    \"\"\"Check that all Nodes with Storages are preserved between short, medium and long term Models.\n\n    Args:\n        simpler_short (dict[str, Component]): Short term Model Components.\n        simpler_medium (dict[str, Component]): Medium term Model Components.\n        simpler_long (dict[str, Component]): Long term Model Components.\n\n    Raises:\n        ValueError: If the Models have differing Storages.\n\n    \"\"\"\n    short_storages = self._get_storages(simpler_short)\n    medium_storages = self._get_storages(simpler_medium)\n    long_storages = self._get_storages(simpler_long)\n\n    if short_storages != medium_storages != long_storages:\n        message = \"Storages are not equal between short, medium and long term Models.\"\n        unique_short = short_storages - (medium_storages | long_storages)\n        unique_medium = medium_storages - (short_storages | long_storages)\n        unique_long = long_storages - (short_storages | medium_storages)\n        if unique_short:\n            message += f\"\\n - Unique Nodes with Storages in Short Model: {unique_short}\"\n        if unique_medium:\n            message += f\"\\n - Unique Nodes with Storages in Medium Model: {unique_medium}\"\n        if unique_long:\n            message += f\"\\n - Unique Nodes with Storages in Long Model: {unique_long}\"\n        raise ValueError(message)\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_long_term_aggregation_map","title":"<code>get_long_term_aggregation_map() -&gt; dict[str, set[str] | None]</code>","text":"<p>Get the aggregation map of Components from clearing to long term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_long_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get the aggregation map of Components from clearing to long term Model.\"\"\"\n    return self._create_aggregation_map(self._clearing, self._short + self._medium + self._long)\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_long_term_graph_map","title":"<code>get_long_term_graph_map(graph_clearing: dict[str, Component], graph_long: dict[str, Component]) -&gt; dict[str, set[str] | None]</code>","text":"<p>Get aggregation map for version of long term Model with graph of Flows and Nodes.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_long_term_graph_map(\n    self,\n    graph_clearing: dict[str, Component],\n    graph_long: dict[str, Component],\n) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get aggregation map for version of long term Model with graph of Flows and Nodes.\"\"\"\n    return self._get_graph_aggregation_map(\n        original_agg_map=self.get_long_term_aggregation_map(),\n        clearing=self._clearing,\n        graph_clearing=graph_clearing,\n        aggregated=self.get_long_term_model(),\n        graph_aggregated=graph_long,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_long_term_model","title":"<code>get_long_term_model() -&gt; Model</code>","text":"<p>Apply defined aggregations for long term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_long_term_model(self) -&gt; Model:\n    \"\"\"Apply defined aggregations for long term Model.\"\"\"\n    if self._long_model is None:\n        self._long_model = self._aggregate(self.get_medium_term_model(), self._long)\n    return self._long_model\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_medium_term_aggregation_map","title":"<code>get_medium_term_aggregation_map() -&gt; dict[str, set[str] | None]</code>","text":"<p>Get the aggregation map of Components from clearing to medium term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_medium_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get the aggregation map of Components from clearing to medium term Model.\"\"\"\n    return self._create_aggregation_map(self._clearing, self._short + self._medium)\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_medium_term_graph_map","title":"<code>get_medium_term_graph_map(graph_clearing: dict[str, Component], graph_medium: dict[str, Component]) -&gt; dict[str, set[str] | None]</code>","text":"<p>Get aggregation map for version of medium term Model with graph of Flows and Nodes.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_medium_term_graph_map(\n    self,\n    graph_clearing: dict[str, Component],\n    graph_medium: dict[str, Component],\n) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get aggregation map for version of medium term Model with graph of Flows and Nodes.\"\"\"\n    return self._get_graph_aggregation_map(\n        original_agg_map=self.get_medium_term_aggregation_map(),\n        clearing=self._clearing,\n        graph_clearing=graph_clearing,\n        aggregated=self.get_medium_term_model(),\n        graph_aggregated=graph_medium,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_medium_term_model","title":"<code>get_medium_term_model() -&gt; Model</code>","text":"<p>Apply defined aggregations for medium term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_medium_term_model(self) -&gt; Model:\n    \"\"\"Apply defined aggregations for medium term Model.\"\"\"\n    if self._medium_model is None:\n        self._medium_model = self._aggregate(self.get_short_term_model(), self._medium)\n    return self._medium_model\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_short_term_aggregation_map","title":"<code>get_short_term_aggregation_map() -&gt; dict[str, set[str] | None]</code>","text":"<p>Get the aggregation map of Components from clearing to short term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_short_term_aggregation_map(self) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get the aggregation map of Components from clearing to short term Model.\"\"\"\n    return self._create_aggregation_map(self._clearing, self._short)\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_short_term_graph_map","title":"<code>get_short_term_graph_map(graph_clearing: dict[str, Component], graph_short: dict[str, Component]) -&gt; dict[str, set[str] | None]</code>","text":"<p>Get aggregation map for version of short term Model with graph of Flows and Nodes.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_short_term_graph_map(\n    self,\n    graph_clearing: dict[str, Component],\n    graph_short: dict[str, Component],\n) -&gt; dict[str, set[str] | None]:\n    \"\"\"Get aggregation map for version of short term Model with graph of Flows and Nodes.\"\"\"\n    return self._get_graph_aggregation_map(\n        original_agg_map=self.get_short_term_aggregation_map(),\n        clearing=self._clearing,\n        graph_clearing=graph_clearing,\n        aggregated=self.get_short_term_model(),\n        graph_aggregated=graph_short,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESAggregator.JulESAggregator.get_short_term_model","title":"<code>get_short_term_model() -&gt; Model</code>","text":"<p>Apply defined aggregations for short term Model.</p> Source code in <code>framjules/solve_handler/JulESAggregator.py</code> <pre><code>def get_short_term_model(self) -&gt; Model:\n    \"\"\"Apply defined aggregations for short term Model.\"\"\"\n    if self._short_model is None:\n        self._short_model = self._aggregate(self._clearing, self._short)\n    return self._short_model\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESNames","title":"<code>JulESNames</code>","text":""},{"location":"reference/#framjules.solve_handler.JulESNames.JulESNames","title":"<code>JulESNames</code>","text":"<p>Constants (both static and dynamic ones defined in init) used in JulES.</p> Source code in <code>framjules/solve_handler/JulESNames.py</code> <pre><code>class JulESNames:\n    \"\"\"Constants (both static and dynamic ones defined in __init__) used in JulES.\"\"\"\n\n    JSON_INDENT = 4\n    YAML_INDENT = 4\n\n    OTHER_TERMS = \"otherterms\"\n    VARS = \"Vars\"\n\n    AGGREGATED = \"aggregated\"\n    MACRO = \"macro\"\n    BALANCE_RHSDATA = \"balance\"\n\n    FILENAME_CONFIG = \"config.yaml\"\n    FILENAME_H5_OUTPUT = \"output.h5\"\n    FILENAME_STORAGE_MAPPING = \"storage_mapping.json\"\n    FILENAME_START_STORAGES_AGGREGATED = \"start_storages_aggregated.json\"\n    FILENAME_START_STORAGES_CLEARING = \"start_storages_clearing.json\"\n    ROOT_FILENAME_DATAELEMENTS = \"data_elements\"\n    FILENAME_DATAELEMENTS_TIMEVECTORS = \"data_elements_timevectors.json\"\n\n    PY_JULES_SETTINGS_NAME = \"python_jules_settings\"\n    PY_JULES_OUTPUT_NAME = \"python_jules_output\"\n\n    MAIN = \"main\"\n    MISSING_CONFIG = \"missing_config\"\n\n    RESULTS = \"results\"\n    MAINRESULTS = \"mainresults\"\n    TIMES = \"times\"\n    SCENARIOS = \"scenarios\"\n    MEMORY = \"memory\"\n    STORAGEVALUES = \"storagevalues\"\n    STORAGEVALUES_ALL_PROBLEMS = \"storagevalues_all_problems\"\n    ALL = \"all\"\n\n    TERM_DURATION_WEEKS = \"termduration_weeks\"\n    TERM_DURATION_DAYS = \"termduration_days\"\n    TERM_DURATION_HOURS = \"termduration_hours\"\n    SEQUENTIAL_HORIZON = \"SequentialHorizon\"\n    ADAPTIVE_HORIZON = \"AdaptiveHorizon\"\n\n    COMMODITIES = \"commodities\"\n    POWER = \"Power\"\n    HYDRO = \"Hydro\"\n    BATTERY = \"Battery\"\n\n    SHRINKAFTER_DAYS = \"startafter_days\"\n    SHRINKATLEAST_DAYS = \"shrinkatleast_days\"\n\n    TWO_STORAGE_DURATION = \"twostorageduration\"\n    SHORT_STOCH_DURATION_HOURS = \"shortstochduration_hours\"\n    LONG_STOCH_DURATION_DAYS = \"longstochduration_days\"\n    LONG_EV_DURATION_DAYS = \"longevduration_days\"\n\n    DISTRIBUTION_METHOD_MP = \"distribution_method_mp\"\n    DISTRIBUTION_METHOD_SP = \"distribution_method_sp\"\n    BYSIZE = \"bysize\"\n    ADVANCED = \"advanced\"\n    STORAGE = \"storage\"\n    GREEDY = \"greedy\"\n    WITHMP = \"withmp\"\n\n    STATEDEPENDENT_PROD = \"statedependentprod\"\n    STATEDEPENDENT_PUMP = \"statedependentpump\"\n    HEADLOSSCOST = \"headlosscost\"\n\n    SUBSYSTEMS = \"subsystems\"\n    RESULTS = \"results\"\n    STARTSTORAGES = \"startstorages\"\n    ENDVALUE = \"endvalue\"\n\n    OUTPUT_FORMAT = \"outputformat\"\n    DATETIME_FORMAT = \"datetimeformat\"\n    DATETIME_FORMAT_JULESIO = \"yyyy-mm-ddTHH:MM:SS\"\n    HDF5 = \"hdf5\"\n    ELASTIC = \"elastic\"\n    TRUE = True\n    FALSE = False\n\n    JULIA = \"julia\"\n    INPUT = \"input\"\n    OUTPUT_PATH = \"outputpath\"\n    NUM_CORES = \"numcores\"\n    DATA_YEARS = \"datayears\"\n    SCENARIO_YEARS = \"weatheryears\"\n    WEEK_START = \"weekstart\"\n    NUM_SIM_YEARS = \"simulationyears\"\n    EXTRA_STEPS = \"extrasteps\"\n    SETTINGS = \"settings\"\n    OUTPUT_NAME = \"outputname\"\n\n    OUTPUT_INDEX = \"outputindex\"\n    WEATHER_YEAR = \"weatheryear\"\n    DATA_YEAR = \"datayear\"\n\n    TIME = \"time\"\n    WEATHER_YEAR_START = \"weatheryearstart\"\n    WEATHER_YEAR_STOP = \"weatheryearstop\"\n    PROB_TIME = \"probtime\"\n    NORMAL_TIME = \"normaltime\"\n\n    FIXED_DATA_TWO_TIME = \"FixedDataTwoTime\"\n    PHASE_IN_FIXED_DATA_TWO_TIME = \"PhaseinFixedDataTwoTime\"\n\n    PHASE_IN_TIME = \"phaseintime\"\n    PHASE_IN_DELTA_DAYS = \"phaseindelta_days\"\n    PHASE_IN_DELTA_STEPS = \"phaseinsteps\"\n    PROBLEMS = \"problems\"\n    PROGNOSIS = \"prognosis\"\n    SIMULATION = \"simulation\"\n    SHRINKABLE = \"shrinkable\"\n    AGGZONE = \"aggzone\"\n    AGGSUPPLYN = \"aggsupplyn\"\n    SHORT_TERM_STORAGE_CUTOFF_HOURS = \"shorttermstoragecutoff_hours\"\n    SHORTER_THAN_PROGNOSIS_MED_DAYS = \"shorterthanprognosismed_days\"\n    LONG = \"long\"\n    MED = \"med\"\n    SHORT = \"short\"\n    PROB = \"prob\"\n    SOLVER = \"solver\"\n    FUNCTION = \"function\"\n    AGG_STARTMAG_DICT = \"aggstartmagdict\"\n    STARTMAG_DICT = \"startmagdict\"\n    RESIDUAL_AREA_LIST = \"residualarealist\"\n    END_CONDITION = \"endcondition\"\n    START_EQUAL_STOP = \"startequalstop\"\n    MONTHLY_PRICE = \"monthly_price\"\n\n    SCENARIO_GENERATION = \"scenariogeneration\"\n    INFLOW_CLUSTERING_METHOD = \"InflowClusteringMethod\"\n    NUM_SCEN = \"numscen\"\n    SCEN_DELTA_DAYS = \"scendelta_days\"\n\n    PARTS = \"parts\"\n\n    SKIPMAX = \"skipmax\"\n\n    HIGHS_PROB = \"HiGHS_Prob()\"\n    HIGHS_SIMPLEX = \"HighsSimplexMethod()\"\n    HIGHS_SIMPLEX_NO_WARMSTART = \"HighsSimplexMethod(warmstart=false)\"\n    HIGHS_SIMPLEX_SIP_NO_WARMSTART = \"HighsSimplexSIPMethod(warmstart=false)\"\n    JUMP_HIGHS = \"JuMPHiGHSMethod()\"\n\n    STOCHASTIC = \"stochastic\"\n    MAXCUTS = \"maxcuts\"\n    LB = \"lb\"\n    RELTOL = \"reltol\"\n    ONLY_AGG_HYDRO = \"onlyagghydro\"\n    MASTER = \"master\"\n    SUBS = \"subs\"\n    SUB = \"sub\"\n\n    HORIZONS = \"horizons\"\n    HORIZON_DURATION_WEEKS = \"horizonduration_weeks\"\n    HORIZON_DURATION_HOURS = \"horizonduration_hours\"\n    PERIOD_DURATION_DAYS = \"periodduration_days\"\n    PERIOD_DURATION_HOURS = \"periodduration_hours\"\n    POWER_PARTS = \"powerparts\"\n\n    RHSDATA = \"rhsdata\"\n    FIND_FIRST_DYNAMIC_EXOGEN_PRICE_AH_DATA = \"FindFirstDynamicExogenPriceAHData\"\n    DYNAMIC_EXOGEN_PRICE_AH_DATA = \"DynamicExogenPriceAHData\"\n    DYNAMIC_RHS_AH_DATA = \"DynamicRHSAHData\"\n    RHSMETHOD = \"rhsmethod\"\n    KMEANS_AH_METHOD = \"KMeansAHMethod()\"\n    CLUSTERS = \"clusters\"\n    UNIT_DURATION_HOURS = \"unitduration_hours\"\n\n    SETTINGS_SCENARIO_YEAR_START = \"scenarioyearstart\"\n\n    CLEARING = \"clearing\"\n    SHORT_TERM = \"short_term\"\n    MEDIUM_TERM = \"medium_term\"\n    LONG_TERM = \"long_term\"\n\n    MARKET = \"Power\"\n    STORAGE_SYSTEM = \"Hydro\"\n    SHORT_TERM_STORAGE = \"Battery\"\n\n    DFMTin = \"%Y-%m-%dT%H:%M:%S\"\n\n    FLOW = \"Flow\"\n    STORAGE = \"Storage\"\n    BALANCE = \"Balance\"\n    COMMODITY = \"Commodity\"\n    PARAM = \"Param\"\n    CAPACITY = \"Capacity\"\n    RHSTERM = \"RHSTerm\"\n    TIMEVECTOR = \"TimeVector\"\n    TIMEINDEX = \"TimeIndex\"\n    TABLE = \"Table\"\n    TIMEDELTA = \"TimeDelta\"\n    TIMEVALUES = \"TimeValues\"\n    ARROW = \"Arrow\"\n    LOSS = \"Loss\"\n    PRICE = \"Price\"\n    CONVERSION = \"Conversion\"\n    COST = \"Cost\"\n    STARTUPCOST = \"StartUpCost\"\n\n    BASEFLOW = \"BaseFlow\"\n    BASEBALANCE = \"BaseBalance\"\n    EXOGENBALANCE = \"ExogenBalance\"\n    BASESTORAGE = \"BaseStorage\"\n    MWTOGWHPARAM = \"MWToGWhParam\"\n    M3STOMM3PARAM = \"M3SToMM3Param\"\n    MEANSERIESPARAM = \"MeanSeriesParam\"\n    MSTIMEDELTA = \"MsTimeDelta\"\n    INFINITETIMEVECTOR = \"InfiniteTimeVector\"\n    ROTATINGTIMEVECTOR = \"RotatingTimeVector\"\n    ONEYEARTIMEVECTOR = \"OneYearTimeVector\"\n    CONSTANTTIMEVECTOR = \"ConstantTimeVector\"\n    RANGETIMEINDEX = \"RangeTimeIndex\"\n    VECTORTIMEINDEX = \"VectorTimeIndex\"\n    BASETABLE = \"BaseTable\"\n    COLUMNTIMEVALUES = \"ColumnTimeValues\"\n    VECTORTIMEVALUES = \"VectorTimeValues\"\n    LOWERZEROCAPACITY = \"LowerZeroCapacity\"\n    POSITIVECAPACITY = \"PositiveCapacity\"\n    BASERHSTERM = \"BaseRHSTerm\"\n    BASEARROW = \"BaseArrow\"\n    SEGMENTEDARROW = \"SegmentedArrow\"\n    SIMPLELOSS = \"SimpleLoss\"\n    COSTTERM = \"CostTerm\"\n    SIMPLESTARTUPCOST = \"SimpleStartUpCost\"\n\n    LOSSFACTORKEY = \"LossFactor\"\n    UTILIZATIONKEY = \"Utilization\"\n    FALLBACK_UTILIZATION = 0.5\n\n    STARTCOSTKEY = \"StartCost\"\n    MINSTABLELOADKEY = \"MinStableLoad\"\n\n    WHICHCONCEPT = \"WhichConcept\"\n    WHICHINSTANCE = \"WhichInstance\"\n\n    DIRECTIONKEY = \"Direction\"\n    DIRECTIONIN = \"In\"\n    DIRECTIONOUT = \"Out\"\n\n    BOUNDKEY = \"Bound\"\n    BOUNDUPPER = \"Upper\"\n    BOUNDLOWER = \"Lower\"\n\n    LEVEL = \"Level\"\n    PROFILE = \"Profile\"\n    VALUE = \"Value\"\n    START = \"Start\"\n    STEPS = \"Steps\"\n    DELTA = \"Delta\"\n    PERIOD = \"Period\"\n    VECTOR = \"Vector\"\n    MATRIX = \"Matrix\"\n    NAMES = \"Names\"\n    NAME = \"Name\"\n\n    METADATA = \"Metadata\"\n    GLOBALENEQ = \"GlobalEneq\"\n    RESIDUALHINT = \"Residualhint\"\n    STORAGEHINT = \"Storagehint\"\n\n    JULES_CONFIG = \"config.yaml\"\n    OUTPUT_FOLDER = \"output\"\n    JULIA_ENV_NAME = \"JulES_julia_env\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Dynamically settable names for JulES.\"\"\"\n        # This is set in BuildHandler when we build data elements\n        # for the clearing model. It is used in ConfigHandler in\n        # connection with using AdaptiveHorizon\n        self.dummy_exogenous_balance_name: str | None = None\n        self.dummy_exogenous_profile_id: str | None = None\n</code></pre>"},{"location":"reference/#framjules.solve_handler.JulESNames.JulESNames.__init__","title":"<code>__init__() -&gt; None</code>","text":"<p>Dynamically settable names for JulES.</p> Source code in <code>framjules/solve_handler/JulESNames.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Dynamically settable names for JulES.\"\"\"\n    # This is set in BuildHandler when we build data elements\n    # for the clearing model. It is used in ConfigHandler in\n    # connection with using AdaptiveHorizon\n    self.dummy_exogenous_balance_name: str | None = None\n    self.dummy_exogenous_profile_id: str | None = None\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler","title":"<code>SolveHandler</code>","text":""},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler","title":"<code>SolveHandler</code>","text":"<p>               Bases: <code>Base</code></p> <p>Common data methods for different simulation modes.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>class SolveHandler(Base):\n    \"\"\"Common data methods for different simulation modes.\"\"\"\n\n    def __init__(self, folder: Path, clearing_model: Model, config: JulESConfig) -&gt; None:\n        \"\"\"Hold all data and methods needed to solve JulES.\"\"\"\n        names = JulESNames()\n\n        t = time()\n        short_aggregations = config.get_short_term_aggregations()  # list of Aggregators\n        self.send_debug_event(f\"get_short_term_aggregations time: {round(time() - t, 2)} seconds\")\n        mid_aggregations = []  # config.get_mid_term_aggregations()  # not supported yet\n        long_aggregations = []  # config.get_long_term_aggregations()  # not supported yet\n\n        t = time()\n        aggregator = JulESAggregator(\n            clearing=clearing_model,\n            short=short_aggregations,\n            medium=mid_aggregations,\n            long=long_aggregations,\n        )\n        self.send_debug_event(f\"JulESAggregator init time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        short_term_model = aggregator.get_short_term_model()\n        self.send_debug_event(f\"get_short_term_model init time: {round(time() - t, 2)} seconds\")\n        t = time()\n        medium_term_model = aggregator.get_medium_term_model()\n        self.send_debug_event(f\"get_medium_term_model init time: {round(time() - t, 2)} seconds\")\n        t = time()\n        long_term_model = aggregator.get_long_term_model()\n        self.send_debug_event(f\"get_long_term_model init time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        domain_models = DomainModels(\n            clearing=clearing_model,\n            short_term=short_term_model,\n            medium_term=medium_term_model,\n            long_term=long_term_model,\n        )\n        self.send_debug_event(f\"DomainModels init time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        supported_types = (Flow, Node)\n        forbidden_types = tuple()\n        graphs = NodeFlowGraphs(\n            clearing=get_supported_components(\n                self._get_components(clearing_model),\n                supported_types,\n                forbidden_types,\n            ),\n            short_term=get_supported_components(\n                self._get_components(short_term_model),\n                supported_types,\n                forbidden_types,\n            ),\n            medium_term=get_supported_components(\n                self._get_components(medium_term_model),\n                supported_types,\n                forbidden_types,\n            ),\n            long_term=get_supported_components(\n                self._get_components(long_term_model),\n                supported_types,\n                forbidden_types,\n            ),\n        )\n        self.send_debug_event(f\"NodeFlowGraphs init time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        graph_infos = GraphInfos(\n            clearing={k: ComponentInfo() for k in graphs.clearing},\n            short_term={k: ComponentInfo() for k in graphs.short_term},\n            medium_term={k: ComponentInfo() for k in graphs.medium_term},\n            long_term={k: ComponentInfo() for k in graphs.long_term},\n        )\n        self.send_debug_event(f\"GraphInfos init time: {round(time() - t, 2)} seconds\")\n\n        # we check that that aggregated models don't have different storages\n        t = time()\n        aggregator.assert_equal_storages(\n            graphs.short_term,\n            graphs.medium_term,\n            graphs.long_term,\n        )\n        self.send_debug_event(f\"assert_equal_storages time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        constructor = CacheDB if config.is_cache_db() else ModelDB\n        db = constructor(\n            domain_models.clearing,\n            domain_models.short_term,\n            domain_models.medium_term,\n            domain_models.long_term,\n        )\n        self.send_debug_event(f\"DB init time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.fill_graph_infos(graph_infos, graphs, names, aggregator, config, db)\n        self.send_debug_event(f\"fill_graph_infos time: {round(time() - t, 2)} seconds\")\n\n        # Finally, we set the member data\n        self.folder: Path = folder\n        self.config: JulESConfig = config\n        self.names: JulESNames = names\n        self.domain_models: DomainModels = domain_models\n        self.graphs: NodeFlowGraphs = graphs\n        self.graph_infos: GraphInfos = graph_infos\n        # NB! will be freed after self.configure()\n        # so we don't hold up memory during run\n        self.db: QueryDB = db\n\n    def build(self) -&gt; None:\n        \"\"\"Build input files for JulES.\"\"\"\n        handler = self.create_build_handler()\n        handler.build()\n\n    def configure(self) -&gt; None:\n        \"\"\"Build configuration file for JulES.\"\"\"\n        handler = self.create_config_handler()\n        handler.configure()\n\n        self.db = None\n        gc.collect()\n\n    def run(self) -&gt; None:\n        \"\"\"Run Julia-JulES.\"\"\"\n        handler = self.create_run_handler()\n        handler.run()\n\n    def set_results(self) -&gt; None:\n        \"\"\"Set results from Julia-JulES run into domain models.\"\"\"\n        handler = self.create_results_handler()\n        handler.set_results()\n\n    def create_build_handler(self) -&gt; BuildHandler:\n        \"\"\"Create specialized BuildHandler for the chosen simulation mode.\"\"\"\n        if self.config.is_simulation_mode_serial():\n            handler_constructor = SerialBuildHandler\n        else:\n            raise NotImplementedError\n\n        return handler_constructor(\n            folder=self.folder,\n            config=self.config,\n            names=self.names,\n            domain_models=self.domain_models,\n            graphs=self.graphs,\n            graph_infos=self.graph_infos,\n            db=self.db,\n        )\n\n    def create_config_handler(self) -&gt; ConfigHandler:\n        \"\"\"Create specialized ConfigHandler for the chosen simulation mode.\"\"\"\n        if self.config.is_simulation_mode_serial():\n            handler_constructor = SerialConfigHandler\n        else:\n            raise NotImplementedError\n\n        return handler_constructor(\n            folder=self.folder,\n            config=self.config,\n            names=self.names,\n            graph_infos=self.graph_infos,\n        )\n\n    def create_run_handler(self) -&gt; SerialRunHandler:\n        \"\"\"Create specialized RunHandler for the chosen simulation mode.\"\"\"\n        dependencies = []\n\n        tulipa_version = self.config.get_tulipa_version()\n        if tulipa_version is not None:\n            if Path.exists(Path(tulipa_version)):\n                dependencies.append(tulipa_version)\n            else:\n                dependencies.append((\"https://github.com/NVE/TuLiPa.git\", tulipa_version))\n\n        jules_version = self.config.get_jules_version()\n        if jules_version is not None:\n            if Path.exists(Path(jules_version)):\n                dependencies.append(jules_version)\n            else:\n                dependencies.append((\"https://github.com/NVE/JulES.git\", jules_version))\n\n        dependencies.extend([\"YAML\", \"HDF5\", \"JSON\", \"PythonCall\"])\n\n        if self.config.is_simulation_mode_serial():\n            handler_constructor = SerialRunHandler\n        else:\n            message = \"JulES Parallel simulation mode is not yet supported.\"\n            raise NotImplementedError(message)\n        handler_constructor.ENV_NAME = self.names.JULIA_ENV_NAME\n        return handler_constructor(folder=self.folder, config=self.config, names=self.names, dependencies=dependencies)\n\n    def create_results_handler(self) -&gt; SerialResultsHandler:\n        \"\"\"Create a SerialResultsHandler.\"\"\"\n        if self.config.is_simulation_mode_serial():\n            handler_constructor = SerialResultsHandler\n        else:\n            message = \"JulES Parallel simulation mode is not yet supported.\"\n            raise NotImplementedError(message)\n        return handler_constructor(\n            folder=self.folder,\n            config=self.config,\n            names=self.names,\n            graphs=self.graphs,\n            graph_infos=self.graph_infos,\n        )\n\n    def _get_components(self, model: Model) -&gt; dict[str, Component]:\n        return {k: v for k, v in model.get_data().items() if isinstance(v, Component)}\n\n    def fill_graph_infos(\n        self,\n        graph_infos: GraphInfos,\n        graphs: NodeFlowGraphs,\n        names: JulESNames,\n        aggregator: JulESAggregator,\n        config: JulESConfig,\n        db: QueryDB,\n    ) -&gt; None:\n        \"\"\"Fill graph_info with derived info.\"\"\"\n        # Intent is to gather complex derivations in just one place\n\n        # NB! Order of below method calls matter\n        t = time()\n        self.set_basic_node_flow_info(graph_infos.clearing, graphs.clearing, db, config)\n        self.set_basic_node_flow_info(graph_infos.short_term, graphs.short_term, db, config)\n        self.set_basic_node_flow_info(graph_infos.medium_term, graphs.medium_term, db, config)\n        self.set_basic_node_flow_info(graph_infos.long_term, graphs.long_term, db, config)\n        self.send_debug_event(f\"set_basic_node_flow_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.set_agg_storage_node_info(graph_infos.clearing, aggregator, graphs.clearing, graphs.short_term)\n        self.send_debug_event(f\"set_agg_storage_node_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()  # opposite order to check if higher level is short term sss\n        self.set_sss_info(graphs.short_term, graph_infos.short_term, graph_infos.medium_term, names)\n        self.set_sss_info(graphs.clearing, graph_infos.clearing, graph_infos.short_term, names)\n        self.send_debug_event(f\"set_sss_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.set_market_info(graph_infos.clearing, graphs.clearing, names)\n        self.set_market_info(graph_infos.short_term, graphs.short_term, names)\n        self.set_market_info(graph_infos.medium_term, graphs.medium_term, names)\n        self.set_market_info(graph_infos.long_term, graphs.long_term, names)\n        self.send_debug_event(f\"set_market_info time: {round(time() - t, 2)} seconds\")\n\n        # self.set_agg_market_node_info(graph_infos.clearing, aggregator, graphs.clearing, graphs.short_term)\n\n        t = time()\n        self.set_jules_id_info(graph_infos.clearing, is_aggregated=False, names=names)\n        self.set_jules_id_info(graph_infos.short_term, is_aggregated=True, names=names)\n        self.send_debug_event(f\"set_jules_id_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.set_unit_info(graph_infos.clearing, graphs.clearing, config, names)\n        self.set_unit_info(graph_infos.short_term, graphs.short_term, config, names)\n        self.send_debug_event(f\"set_unit_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.set_sss_global_eneq_info(graph_infos.clearing, graphs.clearing, db, config)\n        self.set_sss_global_eneq_info(graph_infos.short_term, graphs.short_term, db, config)\n        self.send_debug_event(f\"set_sss_global_eneq_info time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.set_sss_initial_storage(graph_infos.clearing, graphs.clearing, db, config)\n        self.set_agg_initial_storage(graph_infos.short_term, graph_infos.clearing)\n        self.send_debug_event(f\"set_sss_initial_storage time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        # assert that graph_infos has expected content\n        assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.clearing.values())\n        assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.short_term.values())\n        assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.medium_term.values())\n        assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.long_term.values())\n\n        self.send_debug_event(f\"validation time: {round(time() - t, 2)} seconds\")\n\n    def set_basic_node_flow_info(\n        self,\n        out_graph_info: dict[str, ComponentInfo],\n        graph: dict[str, Flow | Node],\n        db: QueryDB,\n        config: JulESConfig,\n    ) -&gt; None:\n        \"\"\"Info directly accessible from Node and Flow API.\n\n        We also set domain_commodity for Flow as main_node.get_commodity().\n        \"\"\"\n        for component_id, c in graph.items():\n            info = out_graph_info[component_id]\n\n            info.is_node = isinstance(c, Node)\n            if info.is_node:\n                info.main_node_id = component_id\n                info.domain_commodity = c.get_commodity()\n\n            info.is_flow = isinstance(c, Flow)\n            if info.is_flow:\n                info.main_node_id = c.get_main_node()\n                info.domain_commodity = graph[info.main_node_id].get_commodity()\n                info.num_arrows = len(c.get_arrows())\n\n            info.is_storage_node = isinstance(c, Node) and c.get_storage() is not None\n            if info.is_storage_node:\n                info.is_short_term_storage = False  # TODO: Should be based on storage duration # noqa FIX002\n\n            info.is_exogenous = c.is_exogenous()\n\n    def set_agg_storage_node_info(\n        self,\n        out: dict[str, ComponentInfo],\n        aggregator: JulESAggregator,\n        detailed_graph: dict[str, Flow | Node],\n        aggregated_graph: dict[str, Flow | Node],\n    ) -&gt; None:\n        \"\"\"Aggregate storages and update info.agg_storage_node_id.\"\"\"\n        agg_storage_node_ids = {\n            n: c for n, c in aggregated_graph.items() if isinstance(c, Node) and c.get_storage() is not None\n        }\n        graph_map = aggregator.get_short_term_graph_map(detailed_graph, agg_storage_node_ids)\n        for member_id, agg_node_ids in graph_map.items():\n            assert len(agg_node_ids) &gt; 0\n            assert sum(int(n in agg_storage_node_ids) for n in agg_node_ids) == 1\n            info = out[member_id]\n            if info.is_storage_node:\n                for agg_node_id in agg_node_ids:\n                    if agg_node_id in agg_storage_node_ids:\n                        info.agg_storage_node_id = agg_node_id\n                        break\n\n    def set_agg_market_node_info(\n        self,\n        out: dict[str, ComponentInfo],\n        aggregator: JulESAggregator,\n        detailed_graph: dict[str, Flow | Node],\n        aggregated_graph: dict[str, Flow | Node],\n    ) -&gt; None:\n        \"\"\"Aggregate market nodes and update info.agg_market_node_id.\"\"\"\n        market_nodes = {n: c for n, c in aggregated_graph.items() if out[n].is_market_node}\n        graph_map = aggregator.get_medium_term_graph_map(detailed_graph, market_nodes)\n        for agg_market_node_id, member_node_ids in graph_map.items():\n            agg_component = aggregated_graph[agg_market_node_id]\n            if not isinstance(agg_component, Node):\n                continue\n            if agg_component.get_storage() is not None:\n                continue\n            for node_id in member_node_ids:\n                info = out[node_id]\n                if info.is_market_node:\n                    info.agg_market_node_id = agg_market_node_id\n\n    def set_sss_info(\n        self,\n        detailed_graph: dict[str, Flow | Node],\n        detailed_graph_info: dict[str, ComponentInfo],\n        agg_graph_info: dict[str, ComponentInfo] | None,\n        names: JulESNames,\n    ) -&gt; None:\n        \"\"\"Storage SubSystem (sss) info.\"\"\"\n        include_boundaries = False  # so market nodes at the boundary is not incorrectly classified\n        subsystems = get_one_commodity_storage_subsystems(detailed_graph, include_boundaries)\n\n        for info in detailed_graph_info.values():\n            info.has_storage_resolution = False\n\n        for subsystem_id, (__, subsystem, boundary_domain_commodities) in subsystems.items():\n            is_short_term = self._is_short_term_storage_subsystem(subsystem, detailed_graph_info, agg_graph_info)\n\n            jules_commodity = names.SHORT_TERM_STORAGE if is_short_term else names.STORAGE_SYSTEM\n\n            if len(boundary_domain_commodities) == 0:\n                message = (\n                    f\"Warning! No boundary domain commodity found for storage subsystem {subsystem_id} \"\n                    f\"with members {subsystem}.\\n\"\n                )\n                self.send_warning_event(message)\n                for component_id in subsystem:\n                    info = detailed_graph_info[component_id]\n                    info.jules_commodity = jules_commodity\n                continue\n            assert len(boundary_domain_commodities) == 1\n            market_commodity = next(iter(boundary_domain_commodities))\n\n            for component_id in subsystem:\n                info = detailed_graph_info[component_id]\n\n                info.is_sss_member = True\n\n                info.sss_id = subsystem_id\n                info.sss_is_short_term = is_short_term\n                info.sss_market_commodity = market_commodity\n                info.sss_members = subsystem\n\n                info.jules_commodity = jules_commodity\n\n            # all nodes in subsystem get True below since include_boundaries = False\n            # Flow get False if any arrow points to market commodity\n            assert include_boundaries is False\n            for component_id in subsystem:\n                component = detailed_graph[component_id]\n                info = detailed_graph_info[component_id]\n                info.has_storage_resolution = bool(not info.sss_is_short_term)\n                if isinstance(component, Flow):\n                    for arrow in component.get_arrows():\n                        node_id = arrow.get_node()\n                        node_info = detailed_graph_info[node_id]\n                        if node_info.jules_commodity == info.sss_market_commodity:\n                            info.has_storage_resolution = False\n                            break\n\n    def _is_short_term_storage_subsystem(\n        self,\n        subsystem: set[str],\n        detailed_graph_info: dict[str, ComponentInfo],\n        agg_graph_info: dict[str, ComponentInfo] | None,\n    ) -&gt; bool:\n        \"\"\"Return True if all storage nodes in subsystem are short term.\"\"\"\n        for component_id in subsystem:\n            info = detailed_graph_info[component_id]\n            if info.is_storage_node and not info.is_short_term_storage:\n                return False\n        for component_id in subsystem:\n            info = detailed_graph_info[component_id]\n            if info.is_storage_node and info.agg_storage_node_id and agg_graph_info:\n                agg_info = agg_graph_info[info.agg_storage_node_id]\n                if not agg_info.is_short_term_storage:\n                    message = (\n                        f\"Detailed storages in subsystem are short term but aggregated is not for {component_id}.\",\n                        \" Set storage system to long term. This is a limitation in JulES.jl where detailed and\",\n                        \" aggregated models must have the same storage system type to be able to interact.\",\n                    )\n                    self.send_debug_event(message)\n                    return False\n        return True\n\n    def set_market_info(\n        self,\n        out_graph_info: dict[str, ComponentInfo],\n        graph: dict[str, Flow | Node],\n        names: JulESNames,\n    ) -&gt; None:\n        \"\"\"Set is_market_node and if so, also set jules_commodity to market.\"\"\"\n        for component_id, info in out_graph_info.items():\n            info.is_market_node = info.is_node and not info.is_storage_node and not info.is_sss_member\n\n            if info.is_market_node:\n                info.jules_commodity = names.MARKET\n\n        for component_id, info in out_graph_info.items():\n            info.is_market_flow = False\n            info.is_market_flow_to_exogenous = False\n            if info.is_flow:\n                flow = graph[component_id]\n                for arrow in flow.get_arrows():\n                    node_info = out_graph_info[arrow.get_node()]\n                    if node_info.is_market_node:\n                        info.is_market_flow = True\n                        if node_info.is_exogenous:\n                            info.is_market_flow_to_exogenous = True\n                        break\n\n    def set_jules_id_info(\n        self,\n        out: dict[str, ComponentInfo],\n        is_aggregated: bool,\n        names: JulESNames,\n    ) -&gt; None:\n        \"\"\"Add jules ids in compliance with required format. Warning! Julia-JulES currently requires this format.\"\"\"\n        for node_id, info in out.items():\n            info.jules_global_eneq_id = f\"{names.GLOBALENEQ}_{node_id}\"\n\n            if info.is_storage_node:\n                if is_aggregated:\n                    info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}_hydro_reservoir\"\n                    info.jules_storage_id = f\"Reservoir_{node_id}_hydro_reservoir\"\n                else:\n                    info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}\"\n                    info.jules_storage_id = f\"Reservoir_{node_id}\"\n\n            elif info.is_node:\n                info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}\"\n\n    def set_unit_info(  # noqa: C901\n        self,\n        out: dict[str, ComponentInfo],\n        graph: dict[str, Flow | Node],\n        config: JulESConfig,\n        names: JulESNames,\n    ) -&gt; None:\n        \"\"\"Calculate all types of target units.\n\n        Need from config:\n        - unit_money\n        - unit_stock per commodity for each storage_node\n        - unit_flow per commodity for each flow\n\n        Will derive:\n        - unit_price per commodity for each market_node\n        - unit_cost for each flow\n        - unit_coeffs for each flow\n        - unit_eneq for each sss_member in each sss\n\n        And also for each flow, we derive:\n        - unit_param_type\n        - unit_param_flow_unit\n        - unit_param_flow_unit\n\n        \"\"\"\n        unit_money = config.get_currency()\n\n        node_info = {k: info for k, info in out.items() if info.is_node}\n        flow_info = {k: info for k, info in out.items() if info.is_flow}\n        market_node_info = {k: info for k, info in node_info.items() if info.is_market_node}\n        storage_node_info = {k: info for k, info in node_info.items() if info.is_storage_node}\n        sss_member_info = {k: info for k, info in node_info.items() if info.is_sss_member}\n\n        for info in market_node_info.values():\n            unit_stock = config.get_unit_stock(info.domain_commodity)\n            info.unit_price = f\"{unit_money}/{unit_stock}\"\n\n        for info in storage_node_info.values():\n            unit_flow = config.get_unit_flow(out[info.main_node_id].domain_commodity)\n            unit_stock = config.get_unit_stock(out[info.main_node_id].domain_commodity)\n            info.unit_flow = unit_flow\n            info.unit_stock = unit_stock\n\n        for d in [flow_info, storage_node_info]:\n            for info in d.values():\n                unit_flow = config.get_unit_flow(out[info.main_node_id].domain_commodity)\n                unit_stock = config.get_unit_stock(out[info.main_node_id].domain_commodity)\n                info.unit_flow = unit_flow\n                info.unit_stock = unit_stock\n                info.unit_cost = f\"{unit_money}/{unit_stock}\"\n                if is_convertable(info.unit_flow, \"MW\"):\n                    info.unit_param_type = names.MWTOGWHPARAM\n                    info.unit_param_unit_flow = \"MW\"\n                    info.unit_param_unit_stock = \"GWh\"\n                elif is_convertable(info.unit_flow, \"m3/s\"):\n                    info.unit_param_type = names.M3STOMM3PARAM\n                    info.unit_param_unit_flow = \"m3/s\"\n                    info.unit_param_unit_stock = \"Mm3\"\n                else:\n                    message = f\"Unsupported unit_flow: {info.unit_flow}\"\n                    raise ValueError(message)\n\n                if info.is_market_flow:\n                    seconds = config.get_time_resolution().get_clearing_market_minutes() * 60\n                else:\n                    seconds = config.get_time_resolution().get_clearing_storage_minutes() * 60\n                info.unit_flow_result = f\"{unit_stock}/({seconds} * s)\"\n\n        for flow_id, info in flow_info.items():\n            flow: Flow = graph[flow_id]\n            info.unit_coeffs = dict()\n            for arrow in flow.get_arrows():\n                from_node_id = arrow.get_node()\n                unit_coeff = None\n                if from_node_id != info.main_node_id:\n                    from_node_unit = config.get_unit_stock(out[from_node_id].domain_commodity)\n                    unit_coeff = None if from_node_unit == info.unit_stock else f\"{from_node_unit}/{info.unit_stock}\"\n                info.unit_coeffs[from_node_id] = unit_coeff\n\n        for info in sss_member_info.values():\n            if info.sss_global_eneq_unit is not None:\n                continue\n            unit_market = config.get_unit_stock(info.sss_market_commodity)\n            unit_stock = config.get_unit_stock(info.domain_commodity)\n            unit_eneq = f\"{unit_market}/{unit_stock}\"\n            for component_id in info.sss_members:\n                member_info = out[component_id]\n                member_info.sss_global_eneq_unit = unit_eneq\n\n    def set_sss_global_eneq_info(\n        self,\n        out: dict[str, ComponentInfo],\n        graph: dict[str, Flow | Node],\n        db: QueryDB,\n        config: JulESConfig,\n    ) -&gt; dict[str, float]:\n        \"\"\"Set global_energy_coefficient using metadata. Convert to usable unit.\"\"\"\n        for component_id, info in out.items():\n            if not info.is_sss_member or not info.is_storage_node:\n                continue\n\n            if is_convertable(info.sss_global_eneq_unit, \"1\"):\n                info.sss_global_eneq_value = 1.0\n                continue\n\n            data_dim: FixedFrequencyTimeIndex = config.get_data_period()\n\n            start_year, num_years = config.get_weather_years()\n            scen_dim = AverageYearRange(start_year, num_years)\n\n            metakeys = graph[component_id].get_meta_keys()\n            if \"EnergyEqDownstream\" in metakeys:\n                metadata = graph[component_id].get_meta(\"EnergyEqDownstream\")\n            else:\n                message = (\n                    f\"Missing metadata EnergyEqDownstream for {component_id}, only metadata keys {list(metakeys)}.\"\n                )\n                message = message + f\" Object info: {info}\"\n                raise ValueError(message)\n            expr = metadata.get_value()\n\n            info.sss_global_eneq_value = get_level_value(\n                expr=expr,\n                unit=info.sss_global_eneq_unit,\n                db=db,\n                data_dim=data_dim,\n                scen_dim=scen_dim,\n                is_max=False,\n            )\n\n    def set_sss_initial_storage(\n        self,\n        out: dict[str, ComponentInfo],\n        graph: dict[str, Flow | Node],\n        db: QueryDB,\n        config: JulESConfig,\n    ) -&gt; dict[str, float]:\n        \"\"\"Set sss_initial_storage. Convert to usable unit.\"\"\"\n        for node_id, info in out.items():\n            if not info.is_storage_node:\n                continue\n\n            node: Node = graph[node_id]\n\n            try:\n                percentage = node.get_storage().get_initial_storage_percentage()\n                assert 0 &lt;= percentage &lt;= 1\n            except Exception:\n                percentage = 0.6\n                self.send_warning_event(\n                    f\"Missing initial storage for {node_id}. Using 60 % of capacity.\",\n                )\n\n            info.sss_initial_storage = self._get_initial_storage_capacity(\n                node_id,\n                node,\n                info,\n                percentage,\n                db,\n                config,\n            )\n\n    def _get_initial_storage_capacity(\n        self,\n        node_id: str,\n        node: Node,\n        info: ComponentInfo,\n        percentage: float,\n        db: QueryDB,\n        config: JulESConfig,\n    ) -&gt; float:\n        data_dim: FixedFrequencyTimeIndex = config.get_data_period()\n\n        if data_dim.get_num_periods() &gt; 1:\n            raise NotImplementedError\n\n        start_year, num_years = config.get_weather_years()\n        scen_dim = AverageYearRange(start_year, num_years)\n\n        capacity: StockVolume = node.get_storage().get_capacity()\n        data_value: float = capacity.get_data_value(\n            db=db,\n            level_period=data_dim,\n            scenario_horizon=scen_dim,\n            unit=info.unit_stock,\n            is_max_level=True,\n        )\n\n        return data_value * percentage\n\n    def set_agg_initial_storage(\n        self,\n        agg_graph_info: dict[str, ComponentInfo],\n        det_graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Set global_eneq and initial_storage in aggregated graph_info from detailed graph_info.\"\"\"\n        for det_id, det in det_graph_info.items():\n            if not det.is_storage_node:\n                continue\n            if det.agg_storage_node_id is None:\n                continue\n\n            agg = agg_graph_info[det.agg_storage_node_id]\n\n            if agg.sss_initial_storage is None:\n                agg.sss_initial_storage = 0.0\n\n            add_value = det.sss_initial_storage\n            if det.sss_global_eneq_value:\n                add_value *= det.sss_global_eneq_value\n\n            agg.sss_initial_storage += add_value\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.__init__","title":"<code>__init__(folder: Path, clearing_model: Model, config: JulESConfig) -&gt; None</code>","text":"<p>Hold all data and methods needed to solve JulES.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def __init__(self, folder: Path, clearing_model: Model, config: JulESConfig) -&gt; None:\n    \"\"\"Hold all data and methods needed to solve JulES.\"\"\"\n    names = JulESNames()\n\n    t = time()\n    short_aggregations = config.get_short_term_aggregations()  # list of Aggregators\n    self.send_debug_event(f\"get_short_term_aggregations time: {round(time() - t, 2)} seconds\")\n    mid_aggregations = []  # config.get_mid_term_aggregations()  # not supported yet\n    long_aggregations = []  # config.get_long_term_aggregations()  # not supported yet\n\n    t = time()\n    aggregator = JulESAggregator(\n        clearing=clearing_model,\n        short=short_aggregations,\n        medium=mid_aggregations,\n        long=long_aggregations,\n    )\n    self.send_debug_event(f\"JulESAggregator init time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    short_term_model = aggregator.get_short_term_model()\n    self.send_debug_event(f\"get_short_term_model init time: {round(time() - t, 2)} seconds\")\n    t = time()\n    medium_term_model = aggregator.get_medium_term_model()\n    self.send_debug_event(f\"get_medium_term_model init time: {round(time() - t, 2)} seconds\")\n    t = time()\n    long_term_model = aggregator.get_long_term_model()\n    self.send_debug_event(f\"get_long_term_model init time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    domain_models = DomainModels(\n        clearing=clearing_model,\n        short_term=short_term_model,\n        medium_term=medium_term_model,\n        long_term=long_term_model,\n    )\n    self.send_debug_event(f\"DomainModels init time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    supported_types = (Flow, Node)\n    forbidden_types = tuple()\n    graphs = NodeFlowGraphs(\n        clearing=get_supported_components(\n            self._get_components(clearing_model),\n            supported_types,\n            forbidden_types,\n        ),\n        short_term=get_supported_components(\n            self._get_components(short_term_model),\n            supported_types,\n            forbidden_types,\n        ),\n        medium_term=get_supported_components(\n            self._get_components(medium_term_model),\n            supported_types,\n            forbidden_types,\n        ),\n        long_term=get_supported_components(\n            self._get_components(long_term_model),\n            supported_types,\n            forbidden_types,\n        ),\n    )\n    self.send_debug_event(f\"NodeFlowGraphs init time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    graph_infos = GraphInfos(\n        clearing={k: ComponentInfo() for k in graphs.clearing},\n        short_term={k: ComponentInfo() for k in graphs.short_term},\n        medium_term={k: ComponentInfo() for k in graphs.medium_term},\n        long_term={k: ComponentInfo() for k in graphs.long_term},\n    )\n    self.send_debug_event(f\"GraphInfos init time: {round(time() - t, 2)} seconds\")\n\n    # we check that that aggregated models don't have different storages\n    t = time()\n    aggregator.assert_equal_storages(\n        graphs.short_term,\n        graphs.medium_term,\n        graphs.long_term,\n    )\n    self.send_debug_event(f\"assert_equal_storages time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    constructor = CacheDB if config.is_cache_db() else ModelDB\n    db = constructor(\n        domain_models.clearing,\n        domain_models.short_term,\n        domain_models.medium_term,\n        domain_models.long_term,\n    )\n    self.send_debug_event(f\"DB init time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.fill_graph_infos(graph_infos, graphs, names, aggregator, config, db)\n    self.send_debug_event(f\"fill_graph_infos time: {round(time() - t, 2)} seconds\")\n\n    # Finally, we set the member data\n    self.folder: Path = folder\n    self.config: JulESConfig = config\n    self.names: JulESNames = names\n    self.domain_models: DomainModels = domain_models\n    self.graphs: NodeFlowGraphs = graphs\n    self.graph_infos: GraphInfos = graph_infos\n    # NB! will be freed after self.configure()\n    # so we don't hold up memory during run\n    self.db: QueryDB = db\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.build","title":"<code>build() -&gt; None</code>","text":"<p>Build input files for JulES.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def build(self) -&gt; None:\n    \"\"\"Build input files for JulES.\"\"\"\n    handler = self.create_build_handler()\n    handler.build()\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.configure","title":"<code>configure() -&gt; None</code>","text":"<p>Build configuration file for JulES.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def configure(self) -&gt; None:\n    \"\"\"Build configuration file for JulES.\"\"\"\n    handler = self.create_config_handler()\n    handler.configure()\n\n    self.db = None\n    gc.collect()\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.create_build_handler","title":"<code>create_build_handler() -&gt; BuildHandler</code>","text":"<p>Create specialized BuildHandler for the chosen simulation mode.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def create_build_handler(self) -&gt; BuildHandler:\n    \"\"\"Create specialized BuildHandler for the chosen simulation mode.\"\"\"\n    if self.config.is_simulation_mode_serial():\n        handler_constructor = SerialBuildHandler\n    else:\n        raise NotImplementedError\n\n    return handler_constructor(\n        folder=self.folder,\n        config=self.config,\n        names=self.names,\n        domain_models=self.domain_models,\n        graphs=self.graphs,\n        graph_infos=self.graph_infos,\n        db=self.db,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.create_config_handler","title":"<code>create_config_handler() -&gt; ConfigHandler</code>","text":"<p>Create specialized ConfigHandler for the chosen simulation mode.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def create_config_handler(self) -&gt; ConfigHandler:\n    \"\"\"Create specialized ConfigHandler for the chosen simulation mode.\"\"\"\n    if self.config.is_simulation_mode_serial():\n        handler_constructor = SerialConfigHandler\n    else:\n        raise NotImplementedError\n\n    return handler_constructor(\n        folder=self.folder,\n        config=self.config,\n        names=self.names,\n        graph_infos=self.graph_infos,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.create_results_handler","title":"<code>create_results_handler() -&gt; SerialResultsHandler</code>","text":"<p>Create a SerialResultsHandler.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def create_results_handler(self) -&gt; SerialResultsHandler:\n    \"\"\"Create a SerialResultsHandler.\"\"\"\n    if self.config.is_simulation_mode_serial():\n        handler_constructor = SerialResultsHandler\n    else:\n        message = \"JulES Parallel simulation mode is not yet supported.\"\n        raise NotImplementedError(message)\n    return handler_constructor(\n        folder=self.folder,\n        config=self.config,\n        names=self.names,\n        graphs=self.graphs,\n        graph_infos=self.graph_infos,\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.create_run_handler","title":"<code>create_run_handler() -&gt; SerialRunHandler</code>","text":"<p>Create specialized RunHandler for the chosen simulation mode.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def create_run_handler(self) -&gt; SerialRunHandler:\n    \"\"\"Create specialized RunHandler for the chosen simulation mode.\"\"\"\n    dependencies = []\n\n    tulipa_version = self.config.get_tulipa_version()\n    if tulipa_version is not None:\n        if Path.exists(Path(tulipa_version)):\n            dependencies.append(tulipa_version)\n        else:\n            dependencies.append((\"https://github.com/NVE/TuLiPa.git\", tulipa_version))\n\n    jules_version = self.config.get_jules_version()\n    if jules_version is not None:\n        if Path.exists(Path(jules_version)):\n            dependencies.append(jules_version)\n        else:\n            dependencies.append((\"https://github.com/NVE/JulES.git\", jules_version))\n\n    dependencies.extend([\"YAML\", \"HDF5\", \"JSON\", \"PythonCall\"])\n\n    if self.config.is_simulation_mode_serial():\n        handler_constructor = SerialRunHandler\n    else:\n        message = \"JulES Parallel simulation mode is not yet supported.\"\n        raise NotImplementedError(message)\n    handler_constructor.ENV_NAME = self.names.JULIA_ENV_NAME\n    return handler_constructor(folder=self.folder, config=self.config, names=self.names, dependencies=dependencies)\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.fill_graph_infos","title":"<code>fill_graph_infos(graph_infos: GraphInfos, graphs: NodeFlowGraphs, names: JulESNames, aggregator: JulESAggregator, config: JulESConfig, db: QueryDB) -&gt; None</code>","text":"<p>Fill graph_info with derived info.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def fill_graph_infos(\n    self,\n    graph_infos: GraphInfos,\n    graphs: NodeFlowGraphs,\n    names: JulESNames,\n    aggregator: JulESAggregator,\n    config: JulESConfig,\n    db: QueryDB,\n) -&gt; None:\n    \"\"\"Fill graph_info with derived info.\"\"\"\n    # Intent is to gather complex derivations in just one place\n\n    # NB! Order of below method calls matter\n    t = time()\n    self.set_basic_node_flow_info(graph_infos.clearing, graphs.clearing, db, config)\n    self.set_basic_node_flow_info(graph_infos.short_term, graphs.short_term, db, config)\n    self.set_basic_node_flow_info(graph_infos.medium_term, graphs.medium_term, db, config)\n    self.set_basic_node_flow_info(graph_infos.long_term, graphs.long_term, db, config)\n    self.send_debug_event(f\"set_basic_node_flow_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.set_agg_storage_node_info(graph_infos.clearing, aggregator, graphs.clearing, graphs.short_term)\n    self.send_debug_event(f\"set_agg_storage_node_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()  # opposite order to check if higher level is short term sss\n    self.set_sss_info(graphs.short_term, graph_infos.short_term, graph_infos.medium_term, names)\n    self.set_sss_info(graphs.clearing, graph_infos.clearing, graph_infos.short_term, names)\n    self.send_debug_event(f\"set_sss_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.set_market_info(graph_infos.clearing, graphs.clearing, names)\n    self.set_market_info(graph_infos.short_term, graphs.short_term, names)\n    self.set_market_info(graph_infos.medium_term, graphs.medium_term, names)\n    self.set_market_info(graph_infos.long_term, graphs.long_term, names)\n    self.send_debug_event(f\"set_market_info time: {round(time() - t, 2)} seconds\")\n\n    # self.set_agg_market_node_info(graph_infos.clearing, aggregator, graphs.clearing, graphs.short_term)\n\n    t = time()\n    self.set_jules_id_info(graph_infos.clearing, is_aggregated=False, names=names)\n    self.set_jules_id_info(graph_infos.short_term, is_aggregated=True, names=names)\n    self.send_debug_event(f\"set_jules_id_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.set_unit_info(graph_infos.clearing, graphs.clearing, config, names)\n    self.set_unit_info(graph_infos.short_term, graphs.short_term, config, names)\n    self.send_debug_event(f\"set_unit_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.set_sss_global_eneq_info(graph_infos.clearing, graphs.clearing, db, config)\n    self.set_sss_global_eneq_info(graph_infos.short_term, graphs.short_term, db, config)\n    self.send_debug_event(f\"set_sss_global_eneq_info time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.set_sss_initial_storage(graph_infos.clearing, graphs.clearing, db, config)\n    self.set_agg_initial_storage(graph_infos.short_term, graph_infos.clearing)\n    self.send_debug_event(f\"set_sss_initial_storage time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    # assert that graph_infos has expected content\n    assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.clearing.values())\n    assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.short_term.values())\n    assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.medium_term.values())\n    assert all({True, False} == {x.is_node, x.is_flow} for x in graph_infos.long_term.values())\n\n    self.send_debug_event(f\"validation time: {round(time() - t, 2)} seconds\")\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.run","title":"<code>run() -&gt; None</code>","text":"<p>Run Julia-JulES.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Run Julia-JulES.\"\"\"\n    handler = self.create_run_handler()\n    handler.run()\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_agg_initial_storage","title":"<code>set_agg_initial_storage(agg_graph_info: dict[str, ComponentInfo], det_graph_info: dict[str, ComponentInfo]) -&gt; None</code>","text":"<p>Set global_eneq and initial_storage in aggregated graph_info from detailed graph_info.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_agg_initial_storage(\n    self,\n    agg_graph_info: dict[str, ComponentInfo],\n    det_graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Set global_eneq and initial_storage in aggregated graph_info from detailed graph_info.\"\"\"\n    for det_id, det in det_graph_info.items():\n        if not det.is_storage_node:\n            continue\n        if det.agg_storage_node_id is None:\n            continue\n\n        agg = agg_graph_info[det.agg_storage_node_id]\n\n        if agg.sss_initial_storage is None:\n            agg.sss_initial_storage = 0.0\n\n        add_value = det.sss_initial_storage\n        if det.sss_global_eneq_value:\n            add_value *= det.sss_global_eneq_value\n\n        agg.sss_initial_storage += add_value\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_agg_market_node_info","title":"<code>set_agg_market_node_info(out: dict[str, ComponentInfo], aggregator: JulESAggregator, detailed_graph: dict[str, Flow | Node], aggregated_graph: dict[str, Flow | Node]) -&gt; None</code>","text":"<p>Aggregate market nodes and update info.agg_market_node_id.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_agg_market_node_info(\n    self,\n    out: dict[str, ComponentInfo],\n    aggregator: JulESAggregator,\n    detailed_graph: dict[str, Flow | Node],\n    aggregated_graph: dict[str, Flow | Node],\n) -&gt; None:\n    \"\"\"Aggregate market nodes and update info.agg_market_node_id.\"\"\"\n    market_nodes = {n: c for n, c in aggregated_graph.items() if out[n].is_market_node}\n    graph_map = aggregator.get_medium_term_graph_map(detailed_graph, market_nodes)\n    for agg_market_node_id, member_node_ids in graph_map.items():\n        agg_component = aggregated_graph[agg_market_node_id]\n        if not isinstance(agg_component, Node):\n            continue\n        if agg_component.get_storage() is not None:\n            continue\n        for node_id in member_node_ids:\n            info = out[node_id]\n            if info.is_market_node:\n                info.agg_market_node_id = agg_market_node_id\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_agg_storage_node_info","title":"<code>set_agg_storage_node_info(out: dict[str, ComponentInfo], aggregator: JulESAggregator, detailed_graph: dict[str, Flow | Node], aggregated_graph: dict[str, Flow | Node]) -&gt; None</code>","text":"<p>Aggregate storages and update info.agg_storage_node_id.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_agg_storage_node_info(\n    self,\n    out: dict[str, ComponentInfo],\n    aggregator: JulESAggregator,\n    detailed_graph: dict[str, Flow | Node],\n    aggregated_graph: dict[str, Flow | Node],\n) -&gt; None:\n    \"\"\"Aggregate storages and update info.agg_storage_node_id.\"\"\"\n    agg_storage_node_ids = {\n        n: c for n, c in aggregated_graph.items() if isinstance(c, Node) and c.get_storage() is not None\n    }\n    graph_map = aggregator.get_short_term_graph_map(detailed_graph, agg_storage_node_ids)\n    for member_id, agg_node_ids in graph_map.items():\n        assert len(agg_node_ids) &gt; 0\n        assert sum(int(n in agg_storage_node_ids) for n in agg_node_ids) == 1\n        info = out[member_id]\n        if info.is_storage_node:\n            for agg_node_id in agg_node_ids:\n                if agg_node_id in agg_storage_node_ids:\n                    info.agg_storage_node_id = agg_node_id\n                    break\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_basic_node_flow_info","title":"<code>set_basic_node_flow_info(out_graph_info: dict[str, ComponentInfo], graph: dict[str, Flow | Node], db: QueryDB, config: JulESConfig) -&gt; None</code>","text":"<p>Info directly accessible from Node and Flow API.</p> <p>We also set domain_commodity for Flow as main_node.get_commodity().</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_basic_node_flow_info(\n    self,\n    out_graph_info: dict[str, ComponentInfo],\n    graph: dict[str, Flow | Node],\n    db: QueryDB,\n    config: JulESConfig,\n) -&gt; None:\n    \"\"\"Info directly accessible from Node and Flow API.\n\n    We also set domain_commodity for Flow as main_node.get_commodity().\n    \"\"\"\n    for component_id, c in graph.items():\n        info = out_graph_info[component_id]\n\n        info.is_node = isinstance(c, Node)\n        if info.is_node:\n            info.main_node_id = component_id\n            info.domain_commodity = c.get_commodity()\n\n        info.is_flow = isinstance(c, Flow)\n        if info.is_flow:\n            info.main_node_id = c.get_main_node()\n            info.domain_commodity = graph[info.main_node_id].get_commodity()\n            info.num_arrows = len(c.get_arrows())\n\n        info.is_storage_node = isinstance(c, Node) and c.get_storage() is not None\n        if info.is_storage_node:\n            info.is_short_term_storage = False  # TODO: Should be based on storage duration # noqa FIX002\n\n        info.is_exogenous = c.is_exogenous()\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_jules_id_info","title":"<code>set_jules_id_info(out: dict[str, ComponentInfo], is_aggregated: bool, names: JulESNames) -&gt; None</code>","text":"<p>Add jules ids in compliance with required format. Warning! Julia-JulES currently requires this format.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_jules_id_info(\n    self,\n    out: dict[str, ComponentInfo],\n    is_aggregated: bool,\n    names: JulESNames,\n) -&gt; None:\n    \"\"\"Add jules ids in compliance with required format. Warning! Julia-JulES currently requires this format.\"\"\"\n    for node_id, info in out.items():\n        info.jules_global_eneq_id = f\"{names.GLOBALENEQ}_{node_id}\"\n\n        if info.is_storage_node:\n            if is_aggregated:\n                info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}_hydro_reservoir\"\n                info.jules_storage_id = f\"Reservoir_{node_id}_hydro_reservoir\"\n            else:\n                info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}\"\n                info.jules_storage_id = f\"Reservoir_{node_id}\"\n\n        elif info.is_node:\n            info.jules_balance_id = f\"{info.jules_commodity}Balance_{node_id}\"\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_market_info","title":"<code>set_market_info(out_graph_info: dict[str, ComponentInfo], graph: dict[str, Flow | Node], names: JulESNames) -&gt; None</code>","text":"<p>Set is_market_node and if so, also set jules_commodity to market.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_market_info(\n    self,\n    out_graph_info: dict[str, ComponentInfo],\n    graph: dict[str, Flow | Node],\n    names: JulESNames,\n) -&gt; None:\n    \"\"\"Set is_market_node and if so, also set jules_commodity to market.\"\"\"\n    for component_id, info in out_graph_info.items():\n        info.is_market_node = info.is_node and not info.is_storage_node and not info.is_sss_member\n\n        if info.is_market_node:\n            info.jules_commodity = names.MARKET\n\n    for component_id, info in out_graph_info.items():\n        info.is_market_flow = False\n        info.is_market_flow_to_exogenous = False\n        if info.is_flow:\n            flow = graph[component_id]\n            for arrow in flow.get_arrows():\n                node_info = out_graph_info[arrow.get_node()]\n                if node_info.is_market_node:\n                    info.is_market_flow = True\n                    if node_info.is_exogenous:\n                        info.is_market_flow_to_exogenous = True\n                    break\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_results","title":"<code>set_results() -&gt; None</code>","text":"<p>Set results from Julia-JulES run into domain models.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_results(self) -&gt; None:\n    \"\"\"Set results from Julia-JulES run into domain models.\"\"\"\n    handler = self.create_results_handler()\n    handler.set_results()\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_sss_global_eneq_info","title":"<code>set_sss_global_eneq_info(out: dict[str, ComponentInfo], graph: dict[str, Flow | Node], db: QueryDB, config: JulESConfig) -&gt; dict[str, float]</code>","text":"<p>Set global_energy_coefficient using metadata. Convert to usable unit.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_sss_global_eneq_info(\n    self,\n    out: dict[str, ComponentInfo],\n    graph: dict[str, Flow | Node],\n    db: QueryDB,\n    config: JulESConfig,\n) -&gt; dict[str, float]:\n    \"\"\"Set global_energy_coefficient using metadata. Convert to usable unit.\"\"\"\n    for component_id, info in out.items():\n        if not info.is_sss_member or not info.is_storage_node:\n            continue\n\n        if is_convertable(info.sss_global_eneq_unit, \"1\"):\n            info.sss_global_eneq_value = 1.0\n            continue\n\n        data_dim: FixedFrequencyTimeIndex = config.get_data_period()\n\n        start_year, num_years = config.get_weather_years()\n        scen_dim = AverageYearRange(start_year, num_years)\n\n        metakeys = graph[component_id].get_meta_keys()\n        if \"EnergyEqDownstream\" in metakeys:\n            metadata = graph[component_id].get_meta(\"EnergyEqDownstream\")\n        else:\n            message = (\n                f\"Missing metadata EnergyEqDownstream for {component_id}, only metadata keys {list(metakeys)}.\"\n            )\n            message = message + f\" Object info: {info}\"\n            raise ValueError(message)\n        expr = metadata.get_value()\n\n        info.sss_global_eneq_value = get_level_value(\n            expr=expr,\n            unit=info.sss_global_eneq_unit,\n            db=db,\n            data_dim=data_dim,\n            scen_dim=scen_dim,\n            is_max=False,\n        )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_sss_info","title":"<code>set_sss_info(detailed_graph: dict[str, Flow | Node], detailed_graph_info: dict[str, ComponentInfo], agg_graph_info: dict[str, ComponentInfo] | None, names: JulESNames) -&gt; None</code>","text":"<p>Storage SubSystem (sss) info.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_sss_info(\n    self,\n    detailed_graph: dict[str, Flow | Node],\n    detailed_graph_info: dict[str, ComponentInfo],\n    agg_graph_info: dict[str, ComponentInfo] | None,\n    names: JulESNames,\n) -&gt; None:\n    \"\"\"Storage SubSystem (sss) info.\"\"\"\n    include_boundaries = False  # so market nodes at the boundary is not incorrectly classified\n    subsystems = get_one_commodity_storage_subsystems(detailed_graph, include_boundaries)\n\n    for info in detailed_graph_info.values():\n        info.has_storage_resolution = False\n\n    for subsystem_id, (__, subsystem, boundary_domain_commodities) in subsystems.items():\n        is_short_term = self._is_short_term_storage_subsystem(subsystem, detailed_graph_info, agg_graph_info)\n\n        jules_commodity = names.SHORT_TERM_STORAGE if is_short_term else names.STORAGE_SYSTEM\n\n        if len(boundary_domain_commodities) == 0:\n            message = (\n                f\"Warning! No boundary domain commodity found for storage subsystem {subsystem_id} \"\n                f\"with members {subsystem}.\\n\"\n            )\n            self.send_warning_event(message)\n            for component_id in subsystem:\n                info = detailed_graph_info[component_id]\n                info.jules_commodity = jules_commodity\n            continue\n        assert len(boundary_domain_commodities) == 1\n        market_commodity = next(iter(boundary_domain_commodities))\n\n        for component_id in subsystem:\n            info = detailed_graph_info[component_id]\n\n            info.is_sss_member = True\n\n            info.sss_id = subsystem_id\n            info.sss_is_short_term = is_short_term\n            info.sss_market_commodity = market_commodity\n            info.sss_members = subsystem\n\n            info.jules_commodity = jules_commodity\n\n        # all nodes in subsystem get True below since include_boundaries = False\n        # Flow get False if any arrow points to market commodity\n        assert include_boundaries is False\n        for component_id in subsystem:\n            component = detailed_graph[component_id]\n            info = detailed_graph_info[component_id]\n            info.has_storage_resolution = bool(not info.sss_is_short_term)\n            if isinstance(component, Flow):\n                for arrow in component.get_arrows():\n                    node_id = arrow.get_node()\n                    node_info = detailed_graph_info[node_id]\n                    if node_info.jules_commodity == info.sss_market_commodity:\n                        info.has_storage_resolution = False\n                        break\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_sss_initial_storage","title":"<code>set_sss_initial_storage(out: dict[str, ComponentInfo], graph: dict[str, Flow | Node], db: QueryDB, config: JulESConfig) -&gt; dict[str, float]</code>","text":"<p>Set sss_initial_storage. Convert to usable unit.</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_sss_initial_storage(\n    self,\n    out: dict[str, ComponentInfo],\n    graph: dict[str, Flow | Node],\n    db: QueryDB,\n    config: JulESConfig,\n) -&gt; dict[str, float]:\n    \"\"\"Set sss_initial_storage. Convert to usable unit.\"\"\"\n    for node_id, info in out.items():\n        if not info.is_storage_node:\n            continue\n\n        node: Node = graph[node_id]\n\n        try:\n            percentage = node.get_storage().get_initial_storage_percentage()\n            assert 0 &lt;= percentage &lt;= 1\n        except Exception:\n            percentage = 0.6\n            self.send_warning_event(\n                f\"Missing initial storage for {node_id}. Using 60 % of capacity.\",\n            )\n\n        info.sss_initial_storage = self._get_initial_storage_capacity(\n            node_id,\n            node,\n            info,\n            percentage,\n            db,\n            config,\n        )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.SolveHandler.SolveHandler.set_unit_info","title":"<code>set_unit_info(out: dict[str, ComponentInfo], graph: dict[str, Flow | Node], config: JulESConfig, names: JulESNames) -&gt; None</code>","text":"<p>Calculate all types of target units.</p> <p>Need from config: - unit_money - unit_stock per commodity for each storage_node - unit_flow per commodity for each flow</p> <p>Will derive: - unit_price per commodity for each market_node - unit_cost for each flow - unit_coeffs for each flow - unit_eneq for each sss_member in each sss</p> <p>And also for each flow, we derive: - unit_param_type - unit_param_flow_unit - unit_param_flow_unit</p> Source code in <code>framjules/solve_handler/SolveHandler.py</code> <pre><code>def set_unit_info(  # noqa: C901\n    self,\n    out: dict[str, ComponentInfo],\n    graph: dict[str, Flow | Node],\n    config: JulESConfig,\n    names: JulESNames,\n) -&gt; None:\n    \"\"\"Calculate all types of target units.\n\n    Need from config:\n    - unit_money\n    - unit_stock per commodity for each storage_node\n    - unit_flow per commodity for each flow\n\n    Will derive:\n    - unit_price per commodity for each market_node\n    - unit_cost for each flow\n    - unit_coeffs for each flow\n    - unit_eneq for each sss_member in each sss\n\n    And also for each flow, we derive:\n    - unit_param_type\n    - unit_param_flow_unit\n    - unit_param_flow_unit\n\n    \"\"\"\n    unit_money = config.get_currency()\n\n    node_info = {k: info for k, info in out.items() if info.is_node}\n    flow_info = {k: info for k, info in out.items() if info.is_flow}\n    market_node_info = {k: info for k, info in node_info.items() if info.is_market_node}\n    storage_node_info = {k: info for k, info in node_info.items() if info.is_storage_node}\n    sss_member_info = {k: info for k, info in node_info.items() if info.is_sss_member}\n\n    for info in market_node_info.values():\n        unit_stock = config.get_unit_stock(info.domain_commodity)\n        info.unit_price = f\"{unit_money}/{unit_stock}\"\n\n    for info in storage_node_info.values():\n        unit_flow = config.get_unit_flow(out[info.main_node_id].domain_commodity)\n        unit_stock = config.get_unit_stock(out[info.main_node_id].domain_commodity)\n        info.unit_flow = unit_flow\n        info.unit_stock = unit_stock\n\n    for d in [flow_info, storage_node_info]:\n        for info in d.values():\n            unit_flow = config.get_unit_flow(out[info.main_node_id].domain_commodity)\n            unit_stock = config.get_unit_stock(out[info.main_node_id].domain_commodity)\n            info.unit_flow = unit_flow\n            info.unit_stock = unit_stock\n            info.unit_cost = f\"{unit_money}/{unit_stock}\"\n            if is_convertable(info.unit_flow, \"MW\"):\n                info.unit_param_type = names.MWTOGWHPARAM\n                info.unit_param_unit_flow = \"MW\"\n                info.unit_param_unit_stock = \"GWh\"\n            elif is_convertable(info.unit_flow, \"m3/s\"):\n                info.unit_param_type = names.M3STOMM3PARAM\n                info.unit_param_unit_flow = \"m3/s\"\n                info.unit_param_unit_stock = \"Mm3\"\n            else:\n                message = f\"Unsupported unit_flow: {info.unit_flow}\"\n                raise ValueError(message)\n\n            if info.is_market_flow:\n                seconds = config.get_time_resolution().get_clearing_market_minutes() * 60\n            else:\n                seconds = config.get_time_resolution().get_clearing_storage_minutes() * 60\n            info.unit_flow_result = f\"{unit_stock}/({seconds} * s)\"\n\n    for flow_id, info in flow_info.items():\n        flow: Flow = graph[flow_id]\n        info.unit_coeffs = dict()\n        for arrow in flow.get_arrows():\n            from_node_id = arrow.get_node()\n            unit_coeff = None\n            if from_node_id != info.main_node_id:\n                from_node_unit = config.get_unit_stock(out[from_node_id].domain_commodity)\n                unit_coeff = None if from_node_unit == info.unit_stock else f\"{from_node_unit}/{info.unit_stock}\"\n            info.unit_coeffs[from_node_id] = unit_coeff\n\n    for info in sss_member_info.values():\n        if info.sss_global_eneq_unit is not None:\n            continue\n        unit_market = config.get_unit_stock(info.sss_market_commodity)\n        unit_stock = config.get_unit_stock(info.domain_commodity)\n        unit_eneq = f\"{unit_market}/{unit_stock}\"\n        for component_id in info.sss_members:\n            member_info = out[component_id]\n            member_info.sss_global_eneq_unit = unit_eneq\n</code></pre>"},{"location":"reference/#framjules.solve_handler.build_handler","title":"<code>build_handler</code>","text":""},{"location":"reference/#framjules.solve_handler.build_handler.BuildHandler","title":"<code>BuildHandler</code>","text":""},{"location":"reference/#framjules.solve_handler.build_handler.BuildHandler.BuildHandler","title":"<code>BuildHandler</code>","text":"<p>               Bases: <code>Base</code>, <code>ABC</code></p> <p>Responsible for implementing shared functionality in build method.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>class BuildHandler(Base, ABC):\n    \"\"\"Responsible for implementing shared functionality in build method.\"\"\"\n\n    def __init__(\n        self,\n        folder: Path,\n        config: JulESConfig,\n        names: JulESNames,\n        domain_models: DomainModels,\n        graphs: NodeFlowGraphs,\n        graph_infos: GraphInfos,\n        db: QueryDB,\n    ) -&gt; None:\n        \"\"\"Initialize handler.\n\n        Use inputs passed down from SolveHandler\n\n        and create extra fields only relevant for\n        the build phase.\n        \"\"\"\n        self.folder = folder\n        self.config = config\n        self.names = names\n        self.domain_models = domain_models\n        self.graphs = graphs\n        self.graph_infos = graph_infos\n        self.db = db\n\n        self.append = DataElementAppender(names)\n\n        self.errors: set[str] = set()\n        self.timevectors: dict[FixedFrequencyTimeIndex, dict[str, NDArray]] = defaultdict(dict)\n\n    def build(self) -&gt; None:\n        \"\"\"Build input and configuration files for JulES.\"\"\"\n        t = time()\n        self.build_data_elements(self.names.CLEARING, self.graphs.clearing, self.graph_infos.clearing)\n        self.send_debug_event(f\"build_data_elements clearing time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.build_data_elements(self.names.AGGREGATED, self.graphs.short_term, self.graph_infos.short_term)\n        self.send_debug_event(f\"build_data_elements aggregated time: {round(time() - t, 2)} seconds\")\n\n        # Intent is to build data elements for aggregated models. Pending changes in Julia-JulES\n        # self.build_data_elements(self.names.SHORT_TERM, self.graphs.short_term, self.graph_infos.short_term)\n        # self.build_data_elements(self.names.MEDIUM_TERM, self.graphs.medium_term, self.graph_infos.medium_term)\n        # self.build_data_elements(self.names.LONG_TERM, self.graphs.long_term, self.graph_infos.long_term)\n\n        t = time()\n        self.build_time_vectors()\n        self.send_debug_event(f\"build_time_vectors time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.build_storage_mapping(self.graph_infos.clearing)\n        self.send_debug_event(f\"build_storage_mapping time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.build_start_storage(self.names.FILENAME_START_STORAGES_CLEARING, self.graph_infos.clearing)\n        self.send_debug_event(f\"build_start_storage clearing time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.build_start_storage(self.names.FILENAME_START_STORAGES_AGGREGATED, self.graph_infos.short_term)\n        self.send_debug_event(f\"build_start_storage aggregated time: {round(time() - t, 2)} seconds\")\n\n    def build_start_storage(\n        self,\n        filename: str,\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Write start storag json file to folder.\"\"\"\n        data = {\n            info.jules_storage_id: info.sss_initial_storage for k, info in graph_info.items() if info.is_storage_node\n        }\n        self.write_json_file(data, filename)\n\n    def build_data_elements(\n        self,\n        model_id: str,\n        graph: dict[str, Flow | Node],\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Write json file with data elements for a graph belonging to a given model_id.\"\"\"\n        self.fill_data_elements(model_id, graph, graph_info)\n        self.stop_if_errors()\n        filename = f\"{self.names.ROOT_FILENAME_DATAELEMENTS}_{model_id}.json\"\n        self.write_json_file(self.append.data_elements, filename)\n\n    def stop_if_errors(self) -&gt; None:\n        \"\"\"Throw RunTimeError if any errors.\"\"\"\n        if self.errors:\n            error_string = \"\\n\".join(self.errors)\n            message = f\"Errors found:\\n{error_string}\"\n            raise RuntimeError(message)\n\n    def build_time_vectors(self) -&gt; None:\n        \"\"\"Write json file with time vector data elements and csv file for each unique time index.\"\"\"\n        self.append.data_elements = []\n        for i, timeindex in enumerate(self.timevectors, start=1):\n            time_index_id = f\"timeindex_{i}\"\n\n            milliseconds: float = timeindex.get_period_duration().total_seconds() * 1000.0\n            time_delta_id = f\"{time_index_id}_timedelta\"\n            self.append.ms_time_delta(time_delta_id, milliseconds)\n\n            self.append.range_time_index(\n                time_index_id,\n                timeindex.get_start_time(),\n                timeindex.get_num_periods(),\n                time_delta_id,\n            )\n\n            table_id = f\"{time_index_id}_table\"\n            path_table, column_names = self.write_table(time_index_id, timeindex)\n            self.append.base_table(table_id, path_table, column_names)\n\n            is_one_year = timeindex.is_one_year()\n\n            for column_name in column_names:\n                time_vector_id = column_name\n                time_values_id = f\"{time_vector_id}_values\"\n\n                self.append.column_time_values(time_values_id, table_id, column_name)\n\n                if is_one_year:\n                    self.append.one_year_time_vector(time_vector_id, time_index_id, time_values_id)\n                else:\n                    self.append.rotating_time_vector(time_vector_id, time_index_id, time_values_id)\n\n        self.write_json_file(self.append.data_elements, self.names.FILENAME_DATAELEMENTS_TIMEVECTORS)\n\n    def get_time_index_id(self, timeindex: FixedFrequencyTimeIndex) -&gt; str:\n        \"\"\"Return id that works in file name.\"\"\"\n        type_name = type(timeindex).__name__\n        num_periods = timeindex.get_num_periods()\n        resolution = int(timeindex.get_period_duration().total_seconds() * 1000.0)\n        is_52 = timeindex.is_52_week_years()\n        extr_first = timeindex.extrapolate_first_point()\n        extr_last = timeindex.extrapolate_last_point()\n        return f\"timeindex_{type_name}_periods_{num_periods}_ms_{resolution}_{is_52}_{extr_first}_{extr_last}\"\n\n    def write_table(\n        self,\n        time_index_id: str,\n        timeindex: FixedFrequencyTimeIndex,\n    ) -&gt; tuple[Path, list[str]]:\n        \"\"\"Write all vectors corresponding to time_index_id to a csv file.\"\"\"\n        vectors = self.timevectors[timeindex]\n        column_names = list(vectors.keys())\n        matrix = np.column_stack([vectors[c] for c in column_names])\n        matrix = np.round(matrix, decimals=6)  # quick fix for negative values in time vectors\n        # if negative values give warning\n        if np.any(matrix &lt; 0):\n            self.errors.add(f\"Negative values found in time vector for {time_index_id}. This might cause issues.\")\n        filename = f\"timevector_{time_index_id}.csv\"\n        path = self.folder / filename\n        np.savetxt(path, matrix, delimiter=\",\")\n        return path, column_names\n\n    def build_storage_mapping(\n        self,\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Write the mapping of storages from Clearing to Aggregated Model to json.\"\"\"\n        data = {\n            k: info.agg_storage_node_id\n            for k, info in graph_info.items()\n            if info.is_storage_node and info.agg_storage_node_id\n        }\n        self.write_json_file(data, self.names.FILENAME_STORAGE_MAPPING)\n\n    def fill_data_elements(\n        self,\n        model_id: str,\n        graph: dict[str, Flow | Node],\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Reset and fill self.append.data_elements with data element json data.\"\"\"\n        self.append.data_elements = []  # Important to reset the list\n\n        nodes: dict[str, Node] = {k: v for k, v in graph.items() if isinstance(v, Node)}\n        flows: dict[str, Flow] = {k: v for k, v in graph.items() if isinstance(v, Flow)}\n\n        exogenous_nodes = {k: v for k, v in nodes.items() if v.is_exogenous()}\n        exogenous_flows = {k: v for k, v in flows.items() if v.is_exogenous()}\n        endogenous_nodes = {k: v for k, v in nodes.items() if not v.is_exogenous()}\n        endogenous_flows = {k: v for k, v in flows.items() if not v.is_exogenous()}\n\n        t = time()\n        self.add_exogenous_nodes(exogenous_nodes, graph_info)\n        self.send_debug_event(f\"add_exogenous_nodes time: {round(time() - t, 2)} seconds\")\n        t = time()\n        self.add_exogenous_flows(exogenous_flows, graph_info)\n        self.send_debug_event(f\"add_exogenous_flows time: {round(time() - t, 2)} seconds\")\n        t = time()\n        self.add_endogenous_nodes(endogenous_nodes, graph_info, model_id)\n        self.send_debug_event(f\"add_endogenous_nodes time: {round(time() - t, 2)} seconds\")\n        t = time()\n        self.add_endogenous_flows(endogenous_flows, graph_info)\n        self.send_debug_event(f\"add_endogenous_flows time: {round(time() - t, 2)} seconds\")\n\n        t = time()\n        self.add_dummy_exogenous_balance()\n        self.send_debug_event(f\"add_dummy_exogenous_balance time: {round(time() - t, 2)} seconds\")\n\n    def add_dummy_exogenous_balance(self) -&gt; None:\n        \"\"\"Add a dummy exogenous Node for JulES.\"\"\"\n        balance_id = \"PowerBalance_DummyNode\"\n        profile_id = f\"{balance_id}_Profile\"\n        # Find longest name.\n        longest_name = \"\"\n        for name in self.graphs.clearing:\n            if len(name) &gt; len(longest_name):\n                longest_name = name\n        if len(longest_name) &gt;= len(balance_id):\n            unique_postfix = \"_\" + \"x\" * (len(longest_name) - len(balance_id))  # Fill to guarantee uniqueness.\n            balance_id += unique_postfix\n            profile_id += unique_postfix\n\n        # Set balance and profile ids in names so other parts of system have access to them.\n        self.names.dummy_exogenous_balance_name = balance_id\n        self.names.dummy_exogenous_profile_id = profile_id\n\n        price_param_id = f\"{balance_id}_price_param\"\n        self.append.exogenous_balance(balance_id, self.names.MARKET, price_param_id)\n        self.append.mean_series_param(price_param_id, 1.0, profile_id)\n\n        # Set index and vector so they are added to the dataset in build_time_vectors.\n\n        first_scenario_year, num_scenario_years = self.config.get_weather_years()\n\n        period_duration = timedelta(minutes=self.config.get_time_resolution().get_clearing_market_minutes())\n\n        dummy_timeindex = ProfileTimeIndex(\n            start_year=first_scenario_year,\n            num_years=num_scenario_years,\n            period_duration=self._get_closest_valid_profile_duration(period_duration),\n            is_52_week_years=True,\n        )\n\n        if dummy_timeindex not in self.timevectors:\n            default_vector = np.arange(0, dummy_timeindex.get_num_periods(), 1, dtype=np.float64)\n            np.divide(default_vector, default_vector.max(), out=default_vector)\n\n            self.timevectors[dummy_timeindex] = {profile_id: default_vector}\n\n    def add_exogenous_nodes(\n        self,\n        exogenous_nodes: dict[str, Node],\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Append exogenous balance related data elements for exogenous node.\"\"\"\n        for node_id, node in exogenous_nodes.items():\n            info = graph_info[node_id]\n\n            balance_id = info.jules_balance_id\n\n            price_param_id = f\"{balance_id}_price_param\"\n\n            self.append.exogenous_balance(balance_id, info.jules_commodity, price_param_id)\n\n            price: Price = node.get_price()\n\n            if not price.has_level():\n                message = f\"Node {node_id} is exogenous but has not price.\"\n                raise RuntimeError(message)\n\n            if price.has_profile():\n                units = get_units_from_expr(self.db, price.get_profile())\n                if units:\n                    message = f\"Node {node_id} has exogenous price profile with units {units}.\"\n                    raise RuntimeError(message)\n\n            level = self.get_price_level(price_param_id, price, info)\n            profile = self.get_price_profile(price_param_id, price, info)\n\n            self.append.mean_series_param(price_param_id, level, profile)\n\n    def add_endogenous_nodes(\n        self,\n        endogenous_nodes: dict[str, Node],\n        graph_info: dict[str, ComponentInfo],\n        model_id: str,\n    ) -&gt; None:\n        \"\"\"Append endogenous balance related data elements for endogenous node.\"\"\"\n        for node_id, node in endogenous_nodes.items():\n            info = graph_info[node_id]\n\n            self.append.endogenous_balance(info.jules_balance_id, info.jules_commodity)\n\n            storage = node.get_storage()\n            if storage is not None:\n                self.add_storage(model_id, storage, info)\n\n    def add_exogenous_flows(\n        self,\n        exogenous_flows: dict[str, Flow],\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Append data elements related to an exogenous flow.\"\"\"\n        for flow_id, flow in exogenous_flows.items():\n            for arrow in flow.get_arrows():\n                node_info = graph_info[arrow.get_node()]\n                if not node_info.is_exogenous:\n                    self.add_rhs_term(flow_id, flow, arrow, node_info, graph_info[flow_id])\n\n    def add_endogenous_flows(\n        self,\n        endogenous_flows: dict[str, Flow],\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Append data elements for endogenous flows and related attributes.\"\"\"\n        for flow_id, flow in endogenous_flows.items():\n            self.append.base_flow(flow_id)\n\n            flow_info = graph_info[flow_id]\n\n            self.add_flow_lower_bound(flow_id, flow, flow_info)\n            self.add_flow_upper_bound(flow_id, flow, flow_info)\n            self.add_flow_arrows(flow_id, flow, graph_info)\n            self.add_flow_costs(flow_id, flow, flow_info)\n\n    def add_storage(\n        self,\n        model_id: str,\n        storage: Storage,\n        info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append data elements related to a storage.\"\"\"\n        storage_id = info.jules_storage_id\n        balance_id = info.jules_balance_id\n\n        self.append.base_storage(storage_id, balance_id)\n\n        capacity = storage.get_capacity()\n\n        self.add_positive_capacity(storage_id, info, capacity, f\"{storage_id}_upper_bound\", False)\n\n        self.append.lower_zero_capacity(f\"{storage_id}_lower_bound\", info.is_flow, storage_id)\n\n        if model_id == self.names.CLEARING:\n            if info.sss_global_eneq_value is not None:\n                self.append.global_eneq(info.jules_global_eneq_id, info.jules_balance_id, info.sss_global_eneq_value)\n\n            if info.sss_is_short_term and info.is_short_term_storage:\n                self.append.storage_hint(\n                    storage_id,\n                    round(info.sss_storage_duration.total_seconds() * 1000),\n                )\n\n    def add_rhs_term(\n        self,\n        flow_id: str,\n        flow: Flow,\n        arrow: Arrow,\n        node_info: ComponentInfo,\n        flow_info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append data elements related to rhs term.\"\"\"\n        node_id = arrow.get_node()\n\n        rhs_term_id = f\"exogenous_flow_{flow_id}_{node_id}\"\n        unit_param_id = f\"{rhs_term_id}_unit_param\"\n        series_param_id = f\"{rhs_term_id}_series_param\"\n        balance_id = node_info.jules_balance_id\n\n        self.append.base_rhs_term(rhs_term_id, balance_id, arrow.is_ingoing(), unit_param_id)\n\n        level = self.get_rhs_term_level(rhs_term_id, flow, arrow, flow_info)\n\n        profile = self.get_rhs_term_profile(rhs_term_id, flow, arrow, flow_info)\n\n        # unit is actually flipped from main to target node\n        # using conversion factor inside get_rhs_term_level\n        # so the jules unit param might say GWh but the values\n        # have been converted so that the result will become e.g. Mm3\n\n        self.append.unit_param(unit_param_id, series_param_id, flow_info)\n        self.append.mean_series_param(series_param_id, level, profile)\n\n    def add_flow_lower_bound(\n        self,\n        flow_id: str,\n        flow: Flow,\n        flow_info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append lower bound related data elements for a flow.\"\"\"\n        capacity = flow.get_min_capacity()\n        bound_id = f\"{flow_id}_lower_bound\"\n        profile = None if capacity is None else capacity.get_profile()\n        if profile is None:\n            self.append.lower_zero_capacity(bound_id, flow_info.is_flow, flow_or_storage_id=flow_id)\n            return\n        self.add_positive_capacity(flow_id, flow_info, capacity, bound_id, is_lower_bound=True)\n\n    def add_flow_upper_bound(\n        self,\n        flow_id: str,\n        flow: Flow,\n        flow_info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append upper bound related data elements for a flow.\"\"\"\n        capacity = flow.get_max_capacity()\n        if capacity is None:\n            return\n        bound_id = f\"{flow_id}_upper_bound\"\n        self.add_positive_capacity(flow_id, flow_info, capacity, bound_id, is_lower_bound=False)\n\n    def add_flow_arrows(\n        self,\n        flow_id: str,\n        flow: Flow,\n        graph_info: dict[str, ComponentInfo],\n    ) -&gt; None:\n        \"\"\"Append arrow related data elements for each arrow in flow.\"\"\"\n        flow_info = graph_info[flow_id]\n        for arrow in flow.get_arrows():\n            assert arrow.has_profile() is False, \"Currently not supported, will be implemented later\"\n\n            arrow_id = f\"{flow_id}_arrow_{arrow.get_node()}-&gt;{flow_info.main_node_id}\"\n\n            level = self.get_coefficient_level(arrow_id, arrow, flow_info)\n\n            balance_id = graph_info[arrow.get_node()].jules_balance_id\n\n            self.append.base_arrow(arrow_id, flow_id, balance_id, arrow.is_ingoing(), level)\n\n    def add_flow_costs(\n        self,\n        flow_id: str,\n        flow: Flow,\n        flow_info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append cost data element for each cost in flow.\"\"\"\n        cost_terms = flow.get_cost_terms()\n        for cost_term_id, cost_term in cost_terms.items():\n            level = self.get_cost_term_level(cost_term_id, cost_term, flow_info)\n\n            has_profile = cost_term.get_profile() is None\n\n            profile = self.get_cost_term_profile(cost_term_id, cost_term, flow_info) if has_profile else 1.0\n\n            extended_cost_term_id = f\"{flow_id}_{cost_term_id}\"\n            param_id = f\"{extended_cost_term_id}_param\"\n            self.append.cost_term(extended_cost_term_id, flow_id, flow_info.is_flow, cost_term.is_cost(), param_id)\n\n            self.append.mean_series_param(param_id, level, profile)\n\n    def add_positive_capacity(\n        self,\n        flow_or_storage_id: str,\n        info: ComponentInfo,\n        capacity: FlowVolume | StockVolume,\n        bound_id: str,\n        is_lower_bound: bool,\n    ) -&gt; None:\n        \"\"\"Append data elements related to positive capacity.\"\"\"\n        series_param_id = f\"{bound_id}_series_param\"\n\n        if isinstance(capacity, FlowVolume):\n            unit_param_id = f\"{bound_id}_unit_param\"\n            self.append.unit_param(unit_param_id, series_param_id, info)\n            self.append.positive_capacity(bound_id, info.is_flow, flow_or_storage_id, is_lower_bound, unit_param_id)\n        else:\n            assert isinstance(capacity, StockVolume)\n            self.append.positive_capacity(bound_id, info.is_flow, flow_or_storage_id, is_lower_bound, series_param_id)\n\n        level = self.get_capacity_level(series_param_id, capacity, info)\n        profile = self.get_capacity_profile(series_param_id, capacity, info)\n\n        self.append.mean_series_param(series_param_id, level, profile)\n\n    def write_json_file(self, data: object, filename: str) -&gt; None:\n        \"\"\"Write data to json.\"\"\"\n        with Path.open(self.folder / filename, \"w\") as f:\n            json.dump(data, f, indent=self.names.JSON_INDENT)\n\n    def _get_closest_valid_profile_duration(self, period_duration: timedelta) -&gt; timedelta:\n        input_seconds = period_duration.total_seconds()\n        data = [h * 3600 for h in [168, 84, 56, 42, 28, 24, 21, 14, 12, 8, 7, 6, 4, 3, 2, 1]]\n        for profile_seconds in data:\n            if profile_seconds &lt;= input_seconds:\n                break\n        return timedelta(seconds=profile_seconds)\n\n    # Must be implemented for each simulation mode\n\n    @abstractmethod\n    def get_price_level(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query price level.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_price_profile(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query price profile.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_capacity_level(self, root_id: str, capacity: FlowVolume | StockVolume, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query capacity level.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_capacity_profile(\n        self,\n        root_id: str,\n        capacity: FlowVolume | StockVolume,\n        info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"Query capacity profile.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_coefficient_level(self, root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query arrow coefficient level.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_cost_term_level(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query cost term level.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_cost_term_profile(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n        \"\"\"Query cost term profile.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_rhs_term_level(\n        self,\n        rhs_term_id: str,\n        flow: Flow,\n        arrow: Arrow,\n        flow_info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"Query rhs term level.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_rhs_term_profile(\n        self,\n        rhs_term_id: str,\n        flow: Flow,\n        arrow: Arrow,\n        flow_info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"Query rhs term profile.\"\"\"\n        pass\n</code></pre> <code></code> <code>__init__(folder: Path, config: JulESConfig, names: JulESNames, domain_models: DomainModels, graphs: NodeFlowGraphs, graph_infos: GraphInfos, db: QueryDB) -&gt; None</code> <p>Initialize handler.</p> <p>Use inputs passed down from SolveHandler</p> <p>and create extra fields only relevant for the build phase.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def __init__(\n    self,\n    folder: Path,\n    config: JulESConfig,\n    names: JulESNames,\n    domain_models: DomainModels,\n    graphs: NodeFlowGraphs,\n    graph_infos: GraphInfos,\n    db: QueryDB,\n) -&gt; None:\n    \"\"\"Initialize handler.\n\n    Use inputs passed down from SolveHandler\n\n    and create extra fields only relevant for\n    the build phase.\n    \"\"\"\n    self.folder = folder\n    self.config = config\n    self.names = names\n    self.domain_models = domain_models\n    self.graphs = graphs\n    self.graph_infos = graph_infos\n    self.db = db\n\n    self.append = DataElementAppender(names)\n\n    self.errors: set[str] = set()\n    self.timevectors: dict[FixedFrequencyTimeIndex, dict[str, NDArray]] = defaultdict(dict)\n</code></pre> <code></code> <code>add_dummy_exogenous_balance() -&gt; None</code> <p>Add a dummy exogenous Node for JulES.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_dummy_exogenous_balance(self) -&gt; None:\n    \"\"\"Add a dummy exogenous Node for JulES.\"\"\"\n    balance_id = \"PowerBalance_DummyNode\"\n    profile_id = f\"{balance_id}_Profile\"\n    # Find longest name.\n    longest_name = \"\"\n    for name in self.graphs.clearing:\n        if len(name) &gt; len(longest_name):\n            longest_name = name\n    if len(longest_name) &gt;= len(balance_id):\n        unique_postfix = \"_\" + \"x\" * (len(longest_name) - len(balance_id))  # Fill to guarantee uniqueness.\n        balance_id += unique_postfix\n        profile_id += unique_postfix\n\n    # Set balance and profile ids in names so other parts of system have access to them.\n    self.names.dummy_exogenous_balance_name = balance_id\n    self.names.dummy_exogenous_profile_id = profile_id\n\n    price_param_id = f\"{balance_id}_price_param\"\n    self.append.exogenous_balance(balance_id, self.names.MARKET, price_param_id)\n    self.append.mean_series_param(price_param_id, 1.0, profile_id)\n\n    # Set index and vector so they are added to the dataset in build_time_vectors.\n\n    first_scenario_year, num_scenario_years = self.config.get_weather_years()\n\n    period_duration = timedelta(minutes=self.config.get_time_resolution().get_clearing_market_minutes())\n\n    dummy_timeindex = ProfileTimeIndex(\n        start_year=first_scenario_year,\n        num_years=num_scenario_years,\n        period_duration=self._get_closest_valid_profile_duration(period_duration),\n        is_52_week_years=True,\n    )\n\n    if dummy_timeindex not in self.timevectors:\n        default_vector = np.arange(0, dummy_timeindex.get_num_periods(), 1, dtype=np.float64)\n        np.divide(default_vector, default_vector.max(), out=default_vector)\n\n        self.timevectors[dummy_timeindex] = {profile_id: default_vector}\n</code></pre> <code></code> <code>add_endogenous_flows(endogenous_flows: dict[str, Flow], graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Append data elements for endogenous flows and related attributes.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_endogenous_flows(\n    self,\n    endogenous_flows: dict[str, Flow],\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Append data elements for endogenous flows and related attributes.\"\"\"\n    for flow_id, flow in endogenous_flows.items():\n        self.append.base_flow(flow_id)\n\n        flow_info = graph_info[flow_id]\n\n        self.add_flow_lower_bound(flow_id, flow, flow_info)\n        self.add_flow_upper_bound(flow_id, flow, flow_info)\n        self.add_flow_arrows(flow_id, flow, graph_info)\n        self.add_flow_costs(flow_id, flow, flow_info)\n</code></pre> <code></code> <code>add_endogenous_nodes(endogenous_nodes: dict[str, Node], graph_info: dict[str, ComponentInfo], model_id: str) -&gt; None</code> <p>Append endogenous balance related data elements for endogenous node.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_endogenous_nodes(\n    self,\n    endogenous_nodes: dict[str, Node],\n    graph_info: dict[str, ComponentInfo],\n    model_id: str,\n) -&gt; None:\n    \"\"\"Append endogenous balance related data elements for endogenous node.\"\"\"\n    for node_id, node in endogenous_nodes.items():\n        info = graph_info[node_id]\n\n        self.append.endogenous_balance(info.jules_balance_id, info.jules_commodity)\n\n        storage = node.get_storage()\n        if storage is not None:\n            self.add_storage(model_id, storage, info)\n</code></pre> <code></code> <code>add_exogenous_flows(exogenous_flows: dict[str, Flow], graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Append data elements related to an exogenous flow.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_exogenous_flows(\n    self,\n    exogenous_flows: dict[str, Flow],\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Append data elements related to an exogenous flow.\"\"\"\n    for flow_id, flow in exogenous_flows.items():\n        for arrow in flow.get_arrows():\n            node_info = graph_info[arrow.get_node()]\n            if not node_info.is_exogenous:\n                self.add_rhs_term(flow_id, flow, arrow, node_info, graph_info[flow_id])\n</code></pre> <code></code> <code>add_exogenous_nodes(exogenous_nodes: dict[str, Node], graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Append exogenous balance related data elements for exogenous node.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_exogenous_nodes(\n    self,\n    exogenous_nodes: dict[str, Node],\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Append exogenous balance related data elements for exogenous node.\"\"\"\n    for node_id, node in exogenous_nodes.items():\n        info = graph_info[node_id]\n\n        balance_id = info.jules_balance_id\n\n        price_param_id = f\"{balance_id}_price_param\"\n\n        self.append.exogenous_balance(balance_id, info.jules_commodity, price_param_id)\n\n        price: Price = node.get_price()\n\n        if not price.has_level():\n            message = f\"Node {node_id} is exogenous but has not price.\"\n            raise RuntimeError(message)\n\n        if price.has_profile():\n            units = get_units_from_expr(self.db, price.get_profile())\n            if units:\n                message = f\"Node {node_id} has exogenous price profile with units {units}.\"\n                raise RuntimeError(message)\n\n        level = self.get_price_level(price_param_id, price, info)\n        profile = self.get_price_profile(price_param_id, price, info)\n\n        self.append.mean_series_param(price_param_id, level, profile)\n</code></pre> <code></code> <code>add_flow_arrows(flow_id: str, flow: Flow, graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Append arrow related data elements for each arrow in flow.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_flow_arrows(\n    self,\n    flow_id: str,\n    flow: Flow,\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Append arrow related data elements for each arrow in flow.\"\"\"\n    flow_info = graph_info[flow_id]\n    for arrow in flow.get_arrows():\n        assert arrow.has_profile() is False, \"Currently not supported, will be implemented later\"\n\n        arrow_id = f\"{flow_id}_arrow_{arrow.get_node()}-&gt;{flow_info.main_node_id}\"\n\n        level = self.get_coefficient_level(arrow_id, arrow, flow_info)\n\n        balance_id = graph_info[arrow.get_node()].jules_balance_id\n\n        self.append.base_arrow(arrow_id, flow_id, balance_id, arrow.is_ingoing(), level)\n</code></pre> <code></code> <code>add_flow_costs(flow_id: str, flow: Flow, flow_info: ComponentInfo) -&gt; None</code> <p>Append cost data element for each cost in flow.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_flow_costs(\n    self,\n    flow_id: str,\n    flow: Flow,\n    flow_info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append cost data element for each cost in flow.\"\"\"\n    cost_terms = flow.get_cost_terms()\n    for cost_term_id, cost_term in cost_terms.items():\n        level = self.get_cost_term_level(cost_term_id, cost_term, flow_info)\n\n        has_profile = cost_term.get_profile() is None\n\n        profile = self.get_cost_term_profile(cost_term_id, cost_term, flow_info) if has_profile else 1.0\n\n        extended_cost_term_id = f\"{flow_id}_{cost_term_id}\"\n        param_id = f\"{extended_cost_term_id}_param\"\n        self.append.cost_term(extended_cost_term_id, flow_id, flow_info.is_flow, cost_term.is_cost(), param_id)\n\n        self.append.mean_series_param(param_id, level, profile)\n</code></pre> <code></code> <code>add_flow_lower_bound(flow_id: str, flow: Flow, flow_info: ComponentInfo) -&gt; None</code> <p>Append lower bound related data elements for a flow.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_flow_lower_bound(\n    self,\n    flow_id: str,\n    flow: Flow,\n    flow_info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append lower bound related data elements for a flow.\"\"\"\n    capacity = flow.get_min_capacity()\n    bound_id = f\"{flow_id}_lower_bound\"\n    profile = None if capacity is None else capacity.get_profile()\n    if profile is None:\n        self.append.lower_zero_capacity(bound_id, flow_info.is_flow, flow_or_storage_id=flow_id)\n        return\n    self.add_positive_capacity(flow_id, flow_info, capacity, bound_id, is_lower_bound=True)\n</code></pre> <code></code> <code>add_flow_upper_bound(flow_id: str, flow: Flow, flow_info: ComponentInfo) -&gt; None</code> <p>Append upper bound related data elements for a flow.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_flow_upper_bound(\n    self,\n    flow_id: str,\n    flow: Flow,\n    flow_info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append upper bound related data elements for a flow.\"\"\"\n    capacity = flow.get_max_capacity()\n    if capacity is None:\n        return\n    bound_id = f\"{flow_id}_upper_bound\"\n    self.add_positive_capacity(flow_id, flow_info, capacity, bound_id, is_lower_bound=False)\n</code></pre> <code></code> <code>add_positive_capacity(flow_or_storage_id: str, info: ComponentInfo, capacity: FlowVolume | StockVolume, bound_id: str, is_lower_bound: bool) -&gt; None</code> <p>Append data elements related to positive capacity.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_positive_capacity(\n    self,\n    flow_or_storage_id: str,\n    info: ComponentInfo,\n    capacity: FlowVolume | StockVolume,\n    bound_id: str,\n    is_lower_bound: bool,\n) -&gt; None:\n    \"\"\"Append data elements related to positive capacity.\"\"\"\n    series_param_id = f\"{bound_id}_series_param\"\n\n    if isinstance(capacity, FlowVolume):\n        unit_param_id = f\"{bound_id}_unit_param\"\n        self.append.unit_param(unit_param_id, series_param_id, info)\n        self.append.positive_capacity(bound_id, info.is_flow, flow_or_storage_id, is_lower_bound, unit_param_id)\n    else:\n        assert isinstance(capacity, StockVolume)\n        self.append.positive_capacity(bound_id, info.is_flow, flow_or_storage_id, is_lower_bound, series_param_id)\n\n    level = self.get_capacity_level(series_param_id, capacity, info)\n    profile = self.get_capacity_profile(series_param_id, capacity, info)\n\n    self.append.mean_series_param(series_param_id, level, profile)\n</code></pre> <code></code> <code>add_rhs_term(flow_id: str, flow: Flow, arrow: Arrow, node_info: ComponentInfo, flow_info: ComponentInfo) -&gt; None</code> <p>Append data elements related to rhs term.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_rhs_term(\n    self,\n    flow_id: str,\n    flow: Flow,\n    arrow: Arrow,\n    node_info: ComponentInfo,\n    flow_info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append data elements related to rhs term.\"\"\"\n    node_id = arrow.get_node()\n\n    rhs_term_id = f\"exogenous_flow_{flow_id}_{node_id}\"\n    unit_param_id = f\"{rhs_term_id}_unit_param\"\n    series_param_id = f\"{rhs_term_id}_series_param\"\n    balance_id = node_info.jules_balance_id\n\n    self.append.base_rhs_term(rhs_term_id, balance_id, arrow.is_ingoing(), unit_param_id)\n\n    level = self.get_rhs_term_level(rhs_term_id, flow, arrow, flow_info)\n\n    profile = self.get_rhs_term_profile(rhs_term_id, flow, arrow, flow_info)\n\n    # unit is actually flipped from main to target node\n    # using conversion factor inside get_rhs_term_level\n    # so the jules unit param might say GWh but the values\n    # have been converted so that the result will become e.g. Mm3\n\n    self.append.unit_param(unit_param_id, series_param_id, flow_info)\n    self.append.mean_series_param(series_param_id, level, profile)\n</code></pre> <code></code> <code>add_storage(model_id: str, storage: Storage, info: ComponentInfo) -&gt; None</code> <p>Append data elements related to a storage.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def add_storage(\n    self,\n    model_id: str,\n    storage: Storage,\n    info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append data elements related to a storage.\"\"\"\n    storage_id = info.jules_storage_id\n    balance_id = info.jules_balance_id\n\n    self.append.base_storage(storage_id, balance_id)\n\n    capacity = storage.get_capacity()\n\n    self.add_positive_capacity(storage_id, info, capacity, f\"{storage_id}_upper_bound\", False)\n\n    self.append.lower_zero_capacity(f\"{storage_id}_lower_bound\", info.is_flow, storage_id)\n\n    if model_id == self.names.CLEARING:\n        if info.sss_global_eneq_value is not None:\n            self.append.global_eneq(info.jules_global_eneq_id, info.jules_balance_id, info.sss_global_eneq_value)\n\n        if info.sss_is_short_term and info.is_short_term_storage:\n            self.append.storage_hint(\n                storage_id,\n                round(info.sss_storage_duration.total_seconds() * 1000),\n            )\n</code></pre> <code></code> <code>build() -&gt; None</code> <p>Build input and configuration files for JulES.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def build(self) -&gt; None:\n    \"\"\"Build input and configuration files for JulES.\"\"\"\n    t = time()\n    self.build_data_elements(self.names.CLEARING, self.graphs.clearing, self.graph_infos.clearing)\n    self.send_debug_event(f\"build_data_elements clearing time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.build_data_elements(self.names.AGGREGATED, self.graphs.short_term, self.graph_infos.short_term)\n    self.send_debug_event(f\"build_data_elements aggregated time: {round(time() - t, 2)} seconds\")\n\n    # Intent is to build data elements for aggregated models. Pending changes in Julia-JulES\n    # self.build_data_elements(self.names.SHORT_TERM, self.graphs.short_term, self.graph_infos.short_term)\n    # self.build_data_elements(self.names.MEDIUM_TERM, self.graphs.medium_term, self.graph_infos.medium_term)\n    # self.build_data_elements(self.names.LONG_TERM, self.graphs.long_term, self.graph_infos.long_term)\n\n    t = time()\n    self.build_time_vectors()\n    self.send_debug_event(f\"build_time_vectors time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.build_storage_mapping(self.graph_infos.clearing)\n    self.send_debug_event(f\"build_storage_mapping time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.build_start_storage(self.names.FILENAME_START_STORAGES_CLEARING, self.graph_infos.clearing)\n    self.send_debug_event(f\"build_start_storage clearing time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.build_start_storage(self.names.FILENAME_START_STORAGES_AGGREGATED, self.graph_infos.short_term)\n    self.send_debug_event(f\"build_start_storage aggregated time: {round(time() - t, 2)} seconds\")\n</code></pre> <code></code> <code>build_data_elements(model_id: str, graph: dict[str, Flow | Node], graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Write json file with data elements for a graph belonging to a given model_id.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def build_data_elements(\n    self,\n    model_id: str,\n    graph: dict[str, Flow | Node],\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Write json file with data elements for a graph belonging to a given model_id.\"\"\"\n    self.fill_data_elements(model_id, graph, graph_info)\n    self.stop_if_errors()\n    filename = f\"{self.names.ROOT_FILENAME_DATAELEMENTS}_{model_id}.json\"\n    self.write_json_file(self.append.data_elements, filename)\n</code></pre> <code></code> <code>build_start_storage(filename: str, graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Write start storag json file to folder.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def build_start_storage(\n    self,\n    filename: str,\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Write start storag json file to folder.\"\"\"\n    data = {\n        info.jules_storage_id: info.sss_initial_storage for k, info in graph_info.items() if info.is_storage_node\n    }\n    self.write_json_file(data, filename)\n</code></pre> <code></code> <code>build_storage_mapping(graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Write the mapping of storages from Clearing to Aggregated Model to json.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def build_storage_mapping(\n    self,\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Write the mapping of storages from Clearing to Aggregated Model to json.\"\"\"\n    data = {\n        k: info.agg_storage_node_id\n        for k, info in graph_info.items()\n        if info.is_storage_node and info.agg_storage_node_id\n    }\n    self.write_json_file(data, self.names.FILENAME_STORAGE_MAPPING)\n</code></pre> <code></code> <code>build_time_vectors() -&gt; None</code> <p>Write json file with time vector data elements and csv file for each unique time index.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def build_time_vectors(self) -&gt; None:\n    \"\"\"Write json file with time vector data elements and csv file for each unique time index.\"\"\"\n    self.append.data_elements = []\n    for i, timeindex in enumerate(self.timevectors, start=1):\n        time_index_id = f\"timeindex_{i}\"\n\n        milliseconds: float = timeindex.get_period_duration().total_seconds() * 1000.0\n        time_delta_id = f\"{time_index_id}_timedelta\"\n        self.append.ms_time_delta(time_delta_id, milliseconds)\n\n        self.append.range_time_index(\n            time_index_id,\n            timeindex.get_start_time(),\n            timeindex.get_num_periods(),\n            time_delta_id,\n        )\n\n        table_id = f\"{time_index_id}_table\"\n        path_table, column_names = self.write_table(time_index_id, timeindex)\n        self.append.base_table(table_id, path_table, column_names)\n\n        is_one_year = timeindex.is_one_year()\n\n        for column_name in column_names:\n            time_vector_id = column_name\n            time_values_id = f\"{time_vector_id}_values\"\n\n            self.append.column_time_values(time_values_id, table_id, column_name)\n\n            if is_one_year:\n                self.append.one_year_time_vector(time_vector_id, time_index_id, time_values_id)\n            else:\n                self.append.rotating_time_vector(time_vector_id, time_index_id, time_values_id)\n\n    self.write_json_file(self.append.data_elements, self.names.FILENAME_DATAELEMENTS_TIMEVECTORS)\n</code></pre> <code></code> <code>fill_data_elements(model_id: str, graph: dict[str, Flow | Node], graph_info: dict[str, ComponentInfo]) -&gt; None</code> <p>Reset and fill self.append.data_elements with data element json data.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def fill_data_elements(\n    self,\n    model_id: str,\n    graph: dict[str, Flow | Node],\n    graph_info: dict[str, ComponentInfo],\n) -&gt; None:\n    \"\"\"Reset and fill self.append.data_elements with data element json data.\"\"\"\n    self.append.data_elements = []  # Important to reset the list\n\n    nodes: dict[str, Node] = {k: v for k, v in graph.items() if isinstance(v, Node)}\n    flows: dict[str, Flow] = {k: v for k, v in graph.items() if isinstance(v, Flow)}\n\n    exogenous_nodes = {k: v for k, v in nodes.items() if v.is_exogenous()}\n    exogenous_flows = {k: v for k, v in flows.items() if v.is_exogenous()}\n    endogenous_nodes = {k: v for k, v in nodes.items() if not v.is_exogenous()}\n    endogenous_flows = {k: v for k, v in flows.items() if not v.is_exogenous()}\n\n    t = time()\n    self.add_exogenous_nodes(exogenous_nodes, graph_info)\n    self.send_debug_event(f\"add_exogenous_nodes time: {round(time() - t, 2)} seconds\")\n    t = time()\n    self.add_exogenous_flows(exogenous_flows, graph_info)\n    self.send_debug_event(f\"add_exogenous_flows time: {round(time() - t, 2)} seconds\")\n    t = time()\n    self.add_endogenous_nodes(endogenous_nodes, graph_info, model_id)\n    self.send_debug_event(f\"add_endogenous_nodes time: {round(time() - t, 2)} seconds\")\n    t = time()\n    self.add_endogenous_flows(endogenous_flows, graph_info)\n    self.send_debug_event(f\"add_endogenous_flows time: {round(time() - t, 2)} seconds\")\n\n    t = time()\n    self.add_dummy_exogenous_balance()\n    self.send_debug_event(f\"add_dummy_exogenous_balance time: {round(time() - t, 2)} seconds\")\n</code></pre> <code></code> <code>get_capacity_level(root_id: str, capacity: FlowVolume | StockVolume, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query capacity level.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_capacity_level(self, root_id: str, capacity: FlowVolume | StockVolume, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query capacity level.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_capacity_profile(root_id: str, capacity: FlowVolume | StockVolume, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query capacity profile.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_capacity_profile(\n    self,\n    root_id: str,\n    capacity: FlowVolume | StockVolume,\n    info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"Query capacity profile.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_coefficient_level(root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query arrow coefficient level.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_coefficient_level(self, root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query arrow coefficient level.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_cost_term_level(root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query cost term level.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_cost_term_level(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query cost term level.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_cost_term_profile(root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query cost term profile.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_cost_term_profile(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query cost term profile.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_price_level(root_id: str, price: Price, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query price level.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_price_level(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query price level.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_price_profile(root_id: str, price: Price, info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query price profile.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_price_profile(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n    \"\"\"Query price profile.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_rhs_term_level(rhs_term_id: str, flow: Flow, arrow: Arrow, flow_info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query rhs term level.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_rhs_term_level(\n    self,\n    rhs_term_id: str,\n    flow: Flow,\n    arrow: Arrow,\n    flow_info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"Query rhs term level.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_rhs_term_profile(rhs_term_id: str, flow: Flow, arrow: Arrow, flow_info: ComponentInfo) -&gt; str | float</code> <code>abstractmethod</code> <p>Query rhs term profile.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>@abstractmethod\ndef get_rhs_term_profile(\n    self,\n    rhs_term_id: str,\n    flow: Flow,\n    arrow: Arrow,\n    flow_info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"Query rhs term profile.\"\"\"\n    pass\n</code></pre> <code></code> <code>get_time_index_id(timeindex: FixedFrequencyTimeIndex) -&gt; str</code> <p>Return id that works in file name.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def get_time_index_id(self, timeindex: FixedFrequencyTimeIndex) -&gt; str:\n    \"\"\"Return id that works in file name.\"\"\"\n    type_name = type(timeindex).__name__\n    num_periods = timeindex.get_num_periods()\n    resolution = int(timeindex.get_period_duration().total_seconds() * 1000.0)\n    is_52 = timeindex.is_52_week_years()\n    extr_first = timeindex.extrapolate_first_point()\n    extr_last = timeindex.extrapolate_last_point()\n    return f\"timeindex_{type_name}_periods_{num_periods}_ms_{resolution}_{is_52}_{extr_first}_{extr_last}\"\n</code></pre> <code></code> <code>stop_if_errors() -&gt; None</code> <p>Throw RunTimeError if any errors.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def stop_if_errors(self) -&gt; None:\n    \"\"\"Throw RunTimeError if any errors.\"\"\"\n    if self.errors:\n        error_string = \"\\n\".join(self.errors)\n        message = f\"Errors found:\\n{error_string}\"\n        raise RuntimeError(message)\n</code></pre> <code></code> <code>write_json_file(data: object, filename: str) -&gt; None</code> <p>Write data to json.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def write_json_file(self, data: object, filename: str) -&gt; None:\n    \"\"\"Write data to json.\"\"\"\n    with Path.open(self.folder / filename, \"w\") as f:\n        json.dump(data, f, indent=self.names.JSON_INDENT)\n</code></pre> <code></code> <code>write_table(time_index_id: str, timeindex: FixedFrequencyTimeIndex) -&gt; tuple[Path, list[str]]</code> <p>Write all vectors corresponding to time_index_id to a csv file.</p> Source code in <code>framjules/solve_handler/build_handler/BuildHandler.py</code> <pre><code>def write_table(\n    self,\n    time_index_id: str,\n    timeindex: FixedFrequencyTimeIndex,\n) -&gt; tuple[Path, list[str]]:\n    \"\"\"Write all vectors corresponding to time_index_id to a csv file.\"\"\"\n    vectors = self.timevectors[timeindex]\n    column_names = list(vectors.keys())\n    matrix = np.column_stack([vectors[c] for c in column_names])\n    matrix = np.round(matrix, decimals=6)  # quick fix for negative values in time vectors\n    # if negative values give warning\n    if np.any(matrix &lt; 0):\n        self.errors.add(f\"Negative values found in time vector for {time_index_id}. This might cause issues.\")\n    filename = f\"timevector_{time_index_id}.csv\"\n    path = self.folder / filename\n    np.savetxt(path, matrix, delimiter=\",\")\n    return path, column_names\n</code></pre>"},{"location":"reference/#framjules.solve_handler.build_handler.DataElementAppender","title":"<code>DataElementAppender</code>","text":"<p>Functionality to reate data element to JulES.</p>"},{"location":"reference/#framjules.solve_handler.build_handler.DataElementAppender.DataElementAppender","title":"<code>DataElementAppender</code>","text":"<p>Used to generate list of data elements for JulES.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>class DataElementAppender:\n    \"\"\"Used to generate list of data elements for JulES.\"\"\"\n\n    def __init__(self, names: JulESNames) -&gt; None:\n        \"\"\"Initialize new DataElementAppender.\"\"\"\n        self.data_elements: list = []\n        self.names: JulESNames = names\n\n    def exogenous_balance(\n        self,\n        balance_id: str,\n        commodiy: str,\n        price_param_id: str | float,\n    ) -&gt; None:\n        \"\"\"Append exogenous balance data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.BALANCE,\n                self.names.EXOGENBALANCE,\n                balance_id,\n                [self.names.COMMODITY, commodiy],\n                [self.names.PRICE, price_param_id],\n            ],\n        )\n\n    def endogenous_balance(\n        self,\n        balance_id: str,\n        commodiy: str,\n    ) -&gt; None:\n        \"\"\"Append endogenous balance data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.BALANCE,\n                self.names.BASEBALANCE,\n                balance_id,\n                [self.names.COMMODITY, commodiy],\n            ],\n        )\n\n    def mean_series_param(\n        self,\n        param_id: str,\n        level: str | float,\n        profile: str | float,\n    ) -&gt; None:\n        \"\"\"Append mean series param data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.PARAM,\n                self.names.MEANSERIESPARAM,\n                param_id,\n                [self.names.LEVEL, level],\n                [self.names.PROFILE, profile],\n            ],\n        )\n\n    def base_flow(self, flow_id: str) -&gt; None:\n        \"\"\"Append base flow data element.\"\"\"\n        self.data_elements.append([self.names.FLOW, self.names.BASEFLOW, flow_id])\n\n    def lower_zero_capacity(\n        self,\n        lower_bound_id: str,\n        is_flow: bool,\n        flow_or_storage_id: str,\n    ) -&gt; None:\n        \"\"\"Append zero lower capacity data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.CAPACITY,\n                self.names.LOWERZEROCAPACITY,\n                lower_bound_id,\n                [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n                [self.names.WHICHINSTANCE, flow_or_storage_id],\n            ],\n        )\n\n    def positive_capacity(\n        self,\n        bound_id: str,\n        is_flow: bool,\n        flow_or_storage_id: str,\n        is_lower_bound: bool,\n        param_id: str,\n    ) -&gt; None:\n        \"\"\"Append positive capacity data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.CAPACITY,\n                self.names.POSITIVECAPACITY,\n                bound_id,\n                [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n                [self.names.WHICHINSTANCE, flow_or_storage_id],\n                [self.names.BOUNDKEY, self.names.BOUNDLOWER if is_lower_bound else self.names.BOUNDUPPER],\n                [self.names.PARAM, param_id],\n            ],\n        )\n\n    def unit_param(\n        self,\n        unit_param_id: str,\n        series_param_id: str,\n        info: ComponentInfo,\n    ) -&gt; None:\n        \"\"\"Append unit param data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.PARAM,\n                info.unit_param_type,\n                unit_param_id,\n                [self.names.PARAM, series_param_id],\n            ],\n        )\n\n    def base_arrow(\n        self,\n        arrow_id: str,\n        flow_id: str,\n        balance_id: str,\n        is_ingoing: bool,\n        conversion: str | float,\n    ) -&gt; None:\n        \"\"\"Append base arrow data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.ARROW,\n                self.names.BASEARROW,\n                arrow_id,\n                [self.names.FLOW, flow_id],\n                [self.names.BALANCE, balance_id],\n                [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_ingoing else self.names.DIRECTIONOUT],\n                [self.names.CONVERSION, conversion],\n            ],\n        )\n\n    def cost_term(\n        self,\n        cost_term_id: str,\n        flow_or_storage_id: str,\n        is_flow: str,\n        is_cost: bool,\n        cost: str | float,\n    ) -&gt; None:\n        \"\"\"Append cost term data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.COST,\n                self.names.COSTTERM,\n                cost_term_id,\n                [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_cost else self.names.DIRECTIONOUT],\n                [self.names.PARAM, cost],\n                [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n                [self.names.WHICHINSTANCE, flow_or_storage_id],\n            ],\n        )\n\n    def base_rhs_term(\n        self,\n        rhs_term_id: str,\n        balance_id: str,\n        is_ingoing: bool,\n        unit_param_id: str,\n    ) -&gt; None:\n        \"\"\"Append base rhs term data element.\"\"\"\n        # TODO: Add residualhint # noqa FIX002\n        self.data_elements.append(\n            [\n                self.names.RHSTERM,\n                self.names.BASERHSTERM,\n                rhs_term_id,\n                [self.names.BALANCE, balance_id],\n                [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_ingoing else self.names.DIRECTIONOUT],\n                [self.names.PARAM, unit_param_id],\n            ],\n        )\n\n    def base_storage(\n        self,\n        storage_id: str,\n        balance_id: str,\n    ) -&gt; None:\n        \"\"\"Append base storage data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.STORAGE,\n                self.names.BASESTORAGE,\n                storage_id,\n                [self.names.BALANCE, balance_id],\n            ],\n        )\n\n    def global_eneq(\n        self,\n        global_eneq_id: str,\n        balance_id: str,\n        value: float,\n    ) -&gt; None:\n        \"\"\"Append global energy equivalent data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.METADATA,\n                self.names.GLOBALENEQ,\n                global_eneq_id,\n                [self.names.BALANCE, balance_id],\n                [self.names.VALUE, value],\n            ],\n        )\n\n    def storage_hint(self, storage_id: str, period: int) -&gt; None:\n        \"\"\"Append storage hint data element to indicate storage duration in milliseconds.\"\"\"\n        storage_hint_id = f\"StorageHint_{storage_id}\"\n        self.data_elements.append(\n            [\n                self.names.METADATA,\n                self.names.STORAGEHINT,\n                storage_hint_id,\n                [self.names.STORAGE, storage_id],\n                [self.names.PERIOD, period],\n            ],\n        )\n\n    def ms_time_delta(\n        self,\n        time_delta_id: str,\n        milliseconds: float,\n    ) -&gt; None:\n        \"\"\"Append ms time delta data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TIMEDELTA,\n                self.names.MSTIMEDELTA,\n                time_delta_id,\n                [self.names.PERIOD, milliseconds],\n            ],\n        )\n\n    def range_time_index(\n        self,\n        time_index_id: str,\n        start_time: datetime,\n        num_steps: int,\n        time_delta_id: str,\n    ) -&gt; None:\n        \"\"\"Append range time index data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TIMEINDEX,\n                self.names.RANGETIMEINDEX,\n                time_index_id,\n                [self.names.START, start_time.strftime(r\"%Y-%m-%d %H:%M:%S\")],\n                [self.names.STEPS, num_steps],\n                [self.names.DELTA, time_delta_id],\n            ],\n        )\n\n    def base_table(\n        self,\n        table_id: str,\n        path_table: str | Path,\n        column_names: list[str],\n    ) -&gt; None:\n        \"\"\"Append base table data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TABLE,\n                self.names.BASETABLE,\n                table_id,\n                [self.names.MATRIX, str(path_table)],\n                [self.names.NAMES, column_names],\n            ],\n        )\n\n    def column_time_values(\n        self,\n        time_values_id: str,\n        table_id: str,\n        column_id: str,\n    ) -&gt; None:\n        \"\"\"Append column time values data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TIMEVALUES,\n                self.names.COLUMNTIMEVALUES,\n                time_values_id,\n                [self.names.TABLE, table_id],\n                [self.names.NAME, column_id],\n            ],\n        )\n\n    def rotating_time_vector(\n        self,\n        time_vector_id: str,\n        time_index_id: str,\n        time_values_id: str,\n    ) -&gt; None:\n        \"\"\"Append rotating time vector data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TIMEVECTOR,\n                self.names.ROTATINGTIMEVECTOR,\n                time_vector_id,\n                [self.names.TIMEINDEX, time_index_id],\n                [self.names.TIMEVALUES, time_values_id],\n            ],\n        )\n\n    def one_year_time_vector(\n        self,\n        time_vector_id: str,\n        time_index_id: str,\n        time_values_id: str,\n    ) -&gt; None:\n        \"\"\"Append one year time vector data element.\"\"\"\n        self.data_elements.append(\n            [\n                self.names.TIMEVECTOR,\n                self.names.ONEYEARTIMEVECTOR,\n                time_vector_id,\n                [self.names.TIMEINDEX, time_index_id],\n                [self.names.TIMEVALUES, time_values_id],\n            ],\n        )\n</code></pre> <code></code> <code>__init__(names: JulESNames) -&gt; None</code> <p>Initialize new DataElementAppender.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def __init__(self, names: JulESNames) -&gt; None:\n    \"\"\"Initialize new DataElementAppender.\"\"\"\n    self.data_elements: list = []\n    self.names: JulESNames = names\n</code></pre> <code></code> <code>base_arrow(arrow_id: str, flow_id: str, balance_id: str, is_ingoing: bool, conversion: str | float) -&gt; None</code> <p>Append base arrow data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def base_arrow(\n    self,\n    arrow_id: str,\n    flow_id: str,\n    balance_id: str,\n    is_ingoing: bool,\n    conversion: str | float,\n) -&gt; None:\n    \"\"\"Append base arrow data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.ARROW,\n            self.names.BASEARROW,\n            arrow_id,\n            [self.names.FLOW, flow_id],\n            [self.names.BALANCE, balance_id],\n            [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_ingoing else self.names.DIRECTIONOUT],\n            [self.names.CONVERSION, conversion],\n        ],\n    )\n</code></pre> <code></code> <code>base_flow(flow_id: str) -&gt; None</code> <p>Append base flow data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def base_flow(self, flow_id: str) -&gt; None:\n    \"\"\"Append base flow data element.\"\"\"\n    self.data_elements.append([self.names.FLOW, self.names.BASEFLOW, flow_id])\n</code></pre> <code></code> <code>base_rhs_term(rhs_term_id: str, balance_id: str, is_ingoing: bool, unit_param_id: str) -&gt; None</code> <p>Append base rhs term data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def base_rhs_term(\n    self,\n    rhs_term_id: str,\n    balance_id: str,\n    is_ingoing: bool,\n    unit_param_id: str,\n) -&gt; None:\n    \"\"\"Append base rhs term data element.\"\"\"\n    # TODO: Add residualhint # noqa FIX002\n    self.data_elements.append(\n        [\n            self.names.RHSTERM,\n            self.names.BASERHSTERM,\n            rhs_term_id,\n            [self.names.BALANCE, balance_id],\n            [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_ingoing else self.names.DIRECTIONOUT],\n            [self.names.PARAM, unit_param_id],\n        ],\n    )\n</code></pre> <code></code> <code>base_storage(storage_id: str, balance_id: str) -&gt; None</code> <p>Append base storage data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def base_storage(\n    self,\n    storage_id: str,\n    balance_id: str,\n) -&gt; None:\n    \"\"\"Append base storage data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.STORAGE,\n            self.names.BASESTORAGE,\n            storage_id,\n            [self.names.BALANCE, balance_id],\n        ],\n    )\n</code></pre> <code></code> <code>base_table(table_id: str, path_table: str | Path, column_names: list[str]) -&gt; None</code> <p>Append base table data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def base_table(\n    self,\n    table_id: str,\n    path_table: str | Path,\n    column_names: list[str],\n) -&gt; None:\n    \"\"\"Append base table data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TABLE,\n            self.names.BASETABLE,\n            table_id,\n            [self.names.MATRIX, str(path_table)],\n            [self.names.NAMES, column_names],\n        ],\n    )\n</code></pre> <code></code> <code>column_time_values(time_values_id: str, table_id: str, column_id: str) -&gt; None</code> <p>Append column time values data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def column_time_values(\n    self,\n    time_values_id: str,\n    table_id: str,\n    column_id: str,\n) -&gt; None:\n    \"\"\"Append column time values data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TIMEVALUES,\n            self.names.COLUMNTIMEVALUES,\n            time_values_id,\n            [self.names.TABLE, table_id],\n            [self.names.NAME, column_id],\n        ],\n    )\n</code></pre> <code></code> <code>cost_term(cost_term_id: str, flow_or_storage_id: str, is_flow: str, is_cost: bool, cost: str | float) -&gt; None</code> <p>Append cost term data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def cost_term(\n    self,\n    cost_term_id: str,\n    flow_or_storage_id: str,\n    is_flow: str,\n    is_cost: bool,\n    cost: str | float,\n) -&gt; None:\n    \"\"\"Append cost term data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.COST,\n            self.names.COSTTERM,\n            cost_term_id,\n            [self.names.DIRECTIONKEY, self.names.DIRECTIONIN if is_cost else self.names.DIRECTIONOUT],\n            [self.names.PARAM, cost],\n            [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n            [self.names.WHICHINSTANCE, flow_or_storage_id],\n        ],\n    )\n</code></pre> <code></code> <code>endogenous_balance(balance_id: str, commodiy: str) -&gt; None</code> <p>Append endogenous balance data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def endogenous_balance(\n    self,\n    balance_id: str,\n    commodiy: str,\n) -&gt; None:\n    \"\"\"Append endogenous balance data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.BALANCE,\n            self.names.BASEBALANCE,\n            balance_id,\n            [self.names.COMMODITY, commodiy],\n        ],\n    )\n</code></pre> <code></code> <code>exogenous_balance(balance_id: str, commodiy: str, price_param_id: str | float) -&gt; None</code> <p>Append exogenous balance data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def exogenous_balance(\n    self,\n    balance_id: str,\n    commodiy: str,\n    price_param_id: str | float,\n) -&gt; None:\n    \"\"\"Append exogenous balance data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.BALANCE,\n            self.names.EXOGENBALANCE,\n            balance_id,\n            [self.names.COMMODITY, commodiy],\n            [self.names.PRICE, price_param_id],\n        ],\n    )\n</code></pre> <code></code> <code>global_eneq(global_eneq_id: str, balance_id: str, value: float) -&gt; None</code> <p>Append global energy equivalent data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def global_eneq(\n    self,\n    global_eneq_id: str,\n    balance_id: str,\n    value: float,\n) -&gt; None:\n    \"\"\"Append global energy equivalent data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.METADATA,\n            self.names.GLOBALENEQ,\n            global_eneq_id,\n            [self.names.BALANCE, balance_id],\n            [self.names.VALUE, value],\n        ],\n    )\n</code></pre> <code></code> <code>lower_zero_capacity(lower_bound_id: str, is_flow: bool, flow_or_storage_id: str) -&gt; None</code> <p>Append zero lower capacity data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def lower_zero_capacity(\n    self,\n    lower_bound_id: str,\n    is_flow: bool,\n    flow_or_storage_id: str,\n) -&gt; None:\n    \"\"\"Append zero lower capacity data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.CAPACITY,\n            self.names.LOWERZEROCAPACITY,\n            lower_bound_id,\n            [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n            [self.names.WHICHINSTANCE, flow_or_storage_id],\n        ],\n    )\n</code></pre> <code></code> <code>mean_series_param(param_id: str, level: str | float, profile: str | float) -&gt; None</code> <p>Append mean series param data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def mean_series_param(\n    self,\n    param_id: str,\n    level: str | float,\n    profile: str | float,\n) -&gt; None:\n    \"\"\"Append mean series param data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.PARAM,\n            self.names.MEANSERIESPARAM,\n            param_id,\n            [self.names.LEVEL, level],\n            [self.names.PROFILE, profile],\n        ],\n    )\n</code></pre> <code></code> <code>ms_time_delta(time_delta_id: str, milliseconds: float) -&gt; None</code> <p>Append ms time delta data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def ms_time_delta(\n    self,\n    time_delta_id: str,\n    milliseconds: float,\n) -&gt; None:\n    \"\"\"Append ms time delta data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TIMEDELTA,\n            self.names.MSTIMEDELTA,\n            time_delta_id,\n            [self.names.PERIOD, milliseconds],\n        ],\n    )\n</code></pre> <code></code> <code>one_year_time_vector(time_vector_id: str, time_index_id: str, time_values_id: str) -&gt; None</code> <p>Append one year time vector data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def one_year_time_vector(\n    self,\n    time_vector_id: str,\n    time_index_id: str,\n    time_values_id: str,\n) -&gt; None:\n    \"\"\"Append one year time vector data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TIMEVECTOR,\n            self.names.ONEYEARTIMEVECTOR,\n            time_vector_id,\n            [self.names.TIMEINDEX, time_index_id],\n            [self.names.TIMEVALUES, time_values_id],\n        ],\n    )\n</code></pre> <code></code> <code>positive_capacity(bound_id: str, is_flow: bool, flow_or_storage_id: str, is_lower_bound: bool, param_id: str) -&gt; None</code> <p>Append positive capacity data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def positive_capacity(\n    self,\n    bound_id: str,\n    is_flow: bool,\n    flow_or_storage_id: str,\n    is_lower_bound: bool,\n    param_id: str,\n) -&gt; None:\n    \"\"\"Append positive capacity data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.CAPACITY,\n            self.names.POSITIVECAPACITY,\n            bound_id,\n            [self.names.WHICHCONCEPT, self.names.FLOW if is_flow else self.names.STORAGE],\n            [self.names.WHICHINSTANCE, flow_or_storage_id],\n            [self.names.BOUNDKEY, self.names.BOUNDLOWER if is_lower_bound else self.names.BOUNDUPPER],\n            [self.names.PARAM, param_id],\n        ],\n    )\n</code></pre> <code></code> <code>range_time_index(time_index_id: str, start_time: datetime, num_steps: int, time_delta_id: str) -&gt; None</code> <p>Append range time index data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def range_time_index(\n    self,\n    time_index_id: str,\n    start_time: datetime,\n    num_steps: int,\n    time_delta_id: str,\n) -&gt; None:\n    \"\"\"Append range time index data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TIMEINDEX,\n            self.names.RANGETIMEINDEX,\n            time_index_id,\n            [self.names.START, start_time.strftime(r\"%Y-%m-%d %H:%M:%S\")],\n            [self.names.STEPS, num_steps],\n            [self.names.DELTA, time_delta_id],\n        ],\n    )\n</code></pre> <code></code> <code>rotating_time_vector(time_vector_id: str, time_index_id: str, time_values_id: str) -&gt; None</code> <p>Append rotating time vector data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def rotating_time_vector(\n    self,\n    time_vector_id: str,\n    time_index_id: str,\n    time_values_id: str,\n) -&gt; None:\n    \"\"\"Append rotating time vector data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.TIMEVECTOR,\n            self.names.ROTATINGTIMEVECTOR,\n            time_vector_id,\n            [self.names.TIMEINDEX, time_index_id],\n            [self.names.TIMEVALUES, time_values_id],\n        ],\n    )\n</code></pre> <code></code> <code>storage_hint(storage_id: str, period: int) -&gt; None</code> <p>Append storage hint data element to indicate storage duration in milliseconds.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def storage_hint(self, storage_id: str, period: int) -&gt; None:\n    \"\"\"Append storage hint data element to indicate storage duration in milliseconds.\"\"\"\n    storage_hint_id = f\"StorageHint_{storage_id}\"\n    self.data_elements.append(\n        [\n            self.names.METADATA,\n            self.names.STORAGEHINT,\n            storage_hint_id,\n            [self.names.STORAGE, storage_id],\n            [self.names.PERIOD, period],\n        ],\n    )\n</code></pre> <code></code> <code>unit_param(unit_param_id: str, series_param_id: str, info: ComponentInfo) -&gt; None</code> <p>Append unit param data element.</p> Source code in <code>framjules/solve_handler/build_handler/DataElementAppender.py</code> <pre><code>def unit_param(\n    self,\n    unit_param_id: str,\n    series_param_id: str,\n    info: ComponentInfo,\n) -&gt; None:\n    \"\"\"Append unit param data element.\"\"\"\n    self.data_elements.append(\n        [\n            self.names.PARAM,\n            info.unit_param_type,\n            unit_param_id,\n            [self.names.PARAM, series_param_id],\n        ],\n    )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.build_handler.SerialBuildHandler","title":"<code>SerialBuildHandler</code>","text":""},{"location":"reference/#framjules.solve_handler.build_handler.SerialBuildHandler.SerialBuildHandler","title":"<code>SerialBuildHandler</code>","text":"<p>               Bases: <code>BuildHandler</code></p> <p>Specialized methods for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>class SerialBuildHandler(BuildHandler):\n    \"\"\"Specialized methods for serial simulation.\"\"\"\n\n    _PROFILE_VALUE_WHEN_ZERO = 1.0\n\n    def __init__(\n        self,\n        folder: Path,\n        config: JulESConfig,\n        names: JulESNames,\n        domain_models: DomainModels,\n        graphs: NodeFlowGraphs,\n        graph_infos: GraphInfos,\n        db: QueryDB,\n    ) -&gt; None:\n        \"\"\"See BuildHandler.\"\"\"\n        super().__init__(folder, config, names, domain_models, graphs, graph_infos, db)\n\n        # some validations spesific to serial simulation\n        self._data_period = self.config.get_data_period()\n        self._check_type(self._data_period, SinglePeriodTimeIndex)\n\n        start_year, num_years = self.config.get_weather_years()\n        self._avg_year_range = AverageYearRange(start_year=start_year, num_years=num_years)\n        if self._avg_year_range.is_52_week_years():\n            message = \"Expected AverageYearRange to have is_52_week_years() == False.\"\n            raise ValueError(message)\n\n        self._is_float32 = self.config.is_float32()\n\n    def get_attribute_level(\n        self,\n        root_id: str,\n        attribute: LevelProfile,\n        target_unit: str | None,\n    ) -&gt; float:\n        \"\"\"Get level value.\"\"\"\n        is_max_level = False\n        value = attribute.get_data_value(\n            db=self.db,\n            unit=target_unit,\n            level_period=self._data_period,\n            scenario_horizon=self._avg_year_range,\n            is_max_level=is_max_level,\n        )\n        if value &lt; 0:\n            self.send_warning_event(f\"Attribute {root_id} of type {type(attribute).__name__} returned {value}\")\n        return value\n\n    def get_attribute_profile(\n        self,\n        root_id: str,\n        attribute: LevelProfile | Arrow,\n        default: float,\n        unit: str | None,\n        info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"Add profile vector to timevectors and return profile_id.\"\"\"\n        if not attribute.has_profile():\n            return default\n\n        profile_id = f\"{root_id}_profile\"\n\n        timeindex = self._find_profile_timeindex(attribute, info.has_storage_resolution)\n\n        vector: NDArray = attribute.get_scenario_vector(\n            db=self.db,\n            level_period=self._data_period,\n            scenario_horizon=timeindex,\n            is_float32=self._is_float32,\n            unit=unit,\n        )\n        vector = np.round(vector, decimals=6)  # avoid very small numerical noise, e.g negative prices from jules run\n\n        if np.isnan(vector).any():\n            message = (\n                f\"Profile {profile_id} in time index {timeindex} contains NaN values. \"\n                \"This may indicate a problem with the data or the configuration.\"\n            )\n            raise ValueError(message)\n\n        if (vector &lt; 0).any():\n            message = (\n                f\"Profile {profile_id} in time index {timeindex} has negative values. \"\n                \"This may indicate a problem with the data or the configuration.\"\n            )\n            raise ValueError(message)\n\n        denominator = vector.mean()\n\n        if denominator == 0:\n            vector.fill(self._PROFILE_VALUE_WHEN_ZERO)\n        else:\n            np.multiply(vector, 1 / denominator, out=vector)\n\n        self.timevectors[timeindex][profile_id] = vector\n\n        return profile_id\n\n    def _find_profile_timeindex(\n        self,\n        attribute: LevelProfile | Arrow,\n        has_storage_resolution: bool,\n    ) -&gt; ProfileTimeIndex:\n        is_52_week_years = False\n\n        start_year, num_years = self.config.get_weather_years()\n\n        if has_storage_resolution:\n            period_duration = timedelta(minutes=self.config.get_time_resolution().get_clearing_storage_minutes())\n        else:\n            period_duration = timedelta(minutes=self.config.get_time_resolution().get_clearing_market_minutes())\n\n        fallback = ProfileTimeIndex(\n            start_year,\n            num_years,\n            period_duration=self._get_closest_valid_profile_duration(period_duration),\n            is_52_week_years=is_52_week_years,\n        )\n\n        ix_set: set[FixedFrequencyTimeIndex] = attribute.get_profile_timeindex_set(db=self.db)\n        if not all(isinstance(ix, FixedFrequencyTimeIndex) for ix in ix_set):\n            return fallback\n\n        is_one_year = all(ix.is_one_year() for ix in ix_set)\n\n        candidate = min((ix for ix in ix_set), key=lambda ix: ix.get_period_duration().total_seconds())\n\n        s_fallback = fallback.get_period_duration().total_seconds()\n        s_candidate = candidate.get_period_duration().total_seconds()\n        best_duration = (candidate if s_fallback &lt; s_candidate else fallback).get_period_duration()\n\n        if is_one_year:\n            return ProfileTimeIndex(\n                start_year=candidate.get_start_time().isocalendar().year,\n                num_years=1,\n                period_duration=self._get_closest_valid_profile_duration(best_duration),\n                is_52_week_years=is_52_week_years,\n            )\n        return ProfileTimeIndex(\n            start_year=start_year,\n            num_years=num_years,\n            period_duration=self._get_closest_valid_profile_duration(best_duration),\n            is_52_week_years=is_52_week_years,\n        )\n\n    def get_price_level(self, root_id: str, price: Price, info: ComponentInfo) -&gt; float:\n        \"\"\"get_price_level for serial simulation.\"\"\"\n        return self.get_attribute_level(root_id, price, info.unit_price)\n\n    def get_cost_term_level(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; float:\n        \"\"\"get_cost_term_level for serial simulation.\"\"\"\n        return self.get_attribute_level(root_id, cost_term, info.unit_cost)\n\n    def get_capacity_level(self, root_id: str, capacity: StockVolume | FlowVolume, info: ComponentInfo) -&gt; str | float:\n        \"\"\"get_capacity_level for serial simulation. Handles stock or flow based on info.\"\"\"\n        return self.get_attribute_level(root_id, capacity, info.unit_flow if info.is_flow else info.unit_stock)\n\n    def get_coefficient_level(self, root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float:\n        \"\"\"get_coefficient_level for serial simulation.\"\"\"\n        return self.get_attribute_level(root_id, arrow, info.unit_coeffs[arrow.get_node()])\n\n    def get_price_profile(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n        \"\"\"get_price_profile for serial simulation.\"\"\"\n        return self.get_attribute_profile(root_id, price, 1.0, info.unit_price, info)\n\n    def get_cost_term_profile(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n        \"\"\"get_cost_term_profile for serial simulation.\"\"\"\n        return self.get_attribute_profile(root_id, cost_term, 1.0, info.unit_cost, info)\n\n    def get_capacity_profile(\n        self,\n        root_id: str,\n        capacity: FlowVolume | StockVolume,\n        info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"get_capacity_profile for serial simulation.\"\"\"\n        unit = info.unit_flow if info.is_flow else info.unit_stock\n        return self.get_attribute_profile(root_id, capacity, 1.0, unit, info)\n\n    def get_rhs_term_level(\n        self,\n        rhs_term_id: str,\n        flow: Flow,\n        arrow: Arrow,\n        flow_info: ComponentInfo,\n    ) -&gt; float:\n        \"\"\"Convert volume (main node) to target node volume.\n\n        This may scale the volume using arrow coefficient,\n        e.g. due to transportation loss.\n\n        This may also change unit, if target node belongs to\n        different commodity than main node, such as for hydropower.\n        \"\"\"\n        coeff_value = self.get_coefficient_level(rhs_term_id, arrow, flow_info)\n\n        volume = flow.get_volume()\n        if volume.has_level():\n            volume_value = self.get_attribute_level(\n                root_id=rhs_term_id,\n                attribute=volume,\n                target_unit=flow_info.unit_flow,\n            )\n        else:\n            max_cap = flow.get_max_capacity()\n            min_cap = flow.get_min_capacity()\n            if max_cap is not None and max_cap == min_cap:\n                volume_value = self.get_attribute_level(\n                    root_id=rhs_term_id,\n                    attribute=max_cap,\n                    target_unit=flow_info.unit_flow,\n                )\n            else:\n                message = f\"{rhs_term_id} is not exogenous\"\n                raise ValueError(message)\n\n        if coeff_value == 0:\n            message = (\n                f\"Got zero coeff_value for {rhs_term_id}.\\n\"\n                f\"volume_value = {volume_value}\\n\"\n                f\"coeff_value = {coeff_value}\\n\"\n                f\"flow.get_main_node() = {flow.get_main_node()}\\n\"\n                f\"arrow.get_node() = {arrow.get_node()}\\n\"\n            )\n            raise RuntimeError(message)\n\n        return volume_value / coeff_value  # convert from main_unit to target_unit\n\n    def _rank_profile_timeindex(self, ix: ProfileTimeIndex) -&gt; tuple[bool, float]:\n        return ix.is_one_year(), ix.get_period_duration().total_seconds()\n\n    def _select_profile_timeindex(self, *candidates: ProfileTimeIndex) -&gt; ProfileTimeIndex:\n        \"\"\"Select the one with not-is_one_year (if any) and finest period duration.\"\"\"\n        return min(candidates, key=self._rank_profile_timeindex)\n\n    def get_rhs_term_profile(\n        self,\n        rhs_term_id: str,\n        flow: Flow,\n        arrow: Arrow,\n        flow_info: ComponentInfo,\n    ) -&gt; str | float:\n        \"\"\"Create profile (possibly) representing volume_profile * coefficient_profile.\"\"\"\n        volume = flow.get_volume()\n\n        if not volume.has_profile():\n            volume = flow.get_max_capacity()\n\n        not_volume_profile = volume is None or not volume.has_profile()\n        not_arrow_profile = not arrow.has_profile()\n        has_volume_profile = not not_volume_profile\n        has_arrow_profile = not not_arrow_profile\n\n        if not_volume_profile and not_arrow_profile:\n            return 1.0\n\n        if has_volume_profile and not_arrow_profile:\n            return self.get_attribute_profile(\n                rhs_term_id,\n                attribute=volume,\n                default=1.0,\n                unit=flow_info.unit_flow,\n                info=flow_info,\n            )\n\n        if not_volume_profile and has_arrow_profile:\n            unit = flow_info.unit_coeffs[arrow.get_node()]\n            return self.get_attribute_profile(\n                rhs_term_id,\n                attribute=arrow,\n                default=1.0,\n                unit=unit,\n                info=flow_info,\n            )\n\n        # Here we get both profiles (volume and coefficient) and muliply them\n        # together and store the resulting product profile in self.timevectors\n\n        profile_id = f\"{rhs_term_id}_profile\"\n\n        timeindex = self._select_profile_timeindex(\n            self._find_profile_timeindex(volume, flow_info.has_storage_resolution),\n            self._find_profile_timeindex(arrow, flow_info.has_storage_resolution),\n        )\n\n        x: NDArray = volume.get_scenario_vector(\n            db=self.db,\n            level_period=self._data_period,\n            scenario_horizon=timeindex,\n            is_float32=self._is_float32,\n            unit=flow_info.unit_flow,\n        )\n\n        y: NDArray = arrow.get_scenario_vector(\n            db=self.db,\n            level_period=self._data_period,\n            scenario_horizon=timeindex,\n            is_float32=self._is_float32,\n            unit=flow_info.unit_coeffs[arrow.get_node()],\n        )\n\n        x_mean = x.mean()\n        y_mean = y.mean()\n        if x_mean == 0 or y_mean == 0:\n            x.fill(self._PROFILE_VALUE_WHEN_ZERO)\n            return x\n\n        np.multiply(x, 1.0 / x_mean, out=x)\n        np.multiply(y, 1.0 / y_mean, out=y)\n\n        np.multiply(x, y, out=x)\n\n        self.timevectors[timeindex][profile_id] = x\n\n        return profile_id\n</code></pre> <code></code> <code>__init__(folder: Path, config: JulESConfig, names: JulESNames, domain_models: DomainModels, graphs: NodeFlowGraphs, graph_infos: GraphInfos, db: QueryDB) -&gt; None</code> <p>See BuildHandler.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def __init__(\n    self,\n    folder: Path,\n    config: JulESConfig,\n    names: JulESNames,\n    domain_models: DomainModels,\n    graphs: NodeFlowGraphs,\n    graph_infos: GraphInfos,\n    db: QueryDB,\n) -&gt; None:\n    \"\"\"See BuildHandler.\"\"\"\n    super().__init__(folder, config, names, domain_models, graphs, graph_infos, db)\n\n    # some validations spesific to serial simulation\n    self._data_period = self.config.get_data_period()\n    self._check_type(self._data_period, SinglePeriodTimeIndex)\n\n    start_year, num_years = self.config.get_weather_years()\n    self._avg_year_range = AverageYearRange(start_year=start_year, num_years=num_years)\n    if self._avg_year_range.is_52_week_years():\n        message = \"Expected AverageYearRange to have is_52_week_years() == False.\"\n        raise ValueError(message)\n\n    self._is_float32 = self.config.is_float32()\n</code></pre> <code></code> <code>get_attribute_level(root_id: str, attribute: LevelProfile, target_unit: str | None) -&gt; float</code> <p>Get level value.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_attribute_level(\n    self,\n    root_id: str,\n    attribute: LevelProfile,\n    target_unit: str | None,\n) -&gt; float:\n    \"\"\"Get level value.\"\"\"\n    is_max_level = False\n    value = attribute.get_data_value(\n        db=self.db,\n        unit=target_unit,\n        level_period=self._data_period,\n        scenario_horizon=self._avg_year_range,\n        is_max_level=is_max_level,\n    )\n    if value &lt; 0:\n        self.send_warning_event(f\"Attribute {root_id} of type {type(attribute).__name__} returned {value}\")\n    return value\n</code></pre> <code></code> <code>get_attribute_profile(root_id: str, attribute: LevelProfile | Arrow, default: float, unit: str | None, info: ComponentInfo) -&gt; str | float</code> <p>Add profile vector to timevectors and return profile_id.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_attribute_profile(\n    self,\n    root_id: str,\n    attribute: LevelProfile | Arrow,\n    default: float,\n    unit: str | None,\n    info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"Add profile vector to timevectors and return profile_id.\"\"\"\n    if not attribute.has_profile():\n        return default\n\n    profile_id = f\"{root_id}_profile\"\n\n    timeindex = self._find_profile_timeindex(attribute, info.has_storage_resolution)\n\n    vector: NDArray = attribute.get_scenario_vector(\n        db=self.db,\n        level_period=self._data_period,\n        scenario_horizon=timeindex,\n        is_float32=self._is_float32,\n        unit=unit,\n    )\n    vector = np.round(vector, decimals=6)  # avoid very small numerical noise, e.g negative prices from jules run\n\n    if np.isnan(vector).any():\n        message = (\n            f\"Profile {profile_id} in time index {timeindex} contains NaN values. \"\n            \"This may indicate a problem with the data or the configuration.\"\n        )\n        raise ValueError(message)\n\n    if (vector &lt; 0).any():\n        message = (\n            f\"Profile {profile_id} in time index {timeindex} has negative values. \"\n            \"This may indicate a problem with the data or the configuration.\"\n        )\n        raise ValueError(message)\n\n    denominator = vector.mean()\n\n    if denominator == 0:\n        vector.fill(self._PROFILE_VALUE_WHEN_ZERO)\n    else:\n        np.multiply(vector, 1 / denominator, out=vector)\n\n    self.timevectors[timeindex][profile_id] = vector\n\n    return profile_id\n</code></pre> <code></code> <code>get_capacity_level(root_id: str, capacity: StockVolume | FlowVolume, info: ComponentInfo) -&gt; str | float</code> <p>get_capacity_level for serial simulation. Handles stock or flow based on info.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_capacity_level(self, root_id: str, capacity: StockVolume | FlowVolume, info: ComponentInfo) -&gt; str | float:\n    \"\"\"get_capacity_level for serial simulation. Handles stock or flow based on info.\"\"\"\n    return self.get_attribute_level(root_id, capacity, info.unit_flow if info.is_flow else info.unit_stock)\n</code></pre> <code></code> <code>get_capacity_profile(root_id: str, capacity: FlowVolume | StockVolume, info: ComponentInfo) -&gt; str | float</code> <p>get_capacity_profile for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_capacity_profile(\n    self,\n    root_id: str,\n    capacity: FlowVolume | StockVolume,\n    info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"get_capacity_profile for serial simulation.\"\"\"\n    unit = info.unit_flow if info.is_flow else info.unit_stock\n    return self.get_attribute_profile(root_id, capacity, 1.0, unit, info)\n</code></pre> <code></code> <code>get_coefficient_level(root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float</code> <p>get_coefficient_level for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_coefficient_level(self, root_id: str, arrow: Arrow, info: ComponentInfo) -&gt; str | float:\n    \"\"\"get_coefficient_level for serial simulation.\"\"\"\n    return self.get_attribute_level(root_id, arrow, info.unit_coeffs[arrow.get_node()])\n</code></pre> <code></code> <code>get_cost_term_level(root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; float</code> <p>get_cost_term_level for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_cost_term_level(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; float:\n    \"\"\"get_cost_term_level for serial simulation.\"\"\"\n    return self.get_attribute_level(root_id, cost_term, info.unit_cost)\n</code></pre> <code></code> <code>get_cost_term_profile(root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float</code> <p>get_cost_term_profile for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_cost_term_profile(self, root_id: str, cost_term: Cost, info: ComponentInfo) -&gt; str | float:\n    \"\"\"get_cost_term_profile for serial simulation.\"\"\"\n    return self.get_attribute_profile(root_id, cost_term, 1.0, info.unit_cost, info)\n</code></pre> <code></code> <code>get_price_level(root_id: str, price: Price, info: ComponentInfo) -&gt; float</code> <p>get_price_level for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_price_level(self, root_id: str, price: Price, info: ComponentInfo) -&gt; float:\n    \"\"\"get_price_level for serial simulation.\"\"\"\n    return self.get_attribute_level(root_id, price, info.unit_price)\n</code></pre> <code></code> <code>get_price_profile(root_id: str, price: Price, info: ComponentInfo) -&gt; str | float</code> <p>get_price_profile for serial simulation.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_price_profile(self, root_id: str, price: Price, info: ComponentInfo) -&gt; str | float:\n    \"\"\"get_price_profile for serial simulation.\"\"\"\n    return self.get_attribute_profile(root_id, price, 1.0, info.unit_price, info)\n</code></pre> <code></code> <code>get_rhs_term_level(rhs_term_id: str, flow: Flow, arrow: Arrow, flow_info: ComponentInfo) -&gt; float</code> <p>Convert volume (main node) to target node volume.</p> <p>This may scale the volume using arrow coefficient, e.g. due to transportation loss.</p> <p>This may also change unit, if target node belongs to different commodity than main node, such as for hydropower.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_rhs_term_level(\n    self,\n    rhs_term_id: str,\n    flow: Flow,\n    arrow: Arrow,\n    flow_info: ComponentInfo,\n) -&gt; float:\n    \"\"\"Convert volume (main node) to target node volume.\n\n    This may scale the volume using arrow coefficient,\n    e.g. due to transportation loss.\n\n    This may also change unit, if target node belongs to\n    different commodity than main node, such as for hydropower.\n    \"\"\"\n    coeff_value = self.get_coefficient_level(rhs_term_id, arrow, flow_info)\n\n    volume = flow.get_volume()\n    if volume.has_level():\n        volume_value = self.get_attribute_level(\n            root_id=rhs_term_id,\n            attribute=volume,\n            target_unit=flow_info.unit_flow,\n        )\n    else:\n        max_cap = flow.get_max_capacity()\n        min_cap = flow.get_min_capacity()\n        if max_cap is not None and max_cap == min_cap:\n            volume_value = self.get_attribute_level(\n                root_id=rhs_term_id,\n                attribute=max_cap,\n                target_unit=flow_info.unit_flow,\n            )\n        else:\n            message = f\"{rhs_term_id} is not exogenous\"\n            raise ValueError(message)\n\n    if coeff_value == 0:\n        message = (\n            f\"Got zero coeff_value for {rhs_term_id}.\\n\"\n            f\"volume_value = {volume_value}\\n\"\n            f\"coeff_value = {coeff_value}\\n\"\n            f\"flow.get_main_node() = {flow.get_main_node()}\\n\"\n            f\"arrow.get_node() = {arrow.get_node()}\\n\"\n        )\n        raise RuntimeError(message)\n\n    return volume_value / coeff_value  # convert from main_unit to target_unit\n</code></pre> <code></code> <code>get_rhs_term_profile(rhs_term_id: str, flow: Flow, arrow: Arrow, flow_info: ComponentInfo) -&gt; str | float</code> <p>Create profile (possibly) representing volume_profile * coefficient_profile.</p> Source code in <code>framjules/solve_handler/build_handler/SerialBuildHandler.py</code> <pre><code>def get_rhs_term_profile(\n    self,\n    rhs_term_id: str,\n    flow: Flow,\n    arrow: Arrow,\n    flow_info: ComponentInfo,\n) -&gt; str | float:\n    \"\"\"Create profile (possibly) representing volume_profile * coefficient_profile.\"\"\"\n    volume = flow.get_volume()\n\n    if not volume.has_profile():\n        volume = flow.get_max_capacity()\n\n    not_volume_profile = volume is None or not volume.has_profile()\n    not_arrow_profile = not arrow.has_profile()\n    has_volume_profile = not not_volume_profile\n    has_arrow_profile = not not_arrow_profile\n\n    if not_volume_profile and not_arrow_profile:\n        return 1.0\n\n    if has_volume_profile and not_arrow_profile:\n        return self.get_attribute_profile(\n            rhs_term_id,\n            attribute=volume,\n            default=1.0,\n            unit=flow_info.unit_flow,\n            info=flow_info,\n        )\n\n    if not_volume_profile and has_arrow_profile:\n        unit = flow_info.unit_coeffs[arrow.get_node()]\n        return self.get_attribute_profile(\n            rhs_term_id,\n            attribute=arrow,\n            default=1.0,\n            unit=unit,\n            info=flow_info,\n        )\n\n    # Here we get both profiles (volume and coefficient) and muliply them\n    # together and store the resulting product profile in self.timevectors\n\n    profile_id = f\"{rhs_term_id}_profile\"\n\n    timeindex = self._select_profile_timeindex(\n        self._find_profile_timeindex(volume, flow_info.has_storage_resolution),\n        self._find_profile_timeindex(arrow, flow_info.has_storage_resolution),\n    )\n\n    x: NDArray = volume.get_scenario_vector(\n        db=self.db,\n        level_period=self._data_period,\n        scenario_horizon=timeindex,\n        is_float32=self._is_float32,\n        unit=flow_info.unit_flow,\n    )\n\n    y: NDArray = arrow.get_scenario_vector(\n        db=self.db,\n        level_period=self._data_period,\n        scenario_horizon=timeindex,\n        is_float32=self._is_float32,\n        unit=flow_info.unit_coeffs[arrow.get_node()],\n    )\n\n    x_mean = x.mean()\n    y_mean = y.mean()\n    if x_mean == 0 or y_mean == 0:\n        x.fill(self._PROFILE_VALUE_WHEN_ZERO)\n        return x\n\n    np.multiply(x, 1.0 / x_mean, out=x)\n    np.multiply(y, 1.0 / y_mean, out=y)\n\n    np.multiply(x, y, out=x)\n\n    self.timevectors[timeindex][profile_id] = x\n\n    return profile_id\n</code></pre>"},{"location":"reference/#framjules.solve_handler.dataclasses","title":"<code>dataclasses</code>","text":""},{"location":"reference/#framjules.solve_handler.dataclasses.ComponentInfo","title":"<code>ComponentInfo</code>  <code>dataclass</code>","text":"<p>All derived info we need during solve.</p> Source code in <code>framjules/solve_handler/dataclasses.py</code> <pre><code>@dataclass\nclass ComponentInfo:\n    \"\"\"All derived info we need during solve.\"\"\"\n\n    is_flow: bool | None = None\n    is_node: bool | None = None\n    is_storage_node: bool | None = None\n    is_short_term_storage: bool | None = None  # used to find if the whole subsystem should be short term\n    is_market_node: bool | None = None\n    is_market_flow: bool | None = None\n    is_market_flow_to_exogenous: bool | None = None\n    is_sss_member: bool | None = None\n    is_exogenous: bool | None = None\n\n    has_storage_resolution: bool | None = None\n\n    jules_commodity: str | None = None\n    domain_commodity: str | None = None\n\n    # sss = storage subsystem\n    sss_id: str | None = None\n    sss_market_commodity: str | None = None\n    sss_members: set[str] | None = None\n    sss_is_short_term: int | None = None\n    sss_storage_duration: timedelta | None = None\n    sss_global_eneq_value: float | None = None\n    sss_global_eneq_unit: str | None = None\n    sss_initial_storage: float | None = None\n\n    jules_balance_id: str | None = None\n    jules_storage_id: str | None = None\n    jules_global_eneq_id: str | None = None\n\n    main_node_id: str | None = None\n    num_arrows: int | None = None\n\n    unit_price: str | None = None\n    unit_stock: str | None = None\n    unit_flow: str | None = None\n    unit_flow_result: str | None = None\n    unit_cost: str | None = None\n    unit_coeffs: dict[str : str | None] | None = None\n    unit_param_type: str | None = None\n    unit_param_unit_flow: str | None = None\n    unit_param_unit_stock: str | None = None\n\n    agg_storage_node_id: str | None = None\n    agg_market_node_id: str | None = None\n</code></pre>"},{"location":"reference/#framjules.solve_handler.dataclasses.DomainModels","title":"<code>DomainModels</code>  <code>dataclass</code>","text":"<p>Model instance for each term.</p> Source code in <code>framjules/solve_handler/dataclasses.py</code> <pre><code>@dataclass\nclass DomainModels:\n    \"\"\"Model instance for each term.\"\"\"\n\n    clearing: Model\n    short_term: Model\n    medium_term: Model\n    long_term: Model\n</code></pre>"},{"location":"reference/#framjules.solve_handler.dataclasses.GraphInfos","title":"<code>GraphInfos</code>  <code>dataclass</code>","text":"<p>Hold all component info for all graphs.</p> Source code in <code>framjules/solve_handler/dataclasses.py</code> <pre><code>@dataclass\nclass GraphInfos:\n    \"\"\"Hold all component info for all graphs.\"\"\"\n\n    clearing: dict[str, ComponentInfo]\n    short_term: dict[str, ComponentInfo]\n    medium_term: dict[str, ComponentInfo]\n    long_term: dict[str, ComponentInfo]\n</code></pre>"},{"location":"reference/#framjules.solve_handler.dataclasses.NodeFlowGraphs","title":"<code>NodeFlowGraphs</code>  <code>dataclass</code>","text":"<p>Node-Flow representation of domain model components via get_supported_components.</p> Source code in <code>framjules/solve_handler/dataclasses.py</code> <pre><code>@dataclass\nclass NodeFlowGraphs:\n    \"\"\"Node-Flow representation of domain model components via get_supported_components.\"\"\"\n\n    clearing: dict[str, Node | Flow]\n    short_term: dict[str, Node | Flow]\n    medium_term: dict[str, Node | Flow]\n    long_term: dict[str, Node | Flow]\n</code></pre>"},{"location":"reference/#framjules.solve_handler.results_handler","title":"<code>results_handler</code>","text":""},{"location":"reference/#framjules.solve_handler.results_handler.SerialResultsHandler","title":"<code>SerialResultsHandler</code>","text":"<p>Handling of results produced by running JulES in Serial mode.</p>"},{"location":"reference/#framjules.solve_handler.results_handler.SerialResultsHandler.SerialResultsHandler","title":"<code>SerialResultsHandler</code>","text":"<p>Set serial simulation results.</p> Source code in <code>framjules/solve_handler/results_handler/SerialResultsHandler.py</code> <pre><code>class SerialResultsHandler:\n    \"\"\"Set serial simulation results.\"\"\"\n\n    def __init__(\n        self,\n        folder: Path | str,\n        config: JulESConfig,\n        names: JulESNames,\n        graphs: NodeFlowGraphs,\n        graph_infos: GraphInfos,\n    ) -&gt; None:\n        \"\"\"Handle retrieval of results from a JulES Serial simulation.\n\n        Args:\n            folder (Path | str): Path to folder of the JulES simulation.\n            config (JulESConfig): Simulation config.\n            names (JulESNames): JulES namespace.\n            graphs (NodeFlowGraphs): Graphs used in the simulation.\n            graph_infos (GraphInfos): JulES specific info of each Component in the graphs.\n\n        \"\"\"\n        self._folder = Path(folder)\n        self._config = config\n        self._names = names\n\n        self.graphs = graphs\n        self.graph_infos = graph_infos\n\n        self.units = self._set_units()\n\n    def set_results(self) -&gt; None:\n        \"\"\"Set JulES results of all Components in the clearing graph.\"\"\"\n        is_whole_years = self._config.is_simulation_mode_serial()\n\n        loader = JulESH5TimeVectorLoader(\n            source=self._folder,\n            units=self.units,\n            relative_loc=self._names.FILENAME_H5_OUTPUT,\n            is_whole_years=is_whole_years,\n        )\n\n        supply_loader = SupplyJulESH5TimeVectorLoader(\n            source=self._folder,\n            units=self.units,\n            relative_loc=self._names.FILENAME_H5_OUTPUT,\n            is_whole_years=is_whole_years,\n        )\n\n        demand_loader = DemandJulESH5TimeVectorLoader(\n            source=self._folder,\n            units=self.units,\n            relative_loc=self._names.FILENAME_H5_OUTPUT,\n            is_whole_years=is_whole_years,\n        )\n\n        power_nodes = [\n            name\n            for name, c in self.graphs.clearing.items()\n            if isinstance(c, Node) and c.get_commodity() == JulESNames.POWER\n        ]\n        for name, c in self.graphs.clearing.items():\n            info: ComponentInfo = self.graph_infos.clearing[name]\n\n            if isinstance(c, Node):\n                if c.is_exogenous():\n                    continue\n                self._set_node_results(c, name, loader)\n            if isinstance(c, Flow):\n                self._set_flow_results(\n                    c,\n                    info,\n                    name,\n                    loader,\n                    power_nodes,\n                    supply_loader=supply_loader,\n                    demand_loader=demand_loader,\n                )\n\n    def _set_node_results(self, node: Node, name: str, loader: JulESH5TimeVectorLoader) -&gt; None:\n        info = self.graph_infos.clearing[name]\n\n        if info.is_market_node:\n            level, profile = self._get_decomposed_level_profile(name, loader, self.units[name])\n            price = node.get_price()\n            price.clear()\n            price.set_level(level)\n            price.set_profile(profile)\n\n        if info.is_storage_node:\n            level, profile = self._get_decomposed_level_profile(\n                info.jules_storage_id,\n                loader,\n                self.units[info.jules_storage_id],\n                is_stock=True,\n            )\n            storage = node.get_storage()\n            volume = storage.get_volume()\n            volume.clear()\n            volume.set_level(level)\n            volume.set_profile(profile)\n\n            level, profile = self._get_decomposed_level_profile(\n                info.jules_storage_id + \"_sv\",\n                loader,\n                self.units[info.jules_storage_id + \"_sv\"],\n            )\n            price = node.get_price()\n            price.clear()\n            price.set_level(level)\n            price.set_profile(profile)\n\n    def _set_flow_results(\n        self,\n        flow: Flow,\n        info: ComponentInfo,\n        name: str,\n        loader: JulESH5TimeVectorLoader,\n        power_nodes: list[str],\n        supply_loader: SupplyJulESH5TimeVectorLoader,\n        demand_loader: DemandJulESH5TimeVectorLoader,\n    ) -&gt; None:\n        if info.is_exogenous and flow.get_volume().get_level():\n            return\n        if info.is_exogenous:\n            max_capacity = flow.get_max_capacity()\n            level = max_capacity.get_level()\n            profile = max_capacity.get_profile()\n        else:\n            level, profile = self._get_decomposed_level_profile(\n                name,\n                loader,\n                self.units[name],\n                is_flow=True,\n            )\n        volume = flow.get_volume()\n        volume.clear()\n        volume.set_level(level)\n        volume.set_profile(profile)\n\n        # temporary workaround, will be fixed in future versions\n        n = len(name)\n        for arrow, volume in flow.get_arrow_volumes().items():\n            arrow_node = arrow.get_node()\n            if arrow_node not in power_nodes:\n                continue\n\n            is_supply = arrow.is_ingoing()\n            loader = supply_loader if is_supply else demand_loader\n\n            unit_flow = self.units[name]\n            unit_coeff = info.unit_coeffs[arrow.get_node()]\n            unit = f\"({unit_flow})*({unit_coeff})\" if unit_coeff is not None else unit_flow\n\n            for i in range(n):\n                subname = name[: n - i]\n                level, profile = self._get_decomposed_level_profile(\n                    subname,\n                    loader,\n                    unit,\n                    is_flow=True,\n                )\n                volume.clear()\n                volume.set_level(level)\n                volume.set_profile(profile)\n                break\n\n    def _get_decomposed_level_profile(\n        self,\n        name: str,\n        loader: JulESH5TimeVectorLoader,\n        unit: str | None = None,\n        is_flow: bool = False,\n        is_stock: bool = False,\n    ) -&gt; tuple[Expr, Expr]:\n        \"\"\"Decompose result vector into level and profile expressions.\n\n        Note! Support for negative prices will come in the next version.\n        \"\"\"\n        timevector = self._get_timevector(jules_id=name, loader=loader)\n\n        mean_value = timevector.get_vector(self._config.is_float32()).mean()\n\n        scale = float(1 / mean_value) if mean_value != 0 else 1.0\n        mean_one_profile_timevector = LinearTransformTimeVector(\n            timevector=timevector,\n            scale=scale,\n            shift=0.0,\n            unit=None,\n            is_zero_one_profile=False,\n        )\n\n        profile_expr = None\n        reference_period = None\n        if mean_value != 0:\n            reference_period = self._get_reference_period()\n            profile_expr = ensure_expr(mean_one_profile_timevector, is_profile=True)\n\n            level_timevector = ConstantTimeVector(\n                scalar=mean_value,\n                unit=unit,\n                is_max_level=False,\n                reference_period=reference_period,\n            )\n        else:\n            level_timevector = ConstantTimeVector(\n                scalar=0.0,\n                unit=unit,\n                is_max_level=True,\n            )\n            profile_expr = ensure_expr(\n                ConstantTimeVector(\n                    scalar=1.0,\n                    is_zero_one_profile=True,\n                ),\n                is_profile=True,\n            )\n\n        level_expr = ensure_expr(\n            level_timevector,\n            is_level=True,\n            is_flow=is_flow,\n            is_stock=is_stock,\n            profile=profile_expr,\n        )\n\n        return level_expr, profile_expr\n\n    def _set_units(self) -&gt; dict[str : str | None]:\n        units = {name: info.unit_price for name, info in self.graph_infos.clearing.items() if info.is_market_node}\n        units.update(\n            {\n                info.jules_storage_id: info.unit_stock\n                for info in self.graph_infos.clearing.values()\n                if info.is_storage_node\n            },\n        )\n        units.update(\n            {\n                info.jules_storage_id + \"_sv\": info.unit_cost\n                for info in self.graph_infos.clearing.values()\n                if info.is_storage_node and info.unit_cost is not None\n            },\n        )\n        units.update(\n            {name: info.unit_flow_result for name, info in self.graph_infos.clearing.items() if info.is_flow},\n        )\n        return units\n\n    def _get_reference_period(self) -&gt; ReferencePeriod:\n        first_year, num_years = self._config.get_simulation_years()\n        return ReferencePeriod(first_year, num_years)\n\n    def _get_timevector(self, jules_id: str, loader: JulESH5TimeVectorLoader) -&gt; LoadedTimeVector:\n        try:\n            return LoadedTimeVector(vector_id=jules_id, loader=loader)\n        except Exception:\n            raise AssertionError from None\n</code></pre> <code></code> <code>__init__(folder: Path | str, config: JulESConfig, names: JulESNames, graphs: NodeFlowGraphs, graph_infos: GraphInfos) -&gt; None</code> <p>Handle retrieval of results from a JulES Serial simulation.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>Path | str</code> <p>Path to folder of the JulES simulation.</p> required <code>config</code> <code>JulESConfig</code> <p>Simulation config.</p> required <code>names</code> <code>JulESNames</code> <p>JulES namespace.</p> required <code>graphs</code> <code>NodeFlowGraphs</code> <p>Graphs used in the simulation.</p> required <code>graph_infos</code> <code>GraphInfos</code> <p>JulES specific info of each Component in the graphs.</p> required Source code in <code>framjules/solve_handler/results_handler/SerialResultsHandler.py</code> <pre><code>def __init__(\n    self,\n    folder: Path | str,\n    config: JulESConfig,\n    names: JulESNames,\n    graphs: NodeFlowGraphs,\n    graph_infos: GraphInfos,\n) -&gt; None:\n    \"\"\"Handle retrieval of results from a JulES Serial simulation.\n\n    Args:\n        folder (Path | str): Path to folder of the JulES simulation.\n        config (JulESConfig): Simulation config.\n        names (JulESNames): JulES namespace.\n        graphs (NodeFlowGraphs): Graphs used in the simulation.\n        graph_infos (GraphInfos): JulES specific info of each Component in the graphs.\n\n    \"\"\"\n    self._folder = Path(folder)\n    self._config = config\n    self._names = names\n\n    self.graphs = graphs\n    self.graph_infos = graph_infos\n\n    self.units = self._set_units()\n</code></pre> <code></code> <code>set_results() -&gt; None</code> <p>Set JulES results of all Components in the clearing graph.</p> Source code in <code>framjules/solve_handler/results_handler/SerialResultsHandler.py</code> <pre><code>def set_results(self) -&gt; None:\n    \"\"\"Set JulES results of all Components in the clearing graph.\"\"\"\n    is_whole_years = self._config.is_simulation_mode_serial()\n\n    loader = JulESH5TimeVectorLoader(\n        source=self._folder,\n        units=self.units,\n        relative_loc=self._names.FILENAME_H5_OUTPUT,\n        is_whole_years=is_whole_years,\n    )\n\n    supply_loader = SupplyJulESH5TimeVectorLoader(\n        source=self._folder,\n        units=self.units,\n        relative_loc=self._names.FILENAME_H5_OUTPUT,\n        is_whole_years=is_whole_years,\n    )\n\n    demand_loader = DemandJulESH5TimeVectorLoader(\n        source=self._folder,\n        units=self.units,\n        relative_loc=self._names.FILENAME_H5_OUTPUT,\n        is_whole_years=is_whole_years,\n    )\n\n    power_nodes = [\n        name\n        for name, c in self.graphs.clearing.items()\n        if isinstance(c, Node) and c.get_commodity() == JulESNames.POWER\n    ]\n    for name, c in self.graphs.clearing.items():\n        info: ComponentInfo = self.graph_infos.clearing[name]\n\n        if isinstance(c, Node):\n            if c.is_exogenous():\n                continue\n            self._set_node_results(c, name, loader)\n        if isinstance(c, Flow):\n            self._set_flow_results(\n                c,\n                info,\n                name,\n                loader,\n                power_nodes,\n                supply_loader=supply_loader,\n                demand_loader=demand_loader,\n            )\n</code></pre>"},{"location":"reference/#framjules.solve_handler.run_handler","title":"<code>run_handler</code>","text":""},{"location":"reference/#framjules.solve_handler.run_handler.SerialRunHandler","title":"<code>SerialRunHandler</code>","text":""},{"location":"reference/#framjules.solve_handler.run_handler.SerialRunHandler.SerialRunHandler","title":"<code>SerialRunHandler</code>","text":"<p>               Bases: <code>JuliaModel</code></p> <p>Handle running the JulES solver in serial simulation mode.</p> Source code in <code>framjules/solve_handler/run_handler/SerialRunHandler.py</code> <pre><code>class SerialRunHandler(JuliaModel):\n    \"\"\"Handle running the JulES solver in serial simulation mode.\"\"\"\n\n    # ENV_NAME = \"JulES_julia_env\"\n\n    def __init__(\n        self,\n        folder: Path,\n        config: JulESConfig,\n        names: JulESNames,\n        dependencies: list[str | tuple[str, str | None]] | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize JulES serial folder.\n\n        The three parameters env_path, depot_path and julia_path sets environment variables for locations of your Julia\n        environment, packages and language.\n            - If user has not specified locations, the default is to use the current python/conda environment.\n            - If a system installation of Python is used, the default is set to the current user location.\n\n        Args:\n            folder (Path): Location of JulES model dataset.\n            config (JulESConfig): Simulaiton config.\n            names (JulESNames): JulES namespace object.\n            dependencies (list[str]): Julia packages dependencies. List of str, either package names or urls.\n\n        \"\"\"\n        self._folder = folder\n        self._config = config\n        self._names = names\n        self.ENV_NAME = self._names.JULIA_ENV_NAME\n        super().__init__(\n            julia_path=self._config.get_julia_exe_path(),\n            env_path=self._config.get_julia_env_path(),\n            depot_path=self._config.get_julia_depot_path(),\n            dependencies=dependencies,\n            skip_install_dependencies=config.is_skip_install_dependencies(),\n            force_julia_install=config.get_force_julia_install(),\n        )\n\n    def run(self) -&gt; None:\n        \"\"\"Run JulES in Series mode.\"\"\"\n        data_year = self._config.get_data_period().get_start_time().isocalendar().year\n        weather_year = self._config.get_weather_years()[0]\n\n        config_path = self._folder / self._names.JULES_CONFIG\n        output_path = self._folder / self._names.FILENAME_H5_OUTPUT\n\n        def get_all_attrs(obj) -&gt; dict:  # noqa: ANN001\n            result = {}\n            result.update(\n                {k: v for k, v in obj.__class__.__dict__.items() if not k.startswith(\"__\") and not callable(v)},\n            )\n            result.update(obj.__dict__)\n            return result\n\n        names_dict = get_all_attrs(self._names)\n        filename_clearing = f\"{self._names.ROOT_FILENAME_DATAELEMENTS}_{self._names.CLEARING}.json\"\n        filename_aggregated = f\"{self._names.ROOT_FILENAME_DATAELEMENTS}_{self._names.AGGREGATED}.json\"\n\n        self._jl.seval(f\"\"\"\n        using Distributed, YAML, HDF5\n        config = YAML.load_file(\\\"{config_path.as_posix()}\\\")\n        println(\"Add cores\")\n        const numcores = config[\"main\"][\"numcores\"]\n        if nprocs() &lt; numcores\n            addprocs(numcores - nprocs())\n        end\n        @show nprocs()\n        println(\"Load JulES\")\n        @time @everywhere using JulES\n        using Pkg; Pkg.status()\n        \"\"\")\n\n        self._jl.JulES.run_jules(\n            config_path.as_posix(),\n            data_year,\n            weather_year,\n            output_path.as_posix(),\n            names_dict,\n            filename_clearing,\n            filename_aggregated,\n        )\n</code></pre> <code></code> <code>__init__(folder: Path, config: JulESConfig, names: JulESNames, dependencies: list[str | tuple[str, str | None]] | None = None) -&gt; None</code> <p>Initialize JulES serial folder.</p> <p>The three parameters env_path, depot_path and julia_path sets environment variables for locations of your Julia environment, packages and language.     - If user has not specified locations, the default is to use the current python/conda environment.     - If a system installation of Python is used, the default is set to the current user location.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>Path</code> <p>Location of JulES model dataset.</p> required <code>config</code> <code>JulESConfig</code> <p>Simulaiton config.</p> required <code>names</code> <code>JulESNames</code> <p>JulES namespace object.</p> required <code>dependencies</code> <code>list[str]</code> <p>Julia packages dependencies. List of str, either package names or urls.</p> <code>None</code> Source code in <code>framjules/solve_handler/run_handler/SerialRunHandler.py</code> <pre><code>def __init__(\n    self,\n    folder: Path,\n    config: JulESConfig,\n    names: JulESNames,\n    dependencies: list[str | tuple[str, str | None]] | None = None,\n) -&gt; None:\n    \"\"\"Initialize JulES serial folder.\n\n    The three parameters env_path, depot_path and julia_path sets environment variables for locations of your Julia\n    environment, packages and language.\n        - If user has not specified locations, the default is to use the current python/conda environment.\n        - If a system installation of Python is used, the default is set to the current user location.\n\n    Args:\n        folder (Path): Location of JulES model dataset.\n        config (JulESConfig): Simulaiton config.\n        names (JulESNames): JulES namespace object.\n        dependencies (list[str]): Julia packages dependencies. List of str, either package names or urls.\n\n    \"\"\"\n    self._folder = folder\n    self._config = config\n    self._names = names\n    self.ENV_NAME = self._names.JULIA_ENV_NAME\n    super().__init__(\n        julia_path=self._config.get_julia_exe_path(),\n        env_path=self._config.get_julia_env_path(),\n        depot_path=self._config.get_julia_depot_path(),\n        dependencies=dependencies,\n        skip_install_dependencies=config.is_skip_install_dependencies(),\n        force_julia_install=config.get_force_julia_install(),\n    )\n</code></pre> <code></code> <code>run() -&gt; None</code> <p>Run JulES in Series mode.</p> Source code in <code>framjules/solve_handler/run_handler/SerialRunHandler.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Run JulES in Series mode.\"\"\"\n    data_year = self._config.get_data_period().get_start_time().isocalendar().year\n    weather_year = self._config.get_weather_years()[0]\n\n    config_path = self._folder / self._names.JULES_CONFIG\n    output_path = self._folder / self._names.FILENAME_H5_OUTPUT\n\n    def get_all_attrs(obj) -&gt; dict:  # noqa: ANN001\n        result = {}\n        result.update(\n            {k: v for k, v in obj.__class__.__dict__.items() if not k.startswith(\"__\") and not callable(v)},\n        )\n        result.update(obj.__dict__)\n        return result\n\n    names_dict = get_all_attrs(self._names)\n    filename_clearing = f\"{self._names.ROOT_FILENAME_DATAELEMENTS}_{self._names.CLEARING}.json\"\n    filename_aggregated = f\"{self._names.ROOT_FILENAME_DATAELEMENTS}_{self._names.AGGREGATED}.json\"\n\n    self._jl.seval(f\"\"\"\n    using Distributed, YAML, HDF5\n    config = YAML.load_file(\\\"{config_path.as_posix()}\\\")\n    println(\"Add cores\")\n    const numcores = config[\"main\"][\"numcores\"]\n    if nprocs() &lt; numcores\n        addprocs(numcores - nprocs())\n    end\n    @show nprocs()\n    println(\"Load JulES\")\n    @time @everywhere using JulES\n    using Pkg; Pkg.status()\n    \"\"\")\n\n    self._jl.JulES.run_jules(\n        config_path.as_posix(),\n        data_year,\n        weather_year,\n        output_path.as_posix(),\n        names_dict,\n        filename_clearing,\n        filename_aggregated,\n    )\n</code></pre>"}]}